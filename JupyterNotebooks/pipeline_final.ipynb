{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import skimage.io as io\n",
    "import lmfit\n",
    "from lmfit.lineshapes import gaussian2d, lorentzian\n",
    "from skimage import transform\n",
    "from skimage.feature import blob_log, blob_doh, blob_dog\n",
    "from scipy import ndimage\n",
    "from skimage.measure import ransac\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import scipy.misc as sp\n",
    "from skimage.filters import gaussian\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from cmath import inf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import axes\n",
    "from matplotlib import figure\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the function needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_cal(src, dst):\n",
    "    \"\"\"This function is used to calculate the residual between src and dst.\n",
    "\n",
    "    Args:\n",
    "        src (numpy array): The source array having (N, 2) shape with N points.\n",
    "        dst (numpy array): The destination array having (N, 2) shape with N points.\n",
    "\n",
    "    Returns:\n",
    "        mse: The mean squared error between these two arraies.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(src, dst)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def blob_detection(img_path, min_sigma, max_sigma, threshold, method=0):\n",
    "    \"\"\"This function is mostly used for detecting the beads in any image.\n",
    "\n",
    "    Args:\n",
    "        img_path (string): The absolute path of the input image.\n",
    "        min_sigma (int): The minimum sigma, lower it is, smaller the blob will be detected.\n",
    "        max_sigma (int): The maximum sigma, higher it is, bigger the blob will be detected.\n",
    "        threshold (float): Higher it is, higher the intensities of blobs.\n",
    "        method (int, optional): 0 for Difference of Gaussian (DoG) and 1 for Determinant of Hessian (DoH). \n",
    "        They should be applied with different combination of parameters. DoG is more suitable for fret movies,\n",
    "        while DoH is more suitable for sequencing images. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        centers: A numpy array containing the coordinates of all the centers.\n",
    "    \"\"\"\n",
    "    img = io.imread(img_path)\n",
    "    if method == 0:\n",
    "        blob = blob_dog(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    else:\n",
    "        blob = blob_doh(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    i = 0\n",
    "    # r = 3\n",
    "    centers = []\n",
    "    h, w = img.shape\n",
    "    for blob in blob:\n",
    "        y, x, r = blob\n",
    "        if y > r and y < (h - r) and x > r and x < (w - r):\n",
    "            centers.append(\n",
    "                ndimage.measurements.center_of_mass(\n",
    "                    img[int(y - r) : int(y + r + 1), int(x - r) : int(x + r + 1)]\n",
    "                )\n",
    "            )\n",
    "            centers[i] = list(np.add(centers[i], [x - r, y - r]))\n",
    "            i += 1\n",
    "    return np.array(centers)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    Wrapped polynomial transformation for Ransac using.\n",
    "\"\"\"\n",
    "class QuadPolyTrans(transform.PolynomialTransform):\n",
    "    def estimate(*data):\n",
    "        return transform.PolynomialTransform.estimate(*data, order=2)\n",
    "\n",
    "\n",
    "class CubicPolyTrans(transform.PolynomialTransform):\n",
    "    def estimate(*data):\n",
    "        return transform.PolynomialTransform.estimate(*data, order=3)\n",
    "\n",
    "\n",
    "def count_nearest_pts(src, dst, radius):\n",
    "    \"\"\"Counting the number of nearest neighbors for each given point.\n",
    "\n",
    "    Args:\n",
    "        src (numpy array): (N, 2) shape array. Build the kd tree based on this.\n",
    "        dst (numpy array): (N, 2) shape array. For each point in this array, find the nearest neighbors in src array.\n",
    "        radius (int): The maximum searching radius.\n",
    "\n",
    "    Returns:\n",
    "        res, idx: res is the distance for the point and its neighbor, 'inf' means no neighbor in given search radius. \n",
    "        idx is the index for the neighbor in src array.\n",
    "    \"\"\"\n",
    "    tree = spatial.KDTree(src)\n",
    "    res, idx = tree.query(dst, k=1, distance_upper_bound=radius)\n",
    "    for i in range(0, len(idx)):\n",
    "        if len(np.argwhere(idx == idx[i])) > 1:\n",
    "            res[i] = inf\n",
    "    return res, idx\n",
    "\n",
    "\n",
    "def save_np_img(npimg, path):\n",
    "    \"\"\"Sava a numpy array as an image.\n",
    "\n",
    "    Args:\n",
    "        npimg (numpy array): A numpy array need to be saved as image.\n",
    "        path (string): The save path.\n",
    "    \"\"\"\n",
    "    img = Image.fromarray(npimg)\n",
    "    img = img.convert(\"L\")\n",
    "    img.save(path, dpi=(300.0, 300.0))\n",
    "\n",
    "\n",
    "def ploting_res(canvas_size, res, pts_radius, save_path, gaussian_sigma=3):\n",
    "    \"\"\" This function is used to generate any given numpy array to the image.\n",
    "\n",
    "    Args:\n",
    "        canvas_size (tuple): A two-element tuple as (x_range, y_range). Determine the size of generated image.\n",
    "        res (numpy array): The point set needed to generate the image.\n",
    "        pts_radius (int): The radius of the points.\n",
    "        save_path (string): The save path of the generated image.\n",
    "        gaussian_sigma (int, optional): The radius of gaussian blurring. Defaults to 3.\n",
    "    \"\"\"\n",
    "    x_range, y_range = canvas_size\n",
    "    pk_img = np.zeros(canvas_size)\n",
    "    for ele in res:\n",
    "        y = int(ele[0])\n",
    "        x = int(ele[1])\n",
    "        for j in range(0, pts_radius):\n",
    "            for k in range(0, pts_radius):\n",
    "                pk_img[\n",
    "                    min(max(0, x - j), x_range - 1), min(max(0, y - k), y_range - 1)\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(x_range - 1, max(0, x + j)), min(max(0, y - k), y_range - 1)\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(x_range - 1, max(0, x + j)), min(y_range - 1, max(0, y + k))\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(max(0, x - j), x_range - 1), min(y_range - 1, max(0, y + k))\n",
    "                ] = (1024 * 2)\n",
    "    blurred_img = gaussian(pk_img, sigma=gaussian_sigma, multichannel=False)\n",
    "    save_np_img(blurred_img, save_path)\n",
    "\n",
    "\n",
    "def count_pairs(ref_coord, target_coord, radius):\n",
    "    \"\"\"This function is used for counting how many pairs are there exsist in two point sets.\n",
    "\n",
    "    Args:\n",
    "        ref_coord (numpy array): The source point set.\n",
    "        target_coord (numpy array): The target point set.\n",
    "        radius (int): Searching radius.\n",
    "\n",
    "    Returns:\n",
    "       pairs: (int) The number of pairs.\n",
    "    \"\"\"\n",
    "    tree = spatial.KDTree(ref_coord)\n",
    "    res, idx = tree.query(target_coord, k=1)\n",
    "    polished_fretPts = ref_coord[idx[np.where(res != inf)]]\n",
    "    pairs = 0\n",
    "    pp = 0\n",
    "    for i in idx:\n",
    "        if res[pp] < radius:\n",
    "            pairs += 1\n",
    "        pp += 1\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def read_coord(csv_path):\n",
    "    \"\"\"Read csv file and transfer them into numpy array.\n",
    "\n",
    "    Args:\n",
    "        csv_path (string): CSV file path.\n",
    "\n",
    "    Returns:\n",
    "        pts: The numpy array containing all the coordinats in the given csv file.\n",
    "    \"\"\"\n",
    "    res_tb = pd.read_csv(csv_path)\n",
    "    pts = np.column_stack(\n",
    "        (np.array(res_tb[\"X\"][0 : len(res_tb)]), np.array(res_tb[\"Y\"][0 : len(res_tb)]))\n",
    "    )\n",
    "    return pts\n",
    "\n",
    "\n",
    "def show_blob_detection_res(img_path, min_sigma, max_sigma, threshold, method=0):\n",
    "    \"\"\"\n",
    "    Showing the result of 'blob detection' function. Used as the same way of 'blob_detection'\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    img = io.imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    if method == 0:\n",
    "        res = blob_dog(\n",
    "            img,\n",
    "            min_sigma=min_sigma,\n",
    "            max_sigma=max_sigma,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    else:\n",
    "        res = blob_doh(\n",
    "            img,\n",
    "            min_sigma=min_sigma,\n",
    "            max_sigma=max_sigma,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    i = 0\n",
    "    CM = []\n",
    "    r = 3\n",
    "    [h, w] = img.shape\n",
    "    for blob in res:\n",
    "        y, x, r = blob\n",
    "        # print(r)\n",
    "        if y > r and y < (h - r) and x > r and x < (w - r):\n",
    "            CM.append(\n",
    "                ndimage.measurements.center_of_mass(\n",
    "                    img[int(y - r) : int(y + r), int(x - r) : int(x + r)]\n",
    "                )\n",
    "            )\n",
    "            CM[i] = list(np.add(CM[i], [y - r, x - r]))\n",
    "            x1, y1 = CM[i]\n",
    "            c = plt.Circle([y1, x1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "            i += 1\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Alignment\n",
    "#### Using mannually labelled beads as the first rough alignment\n",
    "\n",
    "> $res\\_tb$ is the clicked results from ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tb = pd.read_csv(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Test/Results.csv\"\n",
    ")\n",
    "sample_num = int(len(res_tb) / 2)\n",
    "src = np.column_stack(\n",
    "    (np.array(res_tb[\"XM\"][0:sample_num]), np.array(res_tb[\"YM\"][0:sample_num]))\n",
    ")\n",
    "dst = np.column_stack(\n",
    "    (np.array(res_tb[\"XM\"][sample_num:]), np.array(res_tb[\"YM\"][sample_num:]))\n",
    ")\n",
    "\n",
    "rough_tf = transform.estimate_transform(\"affine\", src=src, dst=dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting centers of automatically labelled beads (using center of mass)\n",
    "\n",
    "The parameters could be adjust:\n",
    "\n",
    " 1. $min\\_sigma$ determine how small the blobs could be detected\n",
    " 2. $max\\_sigma$ determine how big the blobs could be detected\n",
    " 3. $threhold$ determine the intensities of blobs.\n",
    "\n",
    "\n",
    "> Uncomment $show\\_blob\\_detection\\_res$ to show the result. It could also be used before getting the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/beads_246_fret_channel.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=10,\n",
    "    threshold=0.01,\n",
    ")\n",
    "\n",
    "seq_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/min_projection_246.tif\",\n",
    "    min_sigma=20,\n",
    "    max_sigma=500,\n",
    "    threshold=0.001,\n",
    "    method=1,\n",
    ")\n",
    "\n",
    "# show_blob_detection_res(\n",
    "#     \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/beads_246_fret_channel.tif\",\n",
    "#     min_sigma=1,\n",
    "#     max_sigma=10,\n",
    "#     threshold=0.01,\n",
    "# )\n",
    "\n",
    "# show_blob_detection_res(\n",
    "#     \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/min_projection_246.tif\",\n",
    "#     min_sigma=20,\n",
    "#     max_sigma=500,\n",
    "#     threshold=0.001,\n",
    "#     method=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the combination of two channels, to get all the peak locations from both channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_channel_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/grenn_channel_beads.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=8,\n",
    "    threshold=0.0001,\n",
    ")\n",
    "\n",
    "red_channel_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_channel_beads.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=8,\n",
    "    threshold=0.0001,\n",
    ")\n",
    "\n",
    "# show_blob_detection_res('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/grenn_channel_beads.tif')\n",
    "# show_blob_detection_res('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_channel_beads.tif')\n",
    "\n",
    "res, idx = count_nearest_pts(green_channel_centers, red_channel_centers, 2)\n",
    "# print(idx)\n",
    "# print(res)\n",
    "\n",
    "usable_green_beads = green_channel_centers[idx[np.where(res != inf)]]\n",
    "usable_red_beads = red_channel_centers[np.where(res != inf)]\n",
    "print(usable_green_beads)\n",
    "print(usable_red_beads)\n",
    "\n",
    "tform = transform.AffineTransform()\n",
    "tform.estimate(usable_green_beads, usable_red_beads)\n",
    "tsformed_green_beads = tform(usable_green_beads)\n",
    "print(tsformed_green_beads)\n",
    "ploting_res(\n",
    "    (256, 512),\n",
    "    res=usable_red_beads,\n",
    "    pts_radius=2,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_beads.png\",\n",
    ")\n",
    "ploting_res(\n",
    "    (256, 512),\n",
    "    res=tsformed_green_beads,\n",
    "    pts_radius=2,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/tform_green_beads.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the local maximum from ImageJ, for both channels\n",
    "And then apply the affine transformation found in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_channel_peaks = read_coord(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/Green_channel_peaks.csv\"\n",
    ")\n",
    "red_channel_peaks = read_coord(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/Red_channel_peaks.csv\"\n",
    ")\n",
    "print(tform(green_channel_peaks))\n",
    "combiened_peaks = np.concatenate((tform(green_channel_peaks), red_channel_peaks))\n",
    "print(combiened_peaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting simple linear transformed beads and beads from seq image\n",
    "Then we will use them to do the RANSAC test and get the reliable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = 1566\n",
    "y_range = 3240\n",
    "print(rough_tf(movie_centers))\n",
    "print(seq_centers)\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    res=rough_tf(movie_centers),\n",
    "    pts_radius=3,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/movie_center.png\",\n",
    ")\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    res=seq_centers,\n",
    "    pts_radius=3,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/seq_center.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ransac to get more pricise beads matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, idx = count_nearest_pts(rough_tf(movie_centers), seq_centers, 8)\n",
    "print(res)\n",
    "print(idx)\n",
    "movie_centers = movie_centers[idx[np.where(res != inf)]]\n",
    "seq_centers = seq_centers[np.where(res != inf)]\n",
    "\n",
    "print(movie_centers)\n",
    "print(seq_centers)\n",
    "\n",
    "model, inliers = ransac(\n",
    "    (movie_centers, seq_centers),\n",
    "    QuadPolyTrans,\n",
    "    4,\n",
    "    5,\n",
    "    initial_inliers=np.ones(len(movie_centers), dtype=bool),\n",
    "    stop_probability=0.8,\n",
    ")\n",
    "print(inliers)\n",
    "print(model(movie_centers))\n",
    "print(seq_centers)\n",
    "print(residual_cal(model(movie_centers), seq_centers))\n",
    "\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    model(movie_centers),\n",
    "    3,\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/movie_center_f.png\",\n",
    ")\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    seq_centers,\n",
    "    3,\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/seq_center_f.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_locations = combiened_peaks\n",
    "\n",
    "res = model(np.array(peak_locations))\n",
    "\n",
    "save_path = \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/\"\n",
    "canvas_size = (1566, 3240)\n",
    "ploting_res(canvas_size, res, 3, save_path + \"transformed_res.png\")\n",
    "fastq = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_lib.csv\")\n",
    "res_1, idx_1 = count_nearest_pts(res, fastq, 20)\n",
    "polished_movie = res[idx_1[np.where(res_1 != inf)]]\n",
    "polished_fastq = fastq[np.where(res_1 != inf)]\n",
    "print(len(polished_fastq))\n",
    "ploting_res((x_range, y_range), polished_fastq, 10, save_path=save_path + \"fastq.png\", gaussian_sigma=10)\n",
    "ploting_res((x_range, y_range), polished_movie, 3, save_path=save_path + \"fret.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This part is for random checking.\n",
    "10 random datasets are generated and stored in $rd\\_set$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_set = []\n",
    "for i in range(0, 1):\n",
    "    rd = np.random.random((1300, 2))\n",
    "    rd[:, 0] = rd[:, 0] * 512\n",
    "    rd[:, 1] = rd[:, 1] * 256\n",
    "    rd_set.append(rd)\n",
    "\n",
    "rd_arr = []\n",
    "arti_arr = []\n",
    "phix_arr = []\n",
    "\n",
    "peak_locations = combiened_peaks\n",
    "\n",
    "res = model(np.array(peak_locations))\n",
    "rd_res = model(np.array(rd_set[0]))\n",
    "canvas_size = (1566, 3240)\n",
    "ploting_res(canvas_size, rd_res, 3, save_path + \"rd1.png\")\n",
    "\n",
    "save_path = \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/\"\n",
    "# ploting_res(canvas_size, res, 3, save_path + \"transformed_res.png\")\n",
    "fastq = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_lib.csv\")\n",
    "phix = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_phix.csv\")\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_rd, idx_rd = count_nearest_pts(rd_res, fastq, i)\n",
    "    polished_fretPts_k = rd_res[idx_rd[np.where(res_rd != inf)]]\n",
    "    polished_rd_k = fastq[np.where(res_rd != inf)]\n",
    "    rd_arr.append(len(polished_rd_k))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_final, idx_final = count_nearest_pts(res, fastq, i)\n",
    "    polished_fretPts_final = res[idx_final[np.where(res_final != inf)]]\n",
    "    polished_fastq_final = fastq[np.where(res_final != inf)]\n",
    "    arti_arr.append(len(polished_fastq_final))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_phix, idx_phix = count_nearest_pts(res, phix, i)\n",
    "    polished_fretPts_phix = res[idx_phix[np.where(res_phix != inf)]]\n",
    "    polished_fastq_phix = phix[np.where(res_phix != inf)]\n",
    "    phix_arr.append(len(polished_fastq_phix))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rd_arr, label='random')\n",
    "plt.plot(arti_arr, label='lib')\n",
    "plt.plot(phix_arr, label='phix')\n",
    "plt.plot(np.array(arti_arr) - np.array(rd_arr), label='Difference')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# ploting_res((x_range, y_range), polished_rd_k, 3, save_path + \"polished_rd.png\")\n",
    "# ploting_res(\n",
    "#     (x_range, y_range), polished_fretPts_k, 3, save_path + \"polished_fretPts_rd.png\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('donuts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09a6daa413063a39d67ff2395b4b7988be6704d7b326a0f0df1f4a2f602d4384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
