{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import skimage.io as io\n",
    "import lmfit\n",
    "from lmfit.lineshapes import gaussian2d, lorentzian\n",
    "from skimage import transform\n",
    "from skimage.feature import blob_log, blob_doh, blob_dog\n",
    "from scipy import ndimage\n",
    "from skimage.measure import ransac\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from scipy import spatial\n",
    "import scipy.misc as sp\n",
    "from skimage.filters import gaussian\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from cmath import inf\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import axes\n",
    "from matplotlib import figure\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the function needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_cal(src, dst):\n",
    "    \"\"\"This function is used to calculate the residual between src and dst.\n",
    "\n",
    "    Args:\n",
    "        src (numpy array): The source array having (N, 2) shape with N points.\n",
    "        dst (numpy array): The destination array having (N, 2) shape with N points.\n",
    "\n",
    "    Returns:\n",
    "        mse: The mean squared error between these two arraies.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(src, dst)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def blob_detection(img_path, min_sigma, max_sigma, threshold, method=0):\n",
    "    \"\"\"This function is mostly used for detecting the beads in any image.\n",
    "\n",
    "    Args:\n",
    "        img_path (string): The absolute path of the input image.\n",
    "        min_sigma (int): The minimum sigma, lower it is, smaller the blob will be detected.\n",
    "        max_sigma (int): The maximum sigma, higher it is, bigger the blob will be detected.\n",
    "        threshold (float): Higher it is, higher the intensities of blobs.\n",
    "        method (int, optional): 0 for Difference of Gaussian (DoG) and 1 for Determinant of Hessian (DoH). \n",
    "        They should be applied with different combination of parameters. DoG is more suitable for fret movies,\n",
    "        while DoH is more suitable for sequencing images. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        centers: A numpy array containing the coordinates of all the centers.\n",
    "    \"\"\"\n",
    "    img = io.imread(img_path)\n",
    "    if method == 0:\n",
    "        blob = blob_dog(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    else:\n",
    "        blob = blob_doh(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    i = 0\n",
    "    # r = 3\n",
    "    centers = []\n",
    "    h, w = img.shape\n",
    "    for blob in blob:\n",
    "        y, x, r = blob\n",
    "        if y > r and y < (h - r) and x > r and x < (w - r):\n",
    "            centers.append(\n",
    "                ndimage.measurements.center_of_mass(\n",
    "                    img[int(y - r) : int(y + r + 1), int(x - r) : int(x + r + 1)]\n",
    "                )\n",
    "            )\n",
    "            centers[i] = list(np.add(centers[i], [x - r, y - r]))\n",
    "            i += 1\n",
    "    return np.array(centers)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    Wrapped polynomial transformation for Ransac using.\n",
    "\"\"\"\n",
    "class QuadPolyTrans(transform.PolynomialTransform):\n",
    "    def estimate(*data):\n",
    "        return transform.PolynomialTransform.estimate(*data, order=2)\n",
    "\n",
    "\n",
    "class CubicPolyTrans(transform.PolynomialTransform):\n",
    "    def estimate(*data):\n",
    "        return transform.PolynomialTransform.estimate(*data, order=3)\n",
    "\n",
    "\n",
    "def count_nearest_pts(src, dst, radius):\n",
    "    \"\"\"Counting the number of nearest neighbors for each given point.\n",
    "\n",
    "    Args:\n",
    "        src (numpy array): (N, 2) shape array. Build the kd tree based on this.\n",
    "        dst (numpy array): (N, 2) shape array. For each point in this array, find the nearest neighbors in src array.\n",
    "        radius (int): The maximum searching radius.\n",
    "\n",
    "    Returns:\n",
    "        res, idx: res is the distance for the point and its neighbor, 'inf' means no neighbor in given search radius. \n",
    "        idx is the index for the neighbor in src array.\n",
    "    \"\"\"\n",
    "    tree = spatial.KDTree(src)\n",
    "    res, idx = tree.query(dst, k=1, distance_upper_bound=radius)\n",
    "    for i in range(0, len(idx)):\n",
    "        if len(np.argwhere(idx == idx[i])) > 1:\n",
    "            res[i] = inf\n",
    "    return res, idx\n",
    "\n",
    "\n",
    "def save_np_img(npimg, path):\n",
    "    \"\"\"Sava a numpy array as an image.\n",
    "\n",
    "    Args:\n",
    "        npimg (numpy array): A numpy array need to be saved as image.\n",
    "        path (string): The save path.\n",
    "    \"\"\"\n",
    "    img = Image.fromarray(npimg)\n",
    "    img = img.convert(\"L\")\n",
    "    img.save(path, dpi=(300.0, 300.0))\n",
    "\n",
    "\n",
    "def ploting_res(canvas_size, res, pts_radius, save_path, gaussian_sigma=3):\n",
    "    \"\"\" This function is used to generate any given numpy array to the image.\n",
    "\n",
    "    Args:\n",
    "        canvas_size (tuple): A two-element tuple as (x_range, y_range). Determine the size of generated image.\n",
    "        res (numpy array): The point set needed to generate the image.\n",
    "        pts_radius (int): The radius of the points.\n",
    "        save_path (string): The save path of the generated image.\n",
    "        gaussian_sigma (int, optional): The radius of gaussian blurring. Defaults to 3.\n",
    "    \"\"\"\n",
    "    x_range, y_range = canvas_size\n",
    "    pk_img = np.zeros(canvas_size)\n",
    "    for ele in res:\n",
    "        y = int(ele[0])\n",
    "        x = int(ele[1])\n",
    "        for j in range(0, pts_radius):\n",
    "            for k in range(0, pts_radius):\n",
    "                pk_img[\n",
    "                    min(max(0, x - j), x_range - 1), min(max(0, y - k), y_range - 1)\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(x_range - 1, max(0, x + j)), min(max(0, y - k), y_range - 1)\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(x_range - 1, max(0, x + j)), min(y_range - 1, max(0, y + k))\n",
    "                ] = (1024 * 2)\n",
    "                pk_img[\n",
    "                    min(max(0, x - j), x_range - 1), min(y_range - 1, max(0, y + k))\n",
    "                ] = (1024 * 2)\n",
    "    blurred_img = gaussian(pk_img, sigma=gaussian_sigma, multichannel=False)\n",
    "    save_np_img(blurred_img, save_path)\n",
    "\n",
    "\n",
    "def count_pairs(ref_coord, target_coord, radius):\n",
    "    \"\"\"This function is used for counting how many pairs are there exsist in two point sets.\n",
    "\n",
    "    Args:\n",
    "        ref_coord (numpy array): The source point set.\n",
    "        target_coord (numpy array): The target point set.\n",
    "        radius (int): Searching radius.\n",
    "\n",
    "    Returns:\n",
    "       pairs: (int) The number of pairs.\n",
    "    \"\"\"\n",
    "    tree = spatial.KDTree(ref_coord)\n",
    "    res, idx = tree.query(target_coord, k=1)\n",
    "    polished_fretPts = ref_coord[idx[np.where(res != inf)]]\n",
    "    pairs = 0\n",
    "    pp = 0\n",
    "    for i in idx:\n",
    "        if res[pp] < radius:\n",
    "            pairs += 1\n",
    "        pp += 1\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def read_coord(csv_path):\n",
    "    \"\"\"Read csv file and transfer them into numpy array.\n",
    "\n",
    "    Args:\n",
    "        csv_path (string): CSV file path.\n",
    "\n",
    "    Returns:\n",
    "        pts: The numpy array containing all the coordinats in the given csv file.\n",
    "    \"\"\"\n",
    "    res_tb = pd.read_csv(csv_path)\n",
    "    pts = np.column_stack(\n",
    "        (np.array(res_tb[\"X\"][0 : len(res_tb)]), np.array(res_tb[\"Y\"][0 : len(res_tb)]))\n",
    "    )\n",
    "    return pts\n",
    "\n",
    "\n",
    "def show_blob_detection_res(img_path, min_sigma, max_sigma, threshold, method=0):\n",
    "    \"\"\"\n",
    "    Showing the result of 'blob detection' function. Used as the same way of 'blob_detection'\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    img = io.imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    if method == 0:\n",
    "        res = blob_dog(\n",
    "            img,\n",
    "            min_sigma=min_sigma,\n",
    "            max_sigma=max_sigma,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    else:\n",
    "        res = blob_doh(\n",
    "            img,\n",
    "            min_sigma=min_sigma,\n",
    "            max_sigma=max_sigma,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "    i = 0\n",
    "    CM = []\n",
    "    r = 3\n",
    "    [h, w] = img.shape\n",
    "    for blob in res:\n",
    "        y, x, r = blob\n",
    "        # print(r)\n",
    "        if y > r and y < (h - r) and x > r and x < (w - r):\n",
    "            CM.append(\n",
    "                ndimage.measurements.center_of_mass(\n",
    "                    img[int(y - r) : int(y + r), int(x - r) : int(x + r)]\n",
    "                )\n",
    "            )\n",
    "            CM[i] = list(np.add(CM[i], [y - r, x - r]))\n",
    "            x1, y1 = CM[i]\n",
    "            c = plt.Circle([y1, x1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "            i += 1\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_pos(record):\n",
    "    des = record.description\n",
    "    tile_num = int(des.split(\" \")[0].split(\":\")[4])\n",
    "    x_pos = int(des.split(\" \")[0].split(\":\")[5])\n",
    "    y_pos = int(des.split(\" \")[0].split(\":\")[6])\n",
    "    seq = str(record.seq)\n",
    "    return tile_num, x_pos, y_pos, seq\n",
    "\n",
    "\n",
    "def generate_img(coordinates, op_path, r, blurred, sigma):\n",
    "    x = coordinates[:, 0]\n",
    "    y = coordinates[:, 1]\n",
    "    x_min = np.min(x)\n",
    "    y_min = np.min(y)\n",
    "    x_range = 30000\n",
    "    y_range = 30000\n",
    "    img = np.zeros(shape=(30000, 30000))\n",
    "    for i in range(0, len(x)):\n",
    "        for j in range(0, r):\n",
    "            for k in range(0, r):\n",
    "                img[max(0, x[i] - x_min - j), max(0, y[i] - y_min - k)] = 1024 * 2\n",
    "                img[min(x_range - 1, x[i] - x_min + j), max(0, y[i] - y_min - k)] = (\n",
    "                    1024 * 2\n",
    "                )\n",
    "                img[\n",
    "                    min(x_range - 1, x[i] - x_min + j),\n",
    "                    min(y_range - 1, y[i] - y_min + k),\n",
    "                ] = (\n",
    "                    1024 * 2\n",
    "                )\n",
    "                img[max(0, x[i] - x_min - j), min(y_range - 1, y[i] - y_min + k)] = (\n",
    "                    1024 * 2\n",
    "                )\n",
    "    if blurred:\n",
    "        img = gaussian(img, sigma=sigma)\n",
    "    im = Image.fromarray(img)\n",
    "    new_im = im.convert(\"L\")\n",
    "    new_im.save(op_path, dpi=(300.0, 300.0))\n",
    "\n",
    "\n",
    "def process_seq_info(fastq_path, tile):\n",
    "    x_coordinate = []\n",
    "    y_coordinate = []\n",
    "    seq_set = []\n",
    "    for record in SeqIO.parse(fastq_path, \"fastq\"):\n",
    "        if record is not None:\n",
    "            tile_num, x_pos, y_pos, seq = get_pos(record)\n",
    "            if tile_num == tile:\n",
    "                x_coordinate.append(x_pos)\n",
    "                y_coordinate.append(y_pos)\n",
    "                seq_set.append(seq)\n",
    "    coordinates = np.column_stack(\n",
    "        (\n",
    "            max(x_coordinate) - np.array(x_coordinate),\n",
    "            max(y_coordinate) - np.array(y_coordinate),\n",
    "        )\n",
    "    )\n",
    "    return coordinates, np.array(seq_set)\n",
    "\n",
    "\n",
    "def tell_me_sequence(source_coord, target_coord, seq_set):\n",
    "    count_nearest_pts(source_coord, target_coord, 20)\n",
    "    tree = spatial.KDTree(source_coord)\n",
    "    res, idx = tree.query(target_coord, k=1, distance_upper_bound=20)\n",
    "    for i in range(0, len(idx)):\n",
    "        if len(np.argwhere(idx == idx[i])) > 1:\n",
    "            res[i] = inf\n",
    "    return seq_set[idx]\n",
    "\n",
    "\n",
    "def get_sequence_list(fastq_coord, peaks, transformation_model, start_point, seq_set):\n",
    "    \"\"\"Use the function to get sequence name tags. \n",
    "    Only need the peaks coordinates from microscopy images and the transformation model from alignment of beads.\n",
    "    The function already includes function of finding the nearest neighbor.\n",
    "\n",
    "    Args:\n",
    "        fastq_coord (numpy array): The fastq coordinates. Should be gotten from processing of sequencing information.\n",
    "        peaks (numpy array): The coordinates for peaks of single molecules.\n",
    "        transformation_model (Transformation Model Class): The transformation model, gotten from alignment of beads.\n",
    "        start_point ((X, Y) array): The start point of the cropped sequencing image for one exact ROI.\n",
    "        seq_set (numpy array): The sequence set. Arranged in the same order of the coordinates. Gotten from processing of sequence information.\n",
    "\n",
    "    Returns:\n",
    "        seq_list: The sequence list.\n",
    "    \"\"\"\n",
    "    transformed_fastq_coord = transformation_model(np.array(peaks))\n",
    "    transformed_fastq_coord[:, 0] = start_point[0] + transformed_fastq_coord[:, 0]\n",
    "    transformed_fastq_coord[:, 1] = start_point[1] + transformed_fastq_coord[:, 1]\n",
    "    seq_list = tell_me_sequence(fastq_coord, transformed_fastq_coord, seq_set)\n",
    "    return np.array(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = read_coord('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0829NewData/Results.csv')\n",
    "ploting_res((2944, 2866), pts, 2, '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0829NewData/1101.png', gaussian_sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misha test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False  True  True  True  True False  True  True\n",
      " False  True False False  True  True False  True  True False False False\n",
      "  True False False False False False  True False  True False False False\n",
      "  True False False False False False False  True False False False  True\n",
      "  True False False  True  True  True  True False False  True False False\n",
      " False False False  True  True  True False  True False  True False False\n",
      " False  True False False False False  True False False  True  True False\n",
      " False False False  True  True False False False False  True False False\n",
      "  True False  True False False False False False False False  True  True\n",
      " False False False  True False  True False False  True  True  True False\n",
      "  True  True  True  True  True False  True  True False  True  True  True\n",
      " False  True False False False  True False False  True False False]\n",
      "1.602240921892089\n"
     ]
    }
   ],
   "source": [
    "green_beads = np.load('/Volumes/Verbatim/usable_green_beads.npy')\n",
    "red_beads = np.load('/Volumes/Verbatim/usable_red_beads.npy')\n",
    "\n",
    "# print(green_beads)\n",
    "# print(red_beads)\n",
    "\n",
    "model, inliers = ransac(\n",
    "    (green_beads, red_beads),\n",
    "    CubicPolyTrans,\n",
    "    10,\n",
    "    0.5,\n",
    "    initial_inliers=np.ones(len(green_beads), dtype=bool),\n",
    "    stop_probability=0.9,\n",
    "    max_trials=1000\n",
    ")\n",
    "print(inliers)\n",
    "# print(model(green_beads))\n",
    "print(residual_cal(model(green_beads), red_beads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Alignment\n",
    "#### Using mannually labelled beads as the first rough alignment\n",
    "\n",
    "> $res\\_tb$ is the clicked results from ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tb = pd.read_csv(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Test/Results.csv\"\n",
    ")\n",
    "sample_num = int(len(res_tb) / 2)\n",
    "src = np.column_stack(\n",
    "    (np.array(res_tb[\"XM\"][0:sample_num]), np.array(res_tb[\"YM\"][0:sample_num]))\n",
    ")\n",
    "dst = np.column_stack(\n",
    "    (np.array(res_tb[\"XM\"][sample_num:]), np.array(res_tb[\"YM\"][sample_num:]))\n",
    ")\n",
    "\n",
    "rough_tf = transform.estimate_transform(\"affine\", src=src, dst=dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting centers of automatically labelled beads (using center of mass)\n",
    "\n",
    "The parameters could be adjust:\n",
    "\n",
    " 1. $min\\_sigma$ determine how small the blobs could be detected\n",
    " 2. $max\\_sigma$ determine how big the blobs could be detected\n",
    " 3. $threhold$ determine the intensities of blobs.\n",
    "\n",
    "\n",
    "> Uncomment $show\\_blob\\_detection\\_res$ to show the result. It could also be used before getting the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "movie_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/beads_246_fret_channel.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=10,\n",
    "    threshold=0.01,\n",
    ")\n",
    "\n",
    "seq_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/min_projection_246.tif\",\n",
    "    min_sigma=20,\n",
    "    max_sigma=500,\n",
    "    threshold=0.001,\n",
    "    method=1,\n",
    ")\n",
    "\n",
    "# show_blob_detection_res(\n",
    "#     \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/beads_246_fret_channel.tif\",\n",
    "#     min_sigma=1,\n",
    "#     max_sigma=10,\n",
    "#     threshold=0.01,\n",
    "# )\n",
    "\n",
    "# show_blob_detection_res(\n",
    "#     \"/Users/qinhanhou/Desktop/DeindlLab/Git/MUSCLE/ExampleData/Pos246/min_projection_246.tif\",\n",
    "#     min_sigma=20,\n",
    "#     max_sigma=500,\n",
    "#     threshold=0.001,\n",
    "#     method=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the combination of two channels, to get all the peak locations from both channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415.05220381 198.99843701]\n",
      " [ 60.01935179 134.04546885]\n",
      " [164.0893684  195.04537877]\n",
      " [316.40385859 123.97529932]\n",
      " [396.00186027 242.02852418]\n",
      " [319.92256565  94.95484136]\n",
      " [389.91068016 246.94510961]\n",
      " [438.43397322  87.47175315]\n",
      " [197.99821429 248.92293719]\n",
      " [186.90573394 247.90049148]\n",
      " [ 79.94434147 247.97121287]\n",
      " [484.98915569 232.00580945]\n",
      " [116.88390411 249.92140411]\n",
      " [ 53.93307234  36.97471887]\n",
      " [ 44.03453012 187.03904257]\n",
      " [140.94421998 216.95903479]\n",
      " [324.97905759 196.9786745 ]\n",
      " [384.49266612  89.40655487]\n",
      " [412.92241174  71.93649345]\n",
      " [339.00961538 107.98726611]\n",
      " [246.91165536 207.90442608]\n",
      " [336.98655745 239.94286915]\n",
      " [331.99524025 135.96600181]]\n",
      "[[414.29681556 198.96565251]\n",
      " [ 60.47869238 135.60814714]\n",
      " [163.37264794 195.97139973]\n",
      " [315.89340905 123.98382864]\n",
      " [394.34556298 242.10790548]\n",
      " [320.08035511  95.25192746]\n",
      " [388.93598955 248.0914435 ]\n",
      " [436.97883218  86.95506095]\n",
      " [198.9213138  248.97013759]\n",
      " [186.34715428 246.41528103]\n",
      " [ 79.92017107 248.94748445]\n",
      " [484.38842569 230.42366867]\n",
      " [115.89328501 250.91524195]\n",
      " [ 55.40666544  37.41916078]\n",
      " [ 44.04777198 186.04108123]\n",
      " [141.01460605 217.01728039]\n",
      " [322.98259145 197.01564566]\n",
      " [384.90346377  90.91600824]\n",
      " [411.94463645  72.94602305]\n",
      " [337.89461461 106.92204645]\n",
      " [247.99407407 208.00948148]\n",
      " [336.89684176 238.88520612]\n",
      " [331.89496644 134.90167785]]\n",
      "[[414.1415375  198.73975691]\n",
      " [ 60.50801077 134.58460954]\n",
      " [164.04001799 195.24027307]\n",
      " [316.05557479 124.08818162]\n",
      " [395.02457455 241.69028819]\n",
      " [319.65078229  95.13785251]\n",
      " [388.93902946 246.60469624]\n",
      " [437.78393663  87.46517034]\n",
      " [197.66998164 248.9162191 ]\n",
      " [186.6181537  247.9160513 ]\n",
      " [ 80.01850954 248.17546978]\n",
      " [483.74126483 231.53679699]\n",
      " [116.82712542 250.05529918]\n",
      " [ 54.73804411  37.77996604]\n",
      " [ 44.41584299 187.46700356]\n",
      " [140.90643634 217.13715405]\n",
      " [324.37935722 196.88436786]\n",
      " [384.01927597  89.49013724]\n",
      " [412.40603445  72.01582927]\n",
      " [338.63353831 108.10228775]\n",
      " [246.54285553 207.9192369 ]\n",
      " [336.21533679 239.7143349 ]\n",
      " [331.55766579 136.019808  ]]\n"
     ]
    }
   ],
   "source": [
    "green_channel_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/grenn_channel_beads.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=8,\n",
    "    threshold=0.0001,\n",
    ")\n",
    "\n",
    "red_channel_centers = blob_detection(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_channel_beads.tif\",\n",
    "    min_sigma=1,\n",
    "    max_sigma=8,\n",
    "    threshold=0.0001,\n",
    ")\n",
    "\n",
    "# show_blob_detection_res('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/grenn_channel_beads.tif')\n",
    "# show_blob_detection_res('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_channel_beads.tif')\n",
    "\n",
    "res, idx = count_nearest_pts(green_channel_centers, red_channel_centers, 2)\n",
    "# print(idx)\n",
    "# print(res)\n",
    "\n",
    "usable_green_beads = green_channel_centers[idx[np.where(res != inf)]]\n",
    "usable_red_beads = red_channel_centers[np.where(res != inf)]\n",
    "print(usable_green_beads)\n",
    "print(usable_red_beads)\n",
    "\n",
    "tform = transform.AffineTransform()\n",
    "tform.estimate(usable_green_beads, usable_red_beads)\n",
    "tsformed_green_beads = tform(usable_green_beads)\n",
    "print(tsformed_green_beads)\n",
    "ploting_res(\n",
    "    (256, 512),\n",
    "    res=usable_red_beads,\n",
    "    pts_radius=2,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/red_beads.png\",\n",
    ")\n",
    "ploting_res(\n",
    "    (256, 512),\n",
    "    res=tsformed_green_beads,\n",
    "    pts_radius=2,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/tform_green_beads.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the local maximum from ImageJ, for both channels\n",
    "And then apply the affine transformation found in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210.21278048  58.47433851]\n",
      " [255.51485428 235.92485222]\n",
      " [364.7369936   42.24271431]\n",
      " ...\n",
      " [ 17.33887663 231.36005557]\n",
      " [ 15.31518074 241.33728092]\n",
      " [ 16.28437907 250.31183921]]\n",
      "[[210.21278048  58.47433851]\n",
      " [255.51485428 235.92485222]\n",
      " [364.7369936   42.24271431]\n",
      " ...\n",
      " [  2.         231.        ]\n",
      " [ 11.         230.        ]\n",
      " [ 23.          15.        ]]\n"
     ]
    }
   ],
   "source": [
    "green_channel_peaks = read_coord(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/Green_channel_peaks.csv\"\n",
    ")\n",
    "red_channel_peaks = read_coord(\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/Red_channel_peaks.csv\"\n",
    ")\n",
    "print(tform(green_channel_peaks))\n",
    "combiened_peaks = np.concatenate((tform(green_channel_peaks), red_channel_peaks))\n",
    "print(combiened_peaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting simple linear transformed beads and beads from seq image\n",
    "Then we will use them to do the RANSAC test and get the reliable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 528.21532662  296.01929469]\n",
      " [2181.43749645  741.63468107]\n",
      " [1128.96697482 1414.47818913]\n",
      " [ 376.33461521 1487.97401176]\n",
      " [ 599.68286765  953.54140139]\n",
      " [1770.51475813 1124.38093029]\n",
      " [ 465.50709797 1407.04350498]\n",
      " [1680.94753897  643.60741874]\n",
      " [ 742.84674574 1209.89570064]\n",
      " [ 433.4946576  1281.39471712]\n",
      " [ 571.39216088 1386.5675764 ]\n",
      " [2788.9207256   629.43649169]\n",
      " [1068.3505937   192.93844911]\n",
      " [2642.72193322  850.60562496]\n",
      " [ 595.25551265 1380.71066604]\n",
      " [2255.62138995 1524.43931497]]\n",
      "[[2198.0662748   740.07539915]\n",
      " [ 529.40063777  293.38320347]\n",
      " [1127.09283872 1418.31100455]\n",
      " [ 373.49989326 1488.00769231]\n",
      " [1936.64905464  289.69508348]\n",
      " [2847.57145278  470.81939384]\n",
      " [3192.87878711  179.72986868]\n",
      " [ 602.91430711  955.02699728]\n",
      " [1772.29126133 1122.59562357]\n",
      " [1218.06577585 1201.05865079]\n",
      " [2716.19815169   62.76062257]\n",
      " [ 627.7905614  1215.27110412]\n",
      " [1355.20054014 1456.22016855]\n",
      " [ 291.1374623  1033.04326591]\n",
      " [1589.71777813  347.11339772]\n",
      " [1128.04357255  713.54568244]\n",
      " [ 461.11704043 1404.67451301]\n",
      " [2373.16697126  575.98803788]\n",
      " [ 437.33957486  542.44867847]\n",
      " [1148.88776178  602.16043971]\n",
      " [1068.72480839  191.18548077]\n",
      " [1028.68310191  585.47340753]\n",
      " [1546.4663935    44.90220806]\n",
      " [ 465.78104316  782.46024561]\n",
      " [ 973.4381076   120.78935626]\n",
      " [ 779.2562834  1519.93155221]\n",
      " [1448.93957492  532.57043738]\n",
      " [ 428.95868046 1274.7789768 ]\n",
      " [1125.43430069 1264.93516452]\n",
      " [2833.16257915  293.93413003]\n",
      " [  51.83920757 1401.35798393]\n",
      " [1068.89702828 1094.1273899 ]\n",
      " [1646.25551902 1112.49140401]\n",
      " [1211.15100057  707.69323158]\n",
      " [3123.4367994   119.60225683]\n",
      " [2056.94522256  873.03101703]\n",
      " [1018.74507853  505.97015315]\n",
      " [ 555.23070711 1484.81219636]\n",
      " [1647.80197656  481.37607566]\n",
      " [1834.96397668  884.66979952]\n",
      " [1932.44672544  249.62957599]\n",
      " [2437.02970235  773.09394595]\n",
      " [2330.71601251  609.50462797]\n",
      " [2974.5662653   823.48849368]\n",
      " [1081.29534012 1452.09087663]\n",
      " [2796.16454426  624.59353588]\n",
      " [2474.62525036 1294.58909308]\n",
      " [ 486.51857091  656.89389099]\n",
      " [2231.6210759   773.35670816]\n",
      " [1663.4641149   499.82559197]\n",
      " [1455.3307071  1374.50384016]\n",
      " [2060.68165052  123.85859392]\n",
      " [2892.11253229  246.17369023]\n",
      " [ 742.35971361 1207.66240491]\n",
      " [2173.29952148  695.16381622]\n",
      " [1287.6535683   484.83867199]\n",
      " [3182.01044689  952.22719095]\n",
      " [ 536.12808307 1232.07760312]\n",
      " [3128.83421613  379.58578387]\n",
      " [ 489.2705277   328.21020363]]\n"
     ]
    }
   ],
   "source": [
    "x_range = 1566\n",
    "y_range = 3240\n",
    "print(rough_tf(movie_centers))\n",
    "print(seq_centers)\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    res=rough_tf(movie_centers),\n",
    "    pts_radius=3,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/movie_center.png\",\n",
    ")\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    res=seq_centers,\n",
    "    pts_radius=3,\n",
    "    save_path=\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/seq_center.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ransac to get more pricise beads matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.89031822 4.26648101 2.83492203 3.55657084 2.51858764 4.9884595\n",
      " 1.79246608 2.28578435]\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[[ 60.71286237  26.60201787]\n",
      " [159.50942063 213.31693191]\n",
      " [ 33.21884831 225.97614063]\n",
      " [ 71.57109354 136.50704513]\n",
      " [267.54829127 164.49581076]\n",
      " [ 48.30509793 212.400363  ]\n",
      " [151.43263736   9.10066641]\n",
      " [ 95.1324732  179.29999911]]\n",
      "[[ 529.40063777  293.38320347]\n",
      " [1127.09283872 1418.31100455]\n",
      " [ 373.49989326 1488.00769231]\n",
      " [ 602.91430711  955.02699728]\n",
      " [1772.29126133 1122.59562357]\n",
      " [ 461.11704043 1404.67451301]\n",
      " [1068.72480839  191.18548077]\n",
      " [ 742.35971361 1207.66240491]]\n",
      "[ True  True  True  True  True  True  True  True]\n",
      "[[ 529.80015362  294.09499409]\n",
      " [1126.63953489 1417.05501715]\n",
      " [ 372.29482356 1486.69105912]\n",
      " [ 601.9458689   952.54650183]\n",
      " [1772.42606602 1122.88532393]\n",
      " [ 462.8414078  1406.34248546]\n",
      " [1068.61453902  190.93954426]\n",
      " [ 742.93504897 1210.36976882]]\n",
      "[[ 529.40063777  293.38320347]\n",
      " [1127.09283872 1418.31100455]\n",
      " [ 373.49989326 1488.00769231]\n",
      " [ 602.91430711  955.02699728]\n",
      " [1772.29126133 1122.59562357]\n",
      " [ 461.11704043 1404.67451301]\n",
      " [1068.72480839  191.18548077]\n",
      " [ 742.35971361 1207.66240491]]\n",
      "1.6448025848991856\n"
     ]
    }
   ],
   "source": [
    "res, idx = count_nearest_pts(rough_tf(movie_centers), seq_centers, 8)\n",
    "print(res)\n",
    "print(idx)\n",
    "movie_centers = movie_centers[idx[np.where(res != inf)]]\n",
    "seq_centers = seq_centers[np.where(res != inf)]\n",
    "\n",
    "print(movie_centers)\n",
    "print(seq_centers)\n",
    "\n",
    "model, inliers = ransac(\n",
    "    (movie_centers, seq_centers),\n",
    "    QuadPolyTrans,\n",
    "    4,\n",
    "    5,\n",
    "    initial_inliers=np.ones(len(movie_centers), dtype=bool),\n",
    "    stop_probability=0.8,\n",
    ")\n",
    "print(inliers)\n",
    "print(model(movie_centers))\n",
    "print(seq_centers)\n",
    "print(residual_cal(model(movie_centers), seq_centers))\n",
    "\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    model(movie_centers),\n",
    "    10,\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/movie_center_f.png\",\n",
    "    gaussian_sigma=8\n",
    ")\n",
    "ploting_res(\n",
    "    (x_range, y_range),\n",
    "    seq_centers,\n",
    "    10,\n",
    "    \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/seq_center_f.png\",\n",
    "    gaussian_sigma=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "peak_locations = combiened_peaks\n",
    "\n",
    "res = model(np.array(peak_locations))\n",
    "\n",
    "save_path = \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/\"\n",
    "canvas_size = (1566, 3240)\n",
    "ploting_res(canvas_size, res, 3, save_path + \"transformed_res.png\")\n",
    "fastq = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_lib.csv\")\n",
    "res_1, idx_1 = count_nearest_pts(res, fastq, 20)\n",
    "polished_movie = res[idx_1[np.where(res_1 != inf)]]\n",
    "polished_fastq = fastq[np.where(res_1 != inf)]\n",
    "print(len(polished_fastq))\n",
    "ploting_res((x_range, y_range), polished_fastq, 10, save_path=save_path + \"fastq.png\", gaussian_sigma=10)\n",
    "ploting_res((x_range, y_range), polished_movie, 5, save_path=save_path + \"fret.png\", gaussian_sigma=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This part is for random checking.\n",
    "10 random datasets are generated and stored in $rd\\_set$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_set = []\n",
    "for i in range(0, 1):\n",
    "    rd = np.random.random((1300, 2))\n",
    "    rd[:, 0] = rd[:, 0] * 512\n",
    "    rd[:, 1] = rd[:, 1] * 256\n",
    "    rd_set.append(rd)\n",
    "\n",
    "rd_arr = []\n",
    "arti_arr = []\n",
    "phix_arr = []\n",
    "\n",
    "peak_locations = combiened_peaks\n",
    "\n",
    "res = model(np.array(peak_locations))\n",
    "rd_res = model(np.array(rd_set[0]))\n",
    "canvas_size = (1566, 3240)\n",
    "ploting_res(canvas_size, rd_res, 3, save_path + \"rd1.png\")\n",
    "\n",
    "save_path = \"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0822_Combine2Channel/\"\n",
    "# ploting_res(canvas_size, res, 3, save_path + \"transformed_res.png\")\n",
    "fastq = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_lib.csv\")\n",
    "phix = read_coord(\"/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0817/coord_phix.csv\")\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_rd, idx_rd = count_nearest_pts(rd_res, fastq, i)\n",
    "    polished_fretPts_k = rd_res[idx_rd[np.where(res_rd != inf)]]\n",
    "    polished_rd_k = fastq[np.where(res_rd != inf)]\n",
    "    rd_arr.append(len(polished_rd_k))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_final, idx_final = count_nearest_pts(res, fastq, i)\n",
    "    polished_fretPts_final = res[idx_final[np.where(res_final != inf)]]\n",
    "    polished_fastq_final = fastq[np.where(res_final != inf)]\n",
    "    arti_arr.append(len(polished_fastq_final))\n",
    "\n",
    "for i in range(0, 100):\n",
    "    res_phix, idx_phix = count_nearest_pts(res, phix, i)\n",
    "    polished_fretPts_phix = res[idx_phix[np.where(res_phix != inf)]]\n",
    "    polished_fastq_phix = phix[np.where(res_phix != inf)]\n",
    "    phix_arr.append(len(polished_fastq_phix))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rd_arr, label='random')\n",
    "plt.plot(arti_arr, label='lib')\n",
    "plt.plot(phix_arr, label='phix')\n",
    "plt.plot(np.array(arti_arr) - np.array(rd_arr), label='Difference')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# ploting_res((x_range, y_range), polished_rd_k, 3, save_path + \"polished_rd.png\")\n",
    "# ploting_res(\n",
    "#     (x_range, y_range), polished_fretPts_k, 3, save_path + \"polished_fretPts_rd.png\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "09a6daa413063a39d67ff2395b4b7988be6704d7b326a0f0df1f4a2f602d4384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
