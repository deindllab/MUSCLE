{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import os.path \n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import tkinter.filedialog as fd\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage import transform, img_as_int, exposure, img_as_ubyte\n",
    "import skimage.io as io\n",
    "import skimage as si\n",
    "import tkinter.messagebox as mb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import blob_log, blob_doh, blob_dog\n",
    "from scipy import ndimage, spatial\n",
    "from cmath import inf\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "from skimage.filters import gaussian\n",
    "import pandas as pd\n",
    "from skimage.feature import peak_local_max\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import norm\n",
    "from math import floor, ceil, exp\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.io import savemat\n",
    "import Polywarp\n",
    "import itertools\n",
    "import scipy.spatial\n",
    "import star\n",
    "from skimage.restoration import rolling_ball\n",
    "\n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was the data collected in the ALEX regime?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX = False\n",
    "ALEX = True\n",
    "if ALEX:\n",
    "    green_frames = np.add(1,np.multiply(2,range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = 1\n",
    "#tile = 2\n",
    "# tile = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide the matching coordinates for the tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT ERASE PREVIOUS COORDINATES. ADD NEW LINES AND LABEL THE EXPERIMENT\n",
    "\n",
    "\n",
    "#240124_Ha_4N_ALEX_Tile_1\n",
    "coords_t_seq = np.array([-3009.476,234]) #Insert matching bead coordinates here manually!\n",
    "coords_t_FRET = np.array([0,0])\n",
    "#240124_Ha_4N_ALEX_Tile_2\n",
    "# coords_t_seq = np.array([106.645,233.696]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([0,0])\n",
    "\n",
    "#230215_Tile_3\n",
    "# coords_t_seq = np.array([2472.485,1187.175]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([9029.710,1510.853])\n",
    "\n",
    "\n",
    "#2023-01-26 Tile 1\n",
    "#coords_t_seq = np.array([1537.5,1398]) #Insert matching bead coordinates here manually!\n",
    "#coords_t_FRET = np.array([6335,1470.5])\n",
    "#2023-01-26 Tile 2\n",
    "# coords_t_seq = np.array([1447.4,1449.7]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3118.5,1499.8])\n",
    "\n",
    "#2023-01-23 Tile 1\n",
    "# coords_t_seq = np.array([1505.5,1481.8]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([6893.9,1298.6])\n",
    "#2023-01-23 Tile 2\n",
    "# coords_t_seq = np.array([829,1559.8]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3111.6,1353.6])\n",
    "\n",
    "#2022-12-27 Tile 1\n",
    "# coords_t_seq = np.array([1451.532,1204.410]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3739.046,1271.476])\n",
    "#2022-12-27 Tile 2\n",
    "# coords_t_seq = np.array([2577.568,1054.075]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([1751.353,1126.065])\n",
    "\n",
    "#2023-01-16 Tile 1\n",
    "# coords_t_seq = np.array([2067,348]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([8813, 785]) \n",
    "#2023-01-16 Tile 2\n",
    "# coords_t_seq = np.array([986,888]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([4644, 1300]) \n",
    "\n",
    "#2023-01-17 Tile 1\n",
    "# coords_t_seq = np.array([1525.5,1810.6]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([7238, 970.6]) \n",
    "#2023-01-17 Tile 2\n",
    "# coords_t_seq = np.array([1333.4,1987.6]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3971.3, 1154.7]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposecands(uknquadlist, refquadlist, n=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Function that identifies similar quads between the unknown image and a reference.\n",
    "    Returns a dict of (uknquad, refquad, dist, trans)\n",
    "    \"\"\"\n",
    "    # Nothing to do if the quadlists are empty ...\n",
    "    if len(uknquadlist) == 0 or len(refquadlist) == 0:\n",
    "        if verbose:\n",
    "            print(\"No quads to propose ...\")\n",
    "        return []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finding %i best candidates among %i x %i (ukn x ref)\" % (n, len(uknquadlist), len(refquadlist)))\n",
    "    uknhashs = np.array([q.hash for q in uknquadlist])\n",
    "    refhashs = np.array([q.hash for q in refquadlist])\n",
    "\n",
    "    # Brute force...\n",
    "    dists = scipy.spatial.distance.cdist(refhashs, uknhashs)\n",
    "    uknmindistindexes = np.argmin(dists, axis=0)  # For each ukn, the index of the closest ref\n",
    "    uknmindist = np.min(dists, axis=0)  # The corresponding distances\n",
    "    uknbestindexes = np.argsort(uknmindist)\n",
    "\n",
    "    candlist = []\n",
    "    nmax = len(uknbestindexes)\n",
    "    if verbose:\n",
    "        print(\"We have a maximum of %i quad pairs\" % (nmax))\n",
    "    for i in range(min(n, nmax)):\n",
    "\n",
    "        cand = {\"uknquad\": uknquadlist[uknbestindexes[i]], \"refquad\": refquadlist[uknmindistindexes[uknbestindexes[i]]],\n",
    "                \"dist\": uknmindist[uknbestindexes[i]]}\n",
    "\n",
    "        cand[\"trans\"] = quadtrans(cand[\"uknquad\"], cand[\"refquad\"])\n",
    "        print ((abs(cand[\"trans\"].getrotation())), cand[\"dist\"]) \n",
    "        if (abs(cand[\"trans\"].getrotation()) < 5): \n",
    "             candlist.append(cand)\n",
    "             if verbose:\n",
    "                 print(\"Cand %2i (dist. %12.8f) : %s\" % (i+1, cand[\"dist\"], str(cand[\"trans\"])))\n",
    "\n",
    "    return candlist\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Overhaul of cosmouline's star module, for alipy2.\n",
    "This module contains stuff for geometric matching algorithms.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import operator  # For sorting\n",
    "import copy\n",
    "import scipy.linalg\n",
    "import scipy.spatial\n",
    "\n",
    "\n",
    "class Dots:\n",
    "    \"\"\"\n",
    "    Simple class to represent a single source (usually stars, but not necessarily).\n",
    "    In this module we often manipulate lists of such Dots objects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=0.0, y=0.0, props={}, fwhm=-1.0, elon=-1.0):\n",
    "        \"\"\"\n",
    "        flux : Some \"default\" or \"automatic\" flux, might be a just good guess. Used for sorting etc.\n",
    "        If you have several fluxes, colours, store them in the props dict.\n",
    "        props : A placeholder dict to contain other properties of your choice (not required nor used by the methods).\n",
    "        \"\"\"\n",
    "        self.x = float(x)\n",
    "        self.y = float(y)\n",
    "        \n",
    "       \n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Used for sorting list of stars.\n",
    "        \"\"\"\n",
    "        if key == 'flux':\n",
    "            return self.flux\n",
    "        if key == 'fwhm':\n",
    "            return self.fwhm\n",
    "        if key == 'elon':\n",
    "            return self.elon\n",
    "\n",
    "  \n",
    "    \n",
    "    def coords(self, full=False):\n",
    "        \"\"\"\n",
    "        Returns the coords in form of an array.\n",
    "\n",
    "        :param full: If True, I also include flux, fwhm, elon\n",
    "        :type full: boolean\n",
    "\n",
    "        \"\"\"\n",
    "        if full:\n",
    "            return np.array([self.x, self.y, self.flux, self.fwhm, self.elon])\n",
    "        else:\n",
    "            return np.array([self.x, self.y])\n",
    "\n",
    "    def distance(self, otherstar):\n",
    "        \"\"\"\n",
    "        Returns the distance between the two stars.\n",
    "        \"\"\"\n",
    "        return math.sqrt(np.sum((self.coords() - otherstar.coords())**2))\n",
    "\n",
    "    def distanceandsort(self, otherstarlist):\n",
    "        \"\"\"\n",
    "        Returns a list of dicts(star, dist, origpos), sorted by distance to self.\n",
    "        The 0th star is the closest.\n",
    "\n",
    "        otherstarlist is not modified.\n",
    "        \"\"\"\n",
    "\n",
    "        returnlist = []\n",
    "        for i, star in enumerate(otherstarlist):\n",
    "            dist = self.distance(star)\n",
    "            returnlist.append({'dot': star, 'dist': dist, 'origpos': i})\n",
    "        returnlist = sorted(returnlist, key=operator.itemgetter('dist'))  # sort stars according to dist\n",
    "\n",
    "        return returnlist\n",
    "\n",
    "# And now some functions to manipulate list of such stars ###\n",
    "\n",
    "\n",
    "def listtoarray(starlist, full=False):\n",
    "    \"\"\"\n",
    "    Transforms the starlist into a 2D numpy array for fast manipulations.\n",
    "    First index is star, second index is x or y\n",
    "\n",
    "    :param full: If True, I also include flux, fwhm, elon\n",
    "    :type full: boolean\n",
    "\n",
    "    \"\"\"\n",
    "    return np.array([star.coords(full=full) for star in starlist])\n",
    "\n",
    "\n",
    "def area(dotlist, border=0.01):\n",
    "    \"\"\"\n",
    "    Returns the area covered by the dots.\n",
    "    Border is relative to max-min\n",
    "    \"\"\"\n",
    "    if len(dotlist) == 0:\n",
    "        return np.array([0, 1, 0, 1])\n",
    "\n",
    "    if len(dotlist) == 1:\n",
    "        dot = dotlist[0]\n",
    "        return np.array([dot.x - 0.5, dot.x + 0.5, dot.y - 0.5, dot.y + 0.5])\n",
    "\n",
    "    a = listtoarray(starlist)\n",
    "    (xmin, xmax) = (np.min(a[:, 0]), np.max(a[:, 0]))\n",
    "    (ymin, ymax) = (np.min(a[:, 1]), np.max(a[:, 1]))\n",
    "    xw = xmax - xmin\n",
    "    yw = ymax - ymin\n",
    "    xmin = xmin - border*xw\n",
    "    xmax = xmax + border*xw\n",
    "    ymin = ymin - border*yw\n",
    "    ymax = ymax + border*yw\n",
    "    return np.array([xmin, xmax, ymin, ymax])\n",
    "\n",
    "\n",
    "class Quad:\n",
    "    \"\"\"\n",
    "    A geometric \"hash\", or asterism, as used in Astrometry.net :\n",
    "    http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:0910.2233\n",
    "    It is made out of 4 stars, and it is shift / scale / rotation invariant\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fourstars):\n",
    "        \"\"\"\n",
    "        fourstars is a list of four stars\n",
    "\n",
    "        We make the following attributes :\n",
    "        self.hash\n",
    "        self.stars (in the order A, B, C, D)\n",
    "\n",
    "        \"\"\"\n",
    "        assert len(fourstars) == 4\n",
    "\n",
    "        tests = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "        other = [(2, 3), (1, 3), (1, 2), (0, 3), (0, 2), (0, 1)]\n",
    "        dists = np.array([fourstars[i].distance(fourstars[j]) for (i, j) in tests])\n",
    "        assert np.min(dists) > 1.0\n",
    "\n",
    "        maxindex = np.argmax(dists) # Returns the indices of the maximum values along an axis\n",
    "        (Ai, Bi) = tests[maxindex]  # Indexes of stars A and B\n",
    "        (Ci, Di) = other[maxindex]  # Indexes of stars C and D\n",
    "        \n",
    "        A = fourstars[Ai]\n",
    "        B = fourstars[Bi]\n",
    "        C = fourstars[Ci]\n",
    "        D = fourstars[Di]\n",
    "\n",
    "        # We look for matrix transform [[a -b], [b a]] + [c d] that brings A and B to 00 11 :\n",
    "        \n",
    "        \n",
    "        x = B.x - A.x\n",
    "        if x == 0:\n",
    "            x = x+0.01\n",
    "        y = B.y - A.y\n",
    "        b = (x-y)/(x*x + y*y)\n",
    "        a = (1.0/x) * (1.0 + b*y)\n",
    "        c = b*A.y - a*A.x\n",
    "        d = - (b*A.x + a*A.y)\n",
    "\n",
    "        t = star.SimpleTransform((a, b, c, d))\n",
    "\n",
    "        (xC, yC) = t.apply(C.x, C.y)\n",
    "        (xD, yD) = t.apply(D.x, D.y)\n",
    "\n",
    "        # Normal case\n",
    "        self.hash = (xC, yC, xD, yD)\n",
    "\n",
    "        # Break symmetries :\n",
    "        testa = xC > xD\n",
    "        testb = xC + xD > 1\n",
    "\n",
    "        if testa and not testb:  # we switch C and D\n",
    "            self.hash = (xD, yD, xC, yC)\n",
    "            (C, D) = (D, C)\n",
    "\n",
    "        if testb and not testa:  # We switch A and B\n",
    "            self.hash = (1.0-xD, 1.0-yD, 1.0-xC, 1.0-yC)\n",
    "            (A, B) = (B, A)\n",
    "            (C, D) = (D, C)\n",
    "\n",
    "        if testa and testb:\n",
    "            self.hash = (1.0-xC, 1.0-yC, 1.0-xD, 1.0-yD)\n",
    "            (A, B) = (B, A)\n",
    "\n",
    "        # Checks :\n",
    "        assert self.hash[0] <= self.hash[2]\n",
    "        assert self.hash[0] + self.hash[2] <= 1\n",
    "\n",
    "        self.stars = [A, B, C, D]  # Order might be different from the fourstars !\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Hash : %6.3f %6.3f %6.3f %6.3f \" % (\n",
    "            self.hash[0], self.hash[1], self.hash[2], self.hash[3])\n",
    "\n",
    "    \n",
    "def distance(self, otherstar):\n",
    "        \"\"\"\n",
    "        Returns the distance between the two stars.\n",
    "        \"\"\"\n",
    "        return math.sqrt(np.sum((self.coords() - otherstar.coords())**2))\n",
    "\n",
    "def mindist(fourstars):\n",
    "    \"\"\"\n",
    "    Function that tests if 4 stars are suitable to make a good quad...\n",
    "    \"\"\"\n",
    "    tests = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "    dists = np.array([fourstars[i].distance(fourstars[j]) for (i, j) in tests])\n",
    "    return np.min(dists)\n",
    "\n",
    "\n",
    "\n",
    "def makequads1(center_coord, n=10, s=0, d=10, verbose=True):\n",
    "    \"\"\"\n",
    "    First trivial quad maker.\n",
    "    Makes combis of the n brightest stars.\n",
    "\n",
    "    :param n: number of stars to consider (brightest ones).\n",
    "    :type n: int\n",
    "    :param s: how many of the brightest stars should I skip ?\n",
    "        This feature is useful to avoid building quads with nearly saturated stars that are not\n",
    "        available in other exposures.\n",
    "    :type s: int\n",
    "    :param d: minimal distance between stars\n",
    "    :type d: float\n",
    "\n",
    "    \"\"\"\n",
    "    quadlist = []\n",
    "     \n",
    "\n",
    "    for fourdots in itertools.combinations(center_coord[s:s+n], 4):\n",
    "        if mindist(fourdots) > d:\n",
    "                quadlist.append(Quad(fourdots))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Made %4i quads from %4i stars (combi n=%i s=%i d=%.1f)\" % (len(quadlist), len(center_coord), n, s, d))\n",
    "\n",
    "    return quadlist\n",
    "\n",
    "def makequads2(dotlist, f=5.0, n=6, s=0, d=50.0, verbose=True):\n",
    "    \"\"\"\n",
    "    Similar, but fxf in subareas roughly f times smaller than the full frame.\n",
    "    s allows to skip the brightest stars in each region\n",
    "\n",
    "    :param f: smallness of the subareas\n",
    "    :type f: float\n",
    "    :param n: number of stars to consider in each subarea\n",
    "    :type n: int\n",
    "    :param d: minimal distance between stars\n",
    "    :type d: float\n",
    "    :param s: number of brightest stars to skip in each subarea\n",
    "    :type s: int\n",
    "\n",
    "    \"\"\"\n",
    "    quadlist = []\n",
    "    \n",
    "    (xmin, xmax, ymin, ymax) = star.area(dotlist)\n",
    "\n",
    "    r = 2.0 * max(xmax - xmin, ymax - ymin) / f\n",
    "\n",
    "    for xc in np.linspace(xmin, xmax, int(f)+2)[1:-1]:\n",
    "        for yc in np.linspace(ymin, ymax, int(f)+2)[1:-1]:\n",
    "            dot = Dots(x=xc, y=yc)\n",
    "            das = dot.distanceandsort(dotlist)\n",
    "            elmnt = [element[\"dot\"] for element in das if element[\"dist\"] <= r]\n",
    "            brightestwithinr = elmnt[s:s+n]\n",
    "            for fourstars in itertools.combinations(brightestwithinr, 4):\n",
    "                if mindist(fourstars) > d:\n",
    "                    quadlist.append(Quad(fourstars))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Made %4i quads from %4i stars (combi sub f=%.1f n=%i s=%i d=%.1f)\" % (len(quadlist), len(dotlist),\n",
    "                                                                                     f, n, s, d))\n",
    "    return quadlist\n",
    "\n",
    "\n",
    "class ImgCat:\n",
    "    \"\"\"\n",
    "    Represent an individual image and its associated catalog, starlist, quads etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, centers):\n",
    "        \"\"\"\n",
    "\n",
    "        :param filepath: Path to the FITS file, or alternatively just a string to identify the image.\n",
    "        :type filepath: string\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        self.filepath = 'default'\n",
    "#         print (self.filepath)\n",
    "#         (imgdir, filename) = path.split(filepath)\n",
    "#         (common, ext) = path.splitext(filename)\n",
    "        self.name = 'default'\n",
    "\n",
    "       \n",
    "        self.dotlist = []\n",
    "        for row in centers: \n",
    "            self.dotlist.append(Dots(row[0], row[1]))      \n",
    "        (xmin, xmax, ymin, ymax) = star.area(self.dotlist, border=0.01)\n",
    "        self.xlim = (xmin, xmax)\n",
    "        self.ylim = (ymin, ymax)\n",
    "        \n",
    "        self.mindist = 0.0\n",
    "        self.xlim = (0.0, 0.0)  # Will be set using the catalog -- no need for the FITS image.\n",
    "        self.ylim = (0.0, 0.0)\n",
    "\n",
    "        self.quadlist = []\n",
    "        self.quadlevel = 0  # encodes what kind of quads have already been computed\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%20s: approx %4i x %4i, %4i stars, %4i quads, quadlevel %i\" % (path.basename(self.filepath),\n",
    "                                                                               self.xlim[1] - self.xlim[0],\n",
    "                                                                               self.ylim[1] - self.ylim[0],\n",
    "                                                                               len(self.starlist), len(self.quadlist),\n",
    "                                                                               self.quadlevel)\n",
    "\n",
    "    def makemorequads(self, verbose=True):\n",
    "        \"\"\"\n",
    "        We add more quads, following the quadlevel.\n",
    "        \"\"\"\n",
    "        # if not add:\n",
    "        #    self.quadlist = []\n",
    "        if verbose:\n",
    "            print(\"Making more quads, from quadlevel %i ...\" % self.quadlevel)\n",
    "        if self.quadlevel == 0:\n",
    "            self.quadlist.extend(makequads1(self.dotlist, n=10, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 1:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=3, n=10, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 2:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=6, n=10, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 3:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=12, n=10, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 4:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=15, n=10, s=0, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 5:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=18, n=10, s=0, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 6:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=21, n=10, s=0, d=self.mindist, verbose=verbose))\n",
    "        elif self.quadlevel == 7:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=24, n=10, s=0, d=self.mindist, verbose=verbose))  \n",
    "        elif self.quadlevel == 8:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=27, n=10, s=0, d=self.mindist, verbose=verbose))  \n",
    "        elif self.quadlevel == 9:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=30, n=10, s=0, d=self.mindist, verbose=verbose)) \n",
    "        elif self.quadlevel == 10:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=33, n=10, s=0, d=self.mindist, verbose=verbose))   \n",
    "        elif self.quadlevel == 11:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=36, n=10, s=0, d=self.mindist, verbose=verbose))  \n",
    "        elif self.quadlevel == 12:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=39, n=10, s=0, d=self.mindist, verbose=verbose))    \n",
    "        elif self.quadlevel == 13:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=42, n=10, s=0, d=self.mindist, verbose=verbose)) \n",
    "        elif self.quadlevel == 14:\n",
    "            self.quadlist.extend(makequads2(self.dotlist, f=45, n=10, s=0, d=self.mindist, verbose=verbose)) \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        self.quadlist = removeduplicates(self.quadlist, verbose=verbose)\n",
    "        self.quadlevel += 1\n",
    "        return True\n",
    "    \n",
    "def removeduplicates(quadlist, verbose=True):\n",
    "    \"\"\"\n",
    "    Returns a quadlist without quads with identical hashes...\n",
    "    \"\"\"\n",
    "    # To avoid crash in lexsort if quadlist is too small :\n",
    "    if len(quadlist) < 2:\n",
    "        return quadlist\n",
    "    hasharray = np.array([q.hash for q in quadlist])\n",
    "\n",
    "    order = np.lexsort(hasharray.T)\n",
    "    hasharray = hasharray[order]\n",
    "    diff = np.fabs(np.diff(hasharray, axis=0))\n",
    "    ui = np.ones(len(hasharray), 'bool')\n",
    "    ui[1:] = (diff >= 0.000001).any(axis=1)\n",
    "    if verbose:\n",
    "        print(\"Removing %i/%i duplicates\" % (len(quadlist) - np.sum(ui), len(quadlist)))\n",
    "\n",
    "    return [quad for (quad, u) in zip(quadlist, ui) if u]\n",
    "def quadtrans(uknquad, refquad):\n",
    "    \"\"\"\n",
    "    Quickly return a transform estimated from the stars A and B of two quads.\n",
    "    \"\"\"\n",
    "    return star.fitstars(uknquad.stars[:2], refquad.stars[:2])\n",
    "\n",
    "\n",
    "\n",
    "class Identification:\n",
    "    \"\"\"\n",
    "    Represents the identification of a transform between two ImgCat objects.\n",
    "    Regroups all the star catalogs, the transform, the quads, the candidate, etc.\n",
    "\n",
    "    All instance attributes are listed below.\n",
    "\n",
    "    :ivar ref: ImgCat object of the reference image\n",
    "    :ivar ukn: ImgCat object of the unknown image\n",
    "    :ivar ok: boolean, True if the idendification was successful.\n",
    "    :ivar trans: The SimpleTransform object that represents the geometrical transform from ukn to ref.\n",
    "    :ivar uknmatchstars: A list of Star objects of the catalog of the unknown image...\n",
    "    :ivar refmatchstars: ... that correspond to these Star objects of the reference image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ref, ukn):\n",
    "        \"\"\"\n",
    "        :param ref: The reference image\n",
    "        :type ref: ImgCat object\n",
    "        :param ukn: The unknown image, whose transform will be adjusted to match the ref\n",
    "        :type ukn: ImgCat object\n",
    "        \"\"\"\n",
    "        self.ref = ref\n",
    "        self.ukn = ukn\n",
    "\n",
    "        self.ok = False\n",
    "\n",
    "        self.trans = None\n",
    "        self.uknmatchstars = []\n",
    "        self.refmatchstars = []\n",
    "        self.cand = None\n",
    "\n",
    "    def findtrans(self, r=5.0, verbose=False):\n",
    "        \"\"\"\n",
    "        Find the best trans given the quads, and tests if the match is sufficient\n",
    "        \"\"\"\n",
    "\n",
    "        # Some robustness checks\n",
    "        if len(self.ref.dotlist) < 4:\n",
    "            if verbose:\n",
    "                print(\"Not enough dot in the reference catalog.\")\n",
    "            return\n",
    "        if len(self.ukn.dotlist) < 4:\n",
    "            if verbose:\n",
    "                print(\"Not enough dot in the unknown catalog.\")\n",
    "            return\n",
    "\n",
    "        # First question : how many stars should match ?\n",
    "        if len(self.ukn.dotlist) < 5:  # Then we should simply try to get the smallest distance...\n",
    "            minnident = 4\n",
    "        else:\n",
    "            minnident = max(4, min(8, len(self.ukn.dotlist)/5.0))  # Perfectly arbitrary, let's see how it works\n",
    "\n",
    "        # Hmm, arbitrary for now :\n",
    "        minquaddist = 0.02\n",
    "\n",
    "        # Let's start :\n",
    "        if self.ref.quadlevel == 0:\n",
    "            self.ref.makemorequads(verbose=verbose)\n",
    "        if self.ukn.quadlevel == 0:\n",
    "            self.ukn.makemorequads(verbose=verbose)\n",
    "\n",
    "        while self.ok is False:\n",
    "            # Find the best candidates\n",
    "            cands = proposecands(self.ukn.quadlist, self.ref.quadlist, n=4, verbose=verbose)\n",
    "\n",
    "            if len(cands) != 0 and cands[0][\"dist\"] < minquaddist:\n",
    "                # If no quads are available, we directly try to make more ones.\n",
    "                for cand in cands:\n",
    "                    # Check how many stars are identified...\n",
    "                    nident = star.identify(self.ukn.dotlist, self.ref.dotlist, trans=cand[\"trans\"],\n",
    "                                           r=r, verbose=verbose, getstars=False)\n",
    "                    if nident >= minnident:\n",
    "                        self.trans = cand[\"trans\"]\n",
    "                        self.cand = cand\n",
    "                        self.ok = True\n",
    "                        break  # get out of the for\n",
    "\n",
    "            if self.ok is False:\n",
    "                # We add more quads...\n",
    "                addedmorerefquads = self.ref.makemorequads(verbose=verbose)\n",
    "                addedmoreuknquads = self.ukn.makemorequads(verbose=verbose)\n",
    "\n",
    "                if addedmorerefquads is False and addedmoreuknquads is False:\n",
    "                    break  # get out of the while, we failed.\n",
    "\n",
    "        #if  ((self.ok) and (abs(self.trans.getrotation()))<5):  # we refine the transform\n",
    "        if  (self.ok) :\n",
    "            # get matching stars :\n",
    "            (self.uknmatchstars, self.refmatchstars) = star.identify(self.ukn.dotlist, self.ref.dotlist,\n",
    "                                                                     trans=self.trans, r=r, verbose=False,\n",
    "                                                                     getstars=True)\n",
    "            # refit the transform on them :\n",
    "            if verbose:\n",
    "                print(\"Refitting transform (before/after) :\")\n",
    "                print(self.trans)\n",
    "            newtrans = star.fitstars(self.uknmatchstars, self.refmatchstars)\n",
    "            if newtrans is not None:\n",
    "                self.trans = newtrans\n",
    "                if verbose:\n",
    "                    print(self.trans)\n",
    "            # Generating final matched star lists :\n",
    "            (self.uknmatchstars, self.refmatchstars) = star.identify(self.ukn.dotlist, self.ref.dotlist,\n",
    "                                                                     trans=self.trans, r=r, verbose=verbose,\n",
    "                                                                     getstars=True)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"I'm done!\")\n",
    "\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to find transform!\")\n",
    "\n",
    " \n",
    "def run(ref, ukns, skipsaturated=False, r=5.0, n=500, sexkeepcat=False, sexrerun=True,\n",
    "        verbose=False, polarMode=None, refpolar=False, camera=None):\n",
    "    \"\"\"\n",
    "    Top-level function to identify transorms between images.\n",
    "    Returns a list of Identification objects that contain all the info to go further.\n",
    "\n",
    "    :param ref: coordinates of beads in a reference image.\n",
    "    :type ref: np.array(:,2)\n",
    "\n",
    "    :param ukns: coordinates of beads in an unknown image.\n",
    "    :type ukns: np.array(:,2)\n",
    "\n",
    "    :param hdu: The hdu of the fits files (same for all) that you want me to use. 0 is somehow \"automatic\".\n",
    "    If multihdu, 1 is usually science.\n",
    "\n",
    "    if the identification fails).\n",
    "\n",
    "    :param skipsaturated: Should I skip saturated stars ?\n",
    "    :type skipsaturated: boolean\n",
    "\n",
    "    :param r: Identification radius in pixels of the reference image (default 5.0 should be fine).\n",
    "    :type r: float\n",
    "    :param n: Number of brightest stars of each image to consider (default 500 should be fine).\n",
    "    :type n: int\n",
    "\n",
    "    :param sexkeepcat: Put this to True if you want me to keep the SExtractor catalogs (in a dir \"alipy_cats\").\n",
    "    :type sexkeepcat: boolean\n",
    "    :param sexrerun: Put this to False if you want me to check if I have some previously kept catalogs\n",
    "    (with sexkeepcat=True), instead of running SExtractor again on the images.\n",
    "    :type sexrerun: boolean\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(10*\"#\", \" Preparing reference ...\")\n",
    "    ref = ImgCat(ref)\n",
    "    \n",
    "    ref.makemorequads(verbose=verbose)\n",
    "\n",
    "    identifications = []\n",
    "\n",
    "   \n",
    "\n",
    "    if verbose:\n",
    "            print(10*\"#\", \"Processing %s\" % (ukns))\n",
    "\n",
    "    ukn = ImgCat(ukns)\n",
    "        \n",
    "    idn = Identification(ref, ukn)\n",
    "    idn.findtrans(verbose=verbose, r=r)\n",
    "    identifications.append(idn)\n",
    "\n",
    "    return identifications\n",
    "\n",
    "def identify(uknstars, refstars, trans=None, r=5.0, verbose=True, getstars=False):\n",
    "    \"\"\"\n",
    "    Allows to:\n",
    "     * get the number or matches, i.e. evaluate the quality of the trans\n",
    "     * get corresponding stars from both lists (without the transform applied)\n",
    "\n",
    "    :param getstars: If True, I return two lists of corresponding stars, instead of just the number of matching stars\n",
    "    :type getstars: boolean\n",
    "\n",
    "    Inspired by the \"formpairs\" of alipy 1.0 ...\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if trans is not None:\n",
    "        ukn = listtoarray(trans.applystarlist(uknstars))\n",
    "    else:\n",
    "        ukn = listtoarray(uknstars)\n",
    "    ref = listtoarray(refstars)\n",
    "\n",
    "    dists = scipy.spatial.distance.cdist(ukn, ref)  # Big table of distances between ukn and ref\n",
    "    mindists = np.min(dists, axis=1)  # For each ukn, the minimal distance\n",
    "    minok = mindists <= r  # booleans for each ukn\n",
    "    minokindexes = np.argwhere(minok).flatten()  # indexes of uknstars with matches\n",
    "\n",
    "    if verbose:\n",
    "        print(\"%i/%i stars with distance < r = %.1f (mean %.1f, median %.1f, std %.1f)\" % (np.sum(minok),\n",
    "                                                                                           len(uknstars), r,\n",
    "                                                                                           np.mean(mindists[minok]),\n",
    "                                                                                           np.median(mindists[minok]),\n",
    "                                                                                           np.std(mindists[minok])))\n",
    "    matchuknstars = []\n",
    "    matchrefstars = []\n",
    "\n",
    "    for i in minokindexes:  # we look for the second nearest ...\n",
    "        sortedrefs = np.argsort(dists[i, :])\n",
    "        firstdist = dists[i, sortedrefs[0]]\n",
    "        seconddist = dists[i, sortedrefs[1]]\n",
    "        if seconddist > 2.0*firstdist:  # Then the situation is clear, we keep it.\n",
    "            matchuknstars.append(uknstars[i])\n",
    "            matchrefstars.append(refstars[sortedrefs[0]])\n",
    "        else:\n",
    "            pass  # Then there is a companion, we skip it.\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Filtered for companions, keeping %i/%i matches\" % (len(matchuknstars), np.sum(minok)))\n",
    "\n",
    "    if getstars is True:\n",
    "        return (matchuknstars, matchrefstars)\n",
    "    else:\n",
    "        return len(matchuknstars)\n",
    "\n",
    "    \n",
    "def find_max (x,y, arr):\n",
    "    \n",
    "#     print(np.shape(arr))\n",
    "#     print((arr))\n",
    "    max_elem = -1\n",
    "    for i in range(x-5, x+6):\n",
    "        for j in range(y-5, y+6):\n",
    "            if arr[j][i] > max_elem:\n",
    "                max_elem =  arr[j][i]\n",
    "\n",
    "    list_index_max =[(i,j) for i in range(x-5, x+6)  for j in range(y-5, y+6) if arr[j][i]  == max_elem]\n",
    "    line, column = list_index_max[0]\n",
    "    return(line, column)\n",
    "#https://www.geeksforgeeks.org/displaying-the-coordinates-of-the-points-clicked-on-the-image-using-python-opencv/  \n",
    "# function to display the coordinates of  of the points clicked on the image\n",
    "\n",
    "def click_event_FRET(event, x, y, flags, params):\n",
    "    global counter\n",
    "    global FRET_coord\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:   # checking for left mouse clicks   \n",
    "        x_max,y_max = find_max(x,y,image_array_F)\n",
    "#         print(x_max, y_max)\n",
    "        FRET_coord.append(x_max) \n",
    "        FRET_coord.append(y_max)\n",
    "        cv2.circle(better_contrast_img, (x_max, y_max), 4, (0, 0, 127), 2)\n",
    "        counter+=1    \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        counter = 0\n",
    "        green_coord.clear()\n",
    "        red_coord.clear()\n",
    "        \n",
    "def click_event_seq(event, x, y, flags, params):\n",
    "    global counter\n",
    "    global seq_coord\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:   # checking for left mouse clicks   \n",
    "        x_max,y_max = find_max(x,y,image_array_seq_t)\n",
    "#         print(x_max, y_max)\n",
    "        seq_coord.append(x_max) \n",
    "        seq_coord.append(y_max)\n",
    "        cv2.circle(better_contrast_img_2, (x_max, y_max), 4, (0, 0, 127), 2)\n",
    "        counter+=1   \n",
    "    if event==cv2.EVENT_RBUTTONDOWN:\n",
    "        counter = 0\n",
    "        green_coord.clear()\n",
    "        red_coord.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative version of figuring out the displacement\n",
    "file_path = fd.askopenfilename(title = \"Choose the position list\")\n",
    "\n",
    "pos_file = open(file_path)\n",
    "data = json.load(pos_file)\n",
    "POS = data['POSITIONS']\n",
    "\n",
    "labels = [P['LABEL'] for P in POS]\n",
    "posX = [P['DEVICES'][1]['X'] for P in POS]\n",
    "posY = [P['DEVICES'][1]['Y'] for P in POS]\n",
    "# print(min(posX), max(posX), min(posY), max(posY))\n",
    "upper_left_um_x = min(posX)\n",
    "upper_left_um_y = max(posY)\n",
    "\n",
    "\n",
    "#2023-01-26 Tile 1\n",
    "# coords_t_seq = np.array([1537.5,1398]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([6335,1470.5])\n",
    "\n",
    "#2023-01-26 Tile 2\n",
    "# coords_t_seq = np.array([1447.4,1449.7]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3118.5,1499.8])\n",
    "\n",
    "\n",
    "\n",
    "#2023-01-23 Tile 1\n",
    "# coords_t_seq = np.array([1505.5,1481.8]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([6893.9,1298.6])\n",
    "\n",
    "#2023-01-23 Tile 2\n",
    "# coords_t_seq = np.array([829,1559.8]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3111.6,1353.6])\n",
    "\n",
    "#2022-12-27 Tile 1\n",
    "# coords_t_seq = np.array([1451.532,1204.410]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3739.046,1271.476])\n",
    "\n",
    "#2022-12-27 Tile 2\n",
    "# coords_t_seq = np.array([2577.568,1054.075]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([1751.353,1126.065])\n",
    "\n",
    "#2023-01-16 Tile 1\n",
    "# coords_t_seq = np.array([2067,348]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([8813, 785]) \n",
    "#2023-01-16 Tile 2\n",
    "# coords_t_seq = np.array([986,888]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([4644, 1300]) \n",
    "\n",
    "#2023-01-17 Tile 1\n",
    "# coords_t_seq = np.array([1525.5,1810.6]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([7238, 970.6]) \n",
    "#2023-01-17 Tile 2\n",
    "# coords_t_seq = np.array([1333.4,1987.6]) #Insert matching bead coordinates here manually!\n",
    "# coords_t_FRET = np.array([3971.3, 1154.7]) \n",
    "\n",
    "\n",
    "[deltax, deltay] = np.subtract(coords_t_seq,coords_t_FRET)\n",
    "print(deltax,deltay)\n",
    "print(upper_left_um_x, upper_left_um_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial match smFRET vs Seq\n",
    "# deltax = 4660 # for tile 1 220815\n",
    "# deltay = -25\n",
    "# upper_left_um_x = 26091.3\n",
    "# upper_left_um_y = -690\n",
    "# Select library sequences from the FASTQ data\n",
    "def library_index(template, strings, min_matches):\n",
    "    row_sums = [sum(a == b for a, b in zip(row, template)) for row in strings]\n",
    "    # Create the index of elements from Seq where row_sums is above the threshold\n",
    "    index = [i for i, row_sum in enumerate(row_sums) if row_sum > min_matches]\n",
    "    return index\n",
    "\n",
    "def get_pos(record):\n",
    "    \n",
    "    des = record.description\n",
    "    tile_num = int(des.split(' ')[0].split(':')[4])\n",
    "    x_pos = int(des.split(' ')[0].split(':')[5])\n",
    "    y_pos = int(des.split(' ')[0].split(':')[6])\n",
    "    return tile_num, x_pos, y_pos\n",
    "\n",
    "\n",
    "def generate_img(x, y, x_min, y_min, x_max, y_max, r, blurred, sigma):\n",
    "    # x_min = min(x)\n",
    "    # x_max = max(x)\n",
    "    # y_min = min(y)\n",
    "    # y_max = max(y)\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    # x_range = 27994\n",
    "    # y_range = 27174\n",
    "    img = np.zeros(shape=(x_range, y_range))\n",
    "    for i in range(0, len(x)):\n",
    "        img[min(x_range-1,max(0,int(x[i]-r))):min(x_range-1,max(0,int(x[i]+r+1))),min(y_range-1,max(0,int(y[i]-r))):min(y_range-1,max(0,int(y[i]+r+1)))] = 200\n",
    "\n",
    "    if blurred:\n",
    "        img = gaussian(img, sigma=sigma)\n",
    "    im = Image.fromarray(img)\n",
    "    new_im = im.convert(\"L\")\n",
    "#     new_im.save(op_path)\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def generate_with_marker(x, y, marker_x, marker_y, op_path, csv_path):\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    y_min = min(y)\n",
    "    y_max = max(y)\n",
    "    x_range = x_max - x_min + 1\n",
    "    y_range = y_max - y_min + 1\n",
    "    img = np.zeros(shape=(x_range, y_range, 3))\n",
    "    marker_dic = {'index': range(0, len(marker_x)), 'x': [], 'y': []}\n",
    "    for i in range(0, len(x)):\n",
    "        for j in range(0, 5):\n",
    "            for k in range(0, 5):\n",
    "                img[max(0, x[i] - x_min - j),\n",
    "                    max(0, y[i] - y_min - k), 0:3] = 255\n",
    "                img[min(x_range - 1, x[i] - x_min + j),\n",
    "                    max(0, y[i] - y_min - k), 0:3] = 255\n",
    "                img[min(x_range - 1, x[i] - x_min + j),\n",
    "                    min(y_range - 1, y[i] - y_min + k), 0:3] = 255\n",
    "                img[max(0, x[i] - x_min - j),\n",
    "                    min(y_range - 1, y[i] - y_min + k), 0:3] = 255\n",
    "    for i in range(0, len(marker_x)):\n",
    "        marker_dic['x'].append(marker_x[i] - x_min)\n",
    "        marker_dic['y'].append(marker_y[i] - y_min)\n",
    "        for j in range(0, 5):\n",
    "            for k in range(0, 5):\n",
    "                img[max(0, marker_x[i] - x_min - j),\n",
    "                    max(0, marker_y[i] - y_min - k), 0] = 255\n",
    "                img[max(0, marker_x[i] - x_min - j),\n",
    "                    max(0, marker_y[i] - y_min - k), 1:3] = 0\n",
    "                img[min(x_range - 1, marker_x[i] - x_min + j),\n",
    "                    max(0, marker_y[i] - y_min - k), 0] = 255\n",
    "                img[min(x_range - 1, marker_x[i] - x_min + j),\n",
    "                    max(0, marker_y[i] - y_min - k), 1:3] = 0\n",
    "                img[min(x_range - 1, marker_x[i] - x_min + j),\n",
    "                    min(y_range - 1, marker_y[i] - y_min + k), 0] = 255\n",
    "                img[min(x_range - 1, marker_x[i] - x_min + j),\n",
    "                    min(y_range - 1, marker_y[i] - y_min + k), 1:3] = 0\n",
    "                img[max(0, marker_x[i] - x_min - j),\n",
    "                    min(y_range - 1, marker_y[i] - y_min + k), 0] = 255\n",
    "                img[max(0, marker_x[i] - x_min - j),\n",
    "                    min(y_range - 1, marker_y[i] - y_min + k), 1:3] = 0\n",
    "    blurred_img = gaussian(img, sigma=3, multichannel=True)\n",
    "    im = Image.fromarray(blurred_img.astype(np.uint8))\n",
    "    new_im = im.convert(\"P\")\n",
    "    new_im.save(op_path)\n",
    "    df = pd.DataFrame(marker_dic)\n",
    "    df.to_csv(csv_path, index=True, header=True)\n",
    "\n",
    "\n",
    "def get_coordinates(fastq_path):\n",
    "    x_coordinate_01 = []\n",
    "    y_coordinate_01 = []\n",
    "    x_coordinate_02 = []\n",
    "    y_coordinate_02 = []\n",
    "    for record in SeqIO.parse(fastq_path, \"fastq\"):\n",
    "        if record is not None:\n",
    "            tile_num, x_pos, y_pos = get_pos(record)\n",
    "            seq = str(record.seq)\n",
    "            if tile_num == 1101:\n",
    "                x_coordinate_01.append(x_pos)\n",
    "                y_coordinate_01.append(y_pos)\n",
    "            elif tile_num == 1102:\n",
    "                x_coordinate_02.append(x_pos)\n",
    "                y_coordinate_02.append(y_pos)\n",
    "#     print('Coordinates are found.')\n",
    "    return x_coordinate_01, y_coordinate_01, x_coordinate_02, y_coordinate_02\n",
    "\n",
    "\n",
    "def get_xy_coordinates(fastq_path, with_seq):\n",
    "    x_coordinate_01 = []\n",
    "    y_coordinate_01 = []\n",
    "    x_coordinate_02 = []\n",
    "    y_coordinate_02 = []\n",
    "    x_seq_coordinate_01 = []\n",
    "    y_seq_coordinate_01 = []\n",
    "    x_seq_coordinate_02 = []\n",
    "    y_seq_coordinate_02 = []\n",
    "    for record in SeqIO.parse(fastq_path, \"fastq\"):\n",
    "        if record is not None:\n",
    "            tile_num, x_pos, y_pos = get_pos(record)\n",
    "            seq = str(record.seq)\n",
    "            if tile_num == 1101:\n",
    "                if with_seq != seq:\n",
    "                    x_coordinate_01.append(x_pos)\n",
    "                    y_coordinate_01.append(y_pos)\n",
    "                else:\n",
    "                    x_seq_coordinate_01.append(x_pos)\n",
    "                    y_seq_coordinate_01.append(y_pos)\n",
    "            elif tile_num == 1102:\n",
    "                if with_seq != seq:\n",
    "                    x_coordinate_02.append(x_pos)\n",
    "                    y_coordinate_02.append(y_pos)\n",
    "                else:\n",
    "                    x_seq_coordinate_02.append(x_pos)\n",
    "                    y_seq_coordinate_02.append(y_pos)\n",
    "#     print('Coordinates are found.')\n",
    "    return x_coordinate_01, y_coordinate_01, \\\n",
    "        x_coordinate_02, y_coordinate_02, \\\n",
    "        x_seq_coordinate_01, y_seq_coordinate_01, \\\n",
    "        x_seq_coordinate_02, y_seq_coordinate_02\n",
    "\n",
    "\n",
    "def get_seq_coordinates(fastq_path, tile):\n",
    "    x_coordinate = []\n",
    "    y_coordinate = []\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fastq_path, \"fastq\"):\n",
    "        if record is not None:\n",
    "            tile_num, x_pos, y_pos = get_pos(record)\n",
    "            seq = str(record.seq)\n",
    "            if tile_num == tile:\n",
    "                x_coordinate.append(x_pos/10)\n",
    "                y_coordinate.append(y_pos/10)\n",
    "                sequences.append(seq)\n",
    "#     print('Coordinates are found.')\n",
    "    return x_coordinate, y_coordinate, sequences\n",
    "\n",
    "def scaling_seq (x, y):\n",
    "    \n",
    "    x = int(deltax+(335-x_border)/2 + (x - upper_left_um_x)/0.34) # tile 2 06/09/2022;\n",
    "    y = int(deltay+(150-y_border)/2  - (y - upper_left_um_y)/0.34)  # 305 and 154 are the size of tfd 512 by 256 image\n",
    "#     \n",
    "#     x = int(-850+(305-x_border)/2 + (x - 26384)/0.34) # tile 2 06/09/2022;\n",
    "#     y = int(-385+(154-y_border)/2  - (y + 407.1)/0.34)  # 305 and 154 are the size of tfd 512 by 256 image\n",
    "#     x = int(-3967+(305-x_border)/2 + (x - 26384)/0.34) # tile 1 06/09/2022; \n",
    "#     y = int(-405+(154-y_border)/2  - (y + 407.1)/0.34)   \n",
    "\n",
    "#     x = int(1700+(330-x_border)/2  + (x - 27246.18)/0.34 ) ### tile 2 19/07/2022\n",
    "#     y = int(1571+(170-y_border)/2 - (y + 1149.66)/0.34)\n",
    "#     x = int(2329+(330-x_border)/2 + (x - 28522.9)/0.34)  ### tile 1 19/07/2022\n",
    "#     y = int(2042+(170-y_border)/2 - (y + 1313.3)/0.34)\n",
    "\n",
    "    \n",
    "    \n",
    "    return (x,y)\n",
    "    \n",
    "\n",
    "def blob_detection(img, min_sigma, max_sigma, threshold, method=0):\n",
    "    \"\"\"This function is mostly used for detecting the beads in any image.\n",
    "\n",
    "    Args:\n",
    "        img_path (string): The absolute path of the input image.\n",
    "        min_sigma (int): The minimum sigma, lower it is, smaller the blob will be detected.\n",
    "        max_sigma (int): The maximum sigma, higher it is, bigger the blob will be detected.\n",
    "        threshold (float): Higher it is, higher the intensities of blobs.\n",
    "        method (int, optional): 0 for Difference of Gaussian (DoG) and 1 for Determinant of Hessian (DoH). \n",
    "        They should be applied with different combination of parameters. DoG is more suitable for fret movies,\n",
    "        while DoH is more suitable for sequencing images. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        centers: A numpy array containing the coordinates of all the centers.\n",
    "    \"\"\"\n",
    "    #img = io.imread(img_path)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    if method == 0:\n",
    "        blob = blob_dog(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    else:\n",
    "        blob = blob_doh(\n",
    "            img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold\n",
    "        )\n",
    "    i = 0\n",
    "    r = 3\n",
    "    centers = []\n",
    "    h, w = img.shape\n",
    "    for blob in blob:\n",
    "        y, x, r = blob\n",
    "        if y > r and y < (h - r) and x > r and x < (w - r):\n",
    "            centers.append(\n",
    "                ndimage.measurements.center_of_mass(\n",
    "                    img[int(y - r) : int(y + r + 1), int(x - r) : int(x + r + 1)]\n",
    "                )\n",
    "            )\n",
    "            centers[i] = list(np.add(np.flip(centers[i]), [x - r, y - r]))\n",
    "            x1, y1 = centers[i]\n",
    "            c = plt.Circle([x1, y1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "            \n",
    "            i += 1\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    return np.array(centers)\n",
    "\n",
    "def count_nearest_pts(src, dst, radius):\n",
    "    \"\"\"Counting the number of nearest neighbors for each given point.\n",
    "\n",
    "    Args:\n",
    "        src (numpy array): (N, 2) shape array. Build the kd tree based on this.\n",
    "        dst (numpy array): (N, 2) shape array. For each point in this array, find the nearest neighbors in src array.\n",
    "        radius (int): The maximum searching radius.\n",
    "\n",
    "    Returns:\n",
    "        res, idx: res is the distance for the point and its neighbor, 'inf' means no neighbor in given search radius. \n",
    "        idx is the index for the neighbor in src array.\n",
    "    \"\"\"\n",
    "    tree = spatial.KDTree(src)\n",
    "    res, idx = tree.query(dst, k=1, distance_upper_bound=radius)\n",
    "    for i in range(0, len(idx)):\n",
    "        idx_t = np.argwhere(idx == idx[i])\n",
    "        if len(idx_t) > 1:\n",
    "            res_t = [res[j] for j in idx_t]\n",
    "            if res[i] > min(res_t): res[i] = inf\n",
    "    return res, idx\n",
    "\n",
    "class App(tk.Tk):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        btn_file = tk.Button(self, text=\"Choose file\",\n",
    "                             command=self.choose_file)\n",
    "        btn_dir = tk.Button(self, text=\"Choose folder\",\n",
    "                             command=self.choose_directory)\n",
    "        btn_file.pack(padx=60, pady=10)\n",
    "        btn_dir.pack(padx=60, pady=10)\n",
    "        \n",
    "\n",
    "    def choose_file(self):\n",
    "        filetypes = ((\"All formats \", \"*\"),\n",
    "                     (\"Text file\", \"*.txt\"),\n",
    "                     (\"Image\", \"*.jpg *.gif *.png *.bmp *.tif\"))\n",
    "        filename = fd.askopenfilename(title=\"Open file\", initialdir=\"/\",\n",
    "                                      filetypes=filetypes)\n",
    "        if filename:\n",
    "            self.st = filename\n",
    "            #print (filename)\n",
    "           \n",
    "            \n",
    "    def choose_directory(self):\n",
    "        directory = fd.askdirectory(title=\"Open folder\", initialdir=\"/\")\n",
    "        if directory:\n",
    "            self.dir = directory\n",
    "#             print (directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of calculating the bead mapping we can load the transformation generated with channel_map\n",
    "\n",
    "\n",
    "tr_G2R = transform.PolynomialTransform()\n",
    "file_path = fd.askopenfilename(title = \"Choose the forward transform file\", initialdir = \"C:/Users/Anton/Documents/Jupyter home/ExampleData/Test_folder/220717_FC_Nano_200nm_Multicolor/original\")\n",
    "tr_G2R.params = np.load(file_path)\n",
    "tr_R2G = transform.PolynomialTransform()\n",
    "file_path = fd.askopenfilename(title = \"Choose the inverse transform file\", initialdir = os.path.dirname(file_path))\n",
    "tr_R2G.params = np.load(file_path)\n",
    "\n",
    "# x_border = int(input(\"Enter the x border\"))\n",
    "# y_border = int(input(\"Enter the y border\"))\n",
    "x_border = 500\n",
    "y_border = 300\n",
    "\n",
    "apriori_tr = transform.SimilarityTransform()\n",
    "apriori_tr.params = np.array([[ 5.98278480e-01, -2.04811207e-03,  0],\n",
    " [ 2.04811207e-03,  5.98278480e-01,  0],\n",
    " [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "# Centering the tranformation to the x_border and y_border\n",
    "delta = 0.5*np.subtract([x_border,y_border],apriori_tr([512,256]))\n",
    "dx, dy = delta[0]\n",
    "apriori_tr.params[0,2] = dx\n",
    "apriori_tr.params[1,2] = dy\n",
    "\n",
    "apriori_tr_inv = transform.SimilarityTransform()\n",
    "apriori_tr_inv.params = np.array([[ 1.67127284e+00,  5.72133913e-03,  0],\n",
    " [-5.72133913e-03,  1.67127284e+00,  0],\n",
    " [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "# Centering the tranformation to the x_border and y_border\n",
    "delta = 0.5*np.subtract([512,256],apriori_tr_inv([x_border,y_border]))\n",
    "dx, dy = delta[0]\n",
    "apriori_tr_inv.params[0,2] = dx\n",
    "apriori_tr_inv.params[1,2] = dy\n",
    "\n",
    "# fastq_path = 'E:/MUSCLE data/0722.fastq'\n",
    "fastq_path = fd.askopenfilename(title = \"Choose the FASTQ file\", initialdir = \"D:/Experiments/MUSCLE DONUTS/\")\n",
    "base_path = os.path.dirname(fastq_path)\n",
    "\n",
    "if tile == 1:\n",
    "    x_coord, y_coord, sequence = get_seq_coordinates(fastq_path,  tile=1101)\n",
    "else:\n",
    "    x_coord, y_coord, sequence = get_seq_coordinates(fastq_path,  tile=1102)\n",
    "\n",
    "# print(len(x_coordinate_01))\n",
    "# print(len(x_coordinate_02))\n",
    "# print(np.max(x_coordinate_01))\n",
    "# print(np.min(x_coordinate_01))\n",
    "\n",
    "# max_y  = max (y_coord)\n",
    "# max_x = max (x_coord)\n",
    "max_y  = max_x = 3000 # To ensure that the alignment is not affected by changes in max x and y\n",
    "\n",
    "\n",
    "x_coord1 = np.subtract(max_y, y_coord)\n",
    "y_coord = np.subtract(max_x, x_coord)\n",
    "\n",
    "x_coord = x_coord1\n",
    "\n",
    "# Correction for the shift between FASTQ and cluster images\n",
    "# x_coord = np.subtract(x_coord, 97.5)\n",
    "# y_coord = np.subtract(y_coord, 3)\n",
    "# # Updated 2023-01-20\n",
    "# x_coord = np.subtract(x_coord, 20)\n",
    "# y_coord = np.subtract(y_coord, -20)\n",
    "# Updated 2023-01-20\n",
    "x_coord = np.subtract(x_coord, 20)\n",
    "y_coord = np.subtract(y_coord, -30)\n",
    "\n",
    "max_x1 = ceil(max_y)\n",
    "max_y = ceil(max_x)\n",
    "max_x = max_x1\n",
    "# max_x = ceil(max_x)\n",
    "# max_y = ceil(max_y)\n",
    "\n",
    "# generate_with_marker(x_coordinate_01, y_coordinate_01, x_coordinate_01m, y_coordinate_01m,\n",
    "#   '/Users/qinhanhou/Desktop/DeindlLab/220722/SeqImg/1101_marked_sigma3.png',\n",
    "#   '/Users/qinhanhou/Desktop/DeindlLab/220722/SeqImg/1101_marked_sigma3.csv')\n",
    "\n",
    "# Cas9_Ha library:\n",
    "library_seq =  'GGTCTCGCACAGCAGAAATCTCTACTGAGGTATAAAGATGAGACGCTGGAGTAAAAACGTTGGTTGGCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = fd.askopenfilename(title = \"Choose the position list\", initialdir = base_path)\n",
    "current_direct = fd.askdirectory(title = \"Choose the output folder\", initialdir = base_path)\n",
    "\n",
    "\n",
    "pos_file = open(file_path)\n",
    "data = json.load(pos_file)\n",
    "POS = data['POSITIONS']\n",
    "\n",
    "labels = [P['LABEL'] for P in POS]\n",
    "posX = [P['DEVICES'][1]['X'] for P in POS]\n",
    "posY = [P['DEVICES'][1]['Y'] for P in POS]\n",
    "\n",
    "\n",
    "#X_c = [posX[i] for i,x in enumerate(labels) if labels[i]=='Pos287']\n",
    "#Y_c = [posY[i] for i,x in enumerate(labels) if labels[i]=='Pos287']\n",
    "\n",
    "labels_res = []\n",
    "posX_res = []\n",
    "posY_res = []\n",
    "for i,x in enumerate(labels):\n",
    "#     x = int(-850+(305-x_border)/2 + (posX[i] - 26384)/0.34) # tile 2 06/09/2022; 305 and 154 are the size of tfd 512 by 256 image\n",
    "#     y = int(-385+(154-y_border)/2  - (posY[i] + 407.1)/0.34)  \n",
    "#     x = int(-3967+(305-x_border)/2 + (posX[i] - 26384)/0.34) # tile 1 06/09/2022; 305 and 154 are the size of tfd 512 by 256 image\n",
    "#     y = int(-405+(154-y_border)/2  - (posY[i] + 407.1)/0.34)   \n",
    "#     x = int(1700+(330-x_border)/2 + (posX[i] - 27246.18)/0.34) # tile 2 19/07/2022\n",
    "#     y = int(1571+(170-y_border)/2  - (posY[i] + 1149.66)/0.34)   \n",
    "    x = int(deltax+(335-x_border)/2 + (posX[i] - upper_left_um_x)/0.34) # tile 2 06/09/2022;\n",
    "    y = int(deltay+(150-y_border)/2  - (posY[i] - upper_left_um_y)/0.34)  # 305 and 154 are the size of tfd 512 by 256 image\n",
    "#     x = int(2329+(330-x_border)/2 + (posX[i] - 28522.9)/0.34) # tile 1 19/07/2022\n",
    "#     y = int(2042+(170-y_border)/2 - (posY[i] + 1313.3)/0.34) \n",
    "    if (x > 0 ) and (y > 0):\n",
    "        if (y+y_border< 2944) and (x+x_border <2866) :\n",
    "            labels_res.append (labels[i])\n",
    "            posX_res.append (posX[i])\n",
    "            posY_res.append( posY[i])\n",
    "\n",
    "\n",
    "print (labels_res)\n",
    "\n",
    "#print(usable_green_beads)\n",
    "#print(usable_red_beads)\n",
    "fastq_image = generate_img(y_coord,x_coord, 0, 0, max_y, max_x, 1, True, 1)\n",
    "fastq_image.save(os.path.join(current_direct, 'FASTQ_image.png'))\n",
    "\n",
    "\n",
    "counter = 0  \n",
    "\n",
    "file_path = fd.askopenfilename(title = \"Choose the MIN projection image\", initialdir = base_path)\n",
    "seq = io.imread(file_path)#reading the sequence image\n",
    "seq = seq.astype(\"ushort\") \n",
    "\n",
    "file_path = fd.askopenfilename(title = \"Choose the MAX projection image\", initialdir = base_path)\n",
    "seq_max = io.imread(file_path)#reading the sequence image\n",
    "seq_max = seq_max.astype(\"ushort\")\n",
    "image_array_max = np.asarray(seq_max)\n",
    "good_pos = []\n",
    "matched_sequences = []\n",
    "matched_centers_red = []\n",
    "matched_centers_green = []\n",
    "matched_centers_FQ = []\n",
    "matched_dist = []\n",
    "processed_pos = []\n",
    "FQ_shifts = []\n",
    "FQ_shifts_pos = []\n",
    "\n",
    "image_array_seq = np.asarray(seq) #array from sequence image\n",
    "image_array_FQ = np.asarray(fastq_image) #array from fastq_image\n",
    "beads_dir = fd.askdirectory(title = \"Choose the beads folder\", initialdir = base_path)\n",
    "path_smFRET = fd.askdirectory(title = \"Choose the smFRET folder\", initialdir = base_path)\n",
    "# path_smFRET = fd.askdirectory(title = \"Choose the smFRET movie\", initialdir = \"D:/Experiments/MUSCLE DONUTS/20220824_FC_Nano_Cas9_CCR5/Cas9/green\")\n",
    "plt.figure()\n",
    "plt.imshow(seq)\n",
    "print('Number of overlapping FOVs: ',len(labels_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to restart analysis from the beginning\n",
    "processed_pos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main cycle. \n",
    "## Matching smFRET peaks and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN CYCLE\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites'), exist_ok=True)\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites_raw'), exist_ok=True)\n",
    "r = 3 # Half-width of the molecule aperture for trace extraction, i.e. for r = 3 it is -3:3\n",
    "rb = 5 # Half-width of the background aperture for trace extraction \n",
    "for pos in labels_res :\n",
    "#     for current_dir,dirs, files in os.walk(beads_dir) :\n",
    "# #         for el in files:     \n",
    "#             if el.split('.')[-2] == pos:\n",
    "#     path1 = os.path.join(beads_dir,pos+'.tiff')\n",
    "    path1 = os.path.join(beads_dir,pos,'A_Red','img_000000000.tiff')\n",
    "    if os.path.exists(path1)&(not os.path.exists(os.path.join(current_direct, pos + \"_traces.mat\")))&(not pos in processed_pos):\n",
    "#         data['sequence'] = []\n",
    "        \n",
    "        processed_pos.append(pos)\n",
    "        pos_direct = os.path.join(current_direct, pos)\n",
    "        os.makedirs(pos_direct, exist_ok=True)\n",
    "        log_file = open(os.path.join(pos_direct, pos + \"_log.txt\"), 'w')\n",
    "        log_file.write('Working on: '+ pos+'\\n')\n",
    "        print('Working on: '+ pos+'\\n')\n",
    "        FRET_coord = []\n",
    "        seq_coord = []\n",
    "        point = []\n",
    "        counter = 0\n",
    "        rb_rad = 10\n",
    "        img_beads_F = io.imread(path1) #reading the stack of images\n",
    "        if len(img_beads_F.shape) == 3:\n",
    "            if img_beads_F.shape[0] == 512: # sometimes slice number is the first dimension, sometimes the third\n",
    "                img_beads_F = np.mean(img_beads_F, axis = 2) #averaging by the stack\n",
    "            else:\n",
    "                img_beads_F = np.mean(img_beads_F, axis = 0) #averaging by the stack\n",
    "             \n",
    "        img_beads_F = img_beads_F.astype(\"ushort\") #turn from float format to ushort\n",
    "        img_beads_F = img_beads_F [256:512, 0:512]\n",
    "        img_beads_F = img_beads_F - rolling_ball(img_beads_F, radius=rb_rad)\n",
    "        image_array_F = transform.warp(img_beads_F, apriori_tr_inv, output_shape = [y_border, x_border])\n",
    "        image_array_F = img_as_ubyte(image_array_F)\n",
    "        #img = io.imread(current_dir + '/' + el) #initial reading of original averaging image\n",
    "        #img = cv2.imread(app.st)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img1)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(seq)\n",
    "\n",
    "        image_array_F = np.asarray(image_array_F) #array from FRET image\n",
    "#         plt.figure()\n",
    "#         plt.imshow(image_array_F)\n",
    "        \n",
    "        idx = [i for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 X_c = [posX_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 Y_c = [posY_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "        X_c = [posX_res[i] for i in idx]\n",
    "        Y_c = [posY_res[i] for i in idx]\n",
    "\n",
    "        X_c, Y_c = scaling_seq(X_c[0], Y_c[0])\n",
    "#         print (X_c, Y_c)\n",
    "        point.append(X_c)\n",
    "        point.append(Y_c)\n",
    "        point = np.array(point)\n",
    "        image_array_seq_t = image_array_seq[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_max_t = image_array_max[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_FQ_t = image_array_FQ[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+x_border) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+y_border)]\n",
    "        x_FQ = [x_coord[i] for i in idx]\n",
    "        y_FQ = [y_coord[i] for i in idx]\n",
    "        seq_t = [sequence[i] for i in idx]\n",
    "        if len(seq_t)<100:\n",
    "            log_file.write('Not enough (<100) clusters: '+ str(len(seq_t))+ '\\n')\n",
    "            continue\n",
    "\n",
    "        #print(image_array)\n",
    "\n",
    "        #reading by cv2 to make possible circles in color\n",
    "        #img_jpg = io.imread('C:/Users/panf/Documents/Muscle_intermediates/AVG_G10_1_1_MMStack_Pos0.ome.jpg')\n",
    "        #img_array = img_as_int(img)\n",
    "        # displaying the image\n",
    "        # setting mouse handler for the image\n",
    "        # and calling the click_event() function\n",
    "        image_seq = Image.fromarray(image_array_seq_t)\n",
    "        image_seq.save (pos_direct + '/'+ pos+'_seq.tif')\n",
    "\n",
    "        image_fastq = Image.fromarray(image_array_FQ_t)\n",
    "        image_fastq.save (pos_direct + '/'+ pos+'_fastq.tif')\n",
    "\n",
    "        v_min, v_max = np.percentile(image_array_seq_t, (0, 99.8))\n",
    "        if v_max == 0: v_max = np.max(image_array_seq_t)  \n",
    "\n",
    "        # Calculating the shift between the FASTQ and cluster images using cross-correlation\n",
    "        shift = phase_cross_correlation(image_array_max_t,image_array_FQ_t)\n",
    "        shift = shift[0]\n",
    "        print(shift)\n",
    "        # Translation of the FASTQ sequences in the FOV to match the cluster image\n",
    "        x_FQ = np.subtract(x_FQ,X_c-shift[1])\n",
    "        y_FQ = np.subtract(y_FQ,Y_c-shift[0])\n",
    "        FQ_shifts.append([X_c-shift[1], Y_c-shift[0]])\n",
    "        FQ_shifts_pos.append(pos)\n",
    "        \n",
    "        MAX_centers = blob_detection(\n",
    "            image_array_max_t,\n",
    "            min_sigma=1,\n",
    "            max_sigma=10,\n",
    "            threshold=0.0001\n",
    "        )\n",
    "        FQ_centers_all = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "        res, idx = count_nearest_pts(FQ_centers_all, MAX_centers, 2)\n",
    "        FQ_centers_all1 = FQ_centers_all[idx[np.where(res != inf)]]\n",
    "        MAX_centers1 = MAX_centers[np.where(res != inf)]\n",
    "#         print(FQ_centers_all1)\n",
    "#         print(MAX_centers1)\n",
    "\n",
    "        trFQtoMAX = transform.estimate_transform(\"similarity\", src=FQ_centers_all1, dst=MAX_centers1)\n",
    "\n",
    "        temp = trFQtoMAX(FQ_centers_all)\n",
    "        x_FQ = temp[:,0];\n",
    "        y_FQ = temp[:,1];\n",
    "\n",
    "        fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "        fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "        max_image = generate_img(MAX_centers[:,1],MAX_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        max_image.save(os.path.join(pos_direct,pos+'_MAX_seq_CoM.png'))\n",
    "        max_image = Image.fromarray(image_array_max_t)\n",
    "        max_image.save(os.path.join(pos_direct,pos+'_MAX_seq.png'))\n",
    "#         fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "#         fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(fastq_image1)\n",
    "        plt.show()\n",
    "\n",
    "        # Selecting the library sequences for further analysis\n",
    "        idx = library_index(library_seq, seq_t, 40)\n",
    "        x_FQ = [x_FQ[i] for i in idx]\n",
    "        y_FQ = [y_FQ[i] for i in idx]\n",
    "        seq_t = [seq_t[i] for i in idx] \n",
    "        \n",
    "        \n",
    "        # Calculating the transformation based on automatically-selected beads\n",
    "        movie_centers = blob_detection(\n",
    "            np.asarray(img_beads_F),\n",
    "            min_sigma=1,\n",
    "            max_sigma=10,\n",
    "            threshold=0.1 # was 0.003 before 2024-01-30\n",
    "        )\n",
    "\n",
    "        seq_centers = blob_detection(\n",
    "            image_array_seq_t,\n",
    "            min_sigma=1,\n",
    "            max_sigma=10,\n",
    "            threshold=0.0005, # Was 0.00001 for 19/07/2022 and 0.0005\n",
    "         )\n",
    "        beadsOK = False\n",
    "#         if len(movie_centers)> 2: \n",
    "#             a = run(seq_centers, apriori_tr(movie_centers))\n",
    "#             uknmatchstars_coord = []\n",
    "#             refmatchstars_coord = []\n",
    "#             if len(a[0].refmatchstars) >= 3:\n",
    "#                 for i in range (len(a[0].refmatchstars)):\n",
    "                \n",
    "#                     uknmatchstars_coord.append(a[0].uknmatchstars[i].x)\n",
    "#                     uknmatchstars_coord.append(a[0].uknmatchstars[i].y)\n",
    "#                     refmatchstars_coord.append(a[0].refmatchstars[i].x)\n",
    "#                     refmatchstars_coord.append(a[0].refmatchstars[i].y)\n",
    "\n",
    "#                 refmatchstars_coord = np.array(refmatchstars_coord)\n",
    "#                 uknmatchstars_coord = np.array(uknmatchstars_coord)\n",
    "\n",
    "#                 refmatchstars_coord = np.reshape ( refmatchstars_coord, ( int(len(a[0].refmatchstars)), 2 ) )\n",
    "#                 uknmatchstars_coord = np.reshape ( uknmatchstars_coord, ( int(len(a[0].uknmatchstars)), 2 ) )\n",
    "#                 result_coord = np.concatenate ((refmatchstars_coord,uknmatchstars_coord ), axis = 0)\n",
    "#     #             print (pos+\"\\n\", result_coord )\n",
    "#                 np.save (os.path.join(pos_direct, pos + \"_matching_beads\"), result_coord)\n",
    "#                 beadsOK = True\n",
    "#                 movie_centers1 = apriori_tr_inv(uknmatchstars_coord)\n",
    "#                 seq_centers1 = refmatchstars_coord\n",
    "#                 print('Automatically matched beads: ',seq_centers1.shape[0])\n",
    "#                 rough_tr1 = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "#                 np.save(os.path.join(pos_direct, pos + \"_auto_bead_tr\"), rough_tr1)\n",
    "#             else:\n",
    "#                 log_file.write(\"\"\"Not enough (<3) automatically detected and matched beads to update the initial\n",
    "#                                transformation estimate based on manually selected beads\\n\"\"\")\n",
    "                \n",
    "#         else:\n",
    "#             log_file.write(\"\"\"Not enough (<3) automatically detected beads to update the initial\n",
    "#                            transformation estimate based on manually selected beads\\n\"\"\")\n",
    "            \n",
    "        print(beadsOK)    \n",
    "        # Reading the smFRET movie\n",
    "#             path_smFRET_file = os.path.join(path_smFRET,pos+'.tiff')\n",
    "        if os.path.exists(os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')\n",
    "        elif os.path.exists(os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')\n",
    "        elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')\n",
    "        elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_Normal','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_Normal','img_000000000.tiff')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        img_smFRET = io.imread(path_smFRET_file)\n",
    "\n",
    "        # Averaging the first 10 frames to select peaks\n",
    "        if ALEX:\n",
    "            img_t = np.mean(img_smFRET[green_frames,::], axis = 0)\n",
    "        else:\n",
    "            img_t = np.mean(img_smFRET[0:10,::], axis = 0)\n",
    "        img_t = img_t.astype(\"ushort\")\n",
    "        rb_rad = 10\n",
    "\n",
    "        red = img_t[256:,:]\n",
    "        green = img_t[:256,:]\n",
    "        red = red - rolling_ball(red, radius=rb_rad)\n",
    "        green = green - rolling_ball(green, radius=rb_rad)\n",
    "        green = transform.warp(green,tr_R2G, preserve_range = True)\n",
    "        combined = red + green # Consider adding the red excitation channel, though there are some difficulties, e.g. beads and int scaling\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(combined)\n",
    "        blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=300) # Was 1000 for 19/07/2022\n",
    "#             Was 300 for 06/09/2022\n",
    "        CM = []\n",
    "        r = 3\n",
    "        [h,w] = red.shape\n",
    "        n_frames = img_smFRET.shape[0]\n",
    "        FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "        \n",
    "        for i, blob in enumerate(blobs_log):\n",
    "            x, y, d = blob\n",
    "            if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "                temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "                CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "                c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "                ax.add_patch(c)\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "        plt.show()\n",
    "        smFRET_centers = np.array(CM)\n",
    "#         res, idx = count_nearest_pts(rough_tr(movie_centers), seq_centers, 8)\n",
    "#         movie_centers1 = movie_centers[idx[np.where(res != inf)]]\n",
    "#         seq_centers1 = seq_centers[np.where(res != inf)]\n",
    "        \n",
    "        if not beadsOK:\n",
    "            # Calculating the shift between the FASTQ and cluster images using cross-correlation\n",
    "            smFRET_centers_tr = apriori_tr(smFRET_centers)\n",
    "            smFRET_centers_tr_image_array = np.asarray(generate_img(smFRET_centers_tr[:,1],smFRET_centers_tr[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "            fastq_image_lib_array = np.asarray(generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1))\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(smFRET_centers_tr_image_array)\n",
    "            plt.show()\n",
    "            image_smFRET_tr = Image.fromarray(smFRET_centers_tr_image_array)\n",
    "            image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_tr.tif\"))\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(fastq_image_lib_array)\n",
    "            plt.show()\n",
    "            image_smFRET_tr = Image.fromarray(fastq_image_lib_array)\n",
    "            image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_FQ_peaks.tif\"))\n",
    "\n",
    "            shift = phase_cross_correlation(fastq_image_lib_array,smFRET_centers_tr_image_array)\n",
    "            shift = shift[0]\n",
    "            print(shift)\n",
    "\n",
    "            rough_tr1 = copy.deepcopy(apriori_tr)\n",
    "            dx = apriori_tr.params[0,2] + shift[1] # Check sign!\n",
    "            dy = apriori_tr.params[1,2] + shift[0]\n",
    "            rough_tr1.params[0,2] = dx\n",
    "            rough_tr1.params[1,2] = dy\n",
    "            \n",
    "            np.save(os.path.join(pos_direct, pos + \"_auto_bead_tr\"), rough_tr1)\n",
    "            \n",
    "            smFRET_centers_tr = rough_tr1(smFRET_centers)\n",
    "            smFRET_centers_tr_image_array = np.asarray(generate_img(smFRET_centers_tr[:,1],smFRET_centers_tr[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "            fastq_image_lib_array = np.asarray(generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1))\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(smFRET_centers_tr_image_array)\n",
    "            plt.show()\n",
    "            image_smFRET_tr = Image.fromarray(smFRET_centers_tr_image_array)\n",
    "            image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_upd_tr.tif\"))\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        res, idx = count_nearest_pts(rough_tr1(smFRET_centers), FQ_centers, 2)\n",
    "        movie_centers1 = smFRET_centers[idx[np.where(res != inf)]]\n",
    "        seq_centers1 = FQ_centers[np.where(res != inf)]\n",
    "\n",
    "        if seq_centers1.shape[0]<4:\n",
    "            print('Not enough smFRET peaks (<4)')\n",
    "            log_file.write('Not enough smFRET peaks (<4)')\n",
    "            continue\n",
    "\n",
    "        tr = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "        tr_inv = transform.estimate_transform(\"similarity\", src=seq_centers1, dst=movie_centers1)\n",
    "        np.save(os.path.join(pos_direct, pos + \"_final_tr\"), tr)\n",
    "        np.save(os.path.join(pos_direct, pos + \"_final_tr_inv\"), tr_inv)\n",
    "        log_file.write('Matched clusters before transform update: ' + str(seq_centers1.shape[0])+'\\n')\n",
    "        print('Matched clusters before transform update: ',seq_centers1.shape[0])\n",
    "\n",
    "        res, idx = count_nearest_pts(tr(smFRET_centers), FQ_centers, 3) # Was 4 for 19/07/2022\n",
    "        centers_matched = smFRET_centers[idx[np.where(res != inf)]]\n",
    "        idx_t = np.where(res != inf)\n",
    "        seq_matched = [seq_t[i] for i in idx_t[0]]\n",
    "        FQ_centers_matched = FQ_centers[idx_t]\n",
    "        distances_matched = res[idx_t]\n",
    "\n",
    "        centers_red = centers_matched\n",
    "        centers_green = tr_R2G(centers_matched)\n",
    "        r = 3\n",
    "        # Weed out positions that are too close to the edge\n",
    "        idx_t = np.where((centers_red[:,0]>rb) & (centers_red[:,0]<(w-rb)) & (centers_red[:,1]>rb) & (centers_red[:,1]<(h-rb))  & \n",
    "                         (centers_green[:,0]>rb) & (centers_green[:,0]<(w-rb)) & (centers_green[:,1]>rb) & (centers_green[:,1]<(h-rb)))\n",
    "        centers_red = centers_red [idx_t]\n",
    "        centers_green = centers_green [idx_t]\n",
    "        distances_matched = distances_matched[idx_t]\n",
    "        seq_matched = [seq_matched[i] for i in idx_t[0]]\n",
    "\n",
    "        matched_sequences.append(seq_matched)\n",
    "        matched_centers_red.append(centers_red)\n",
    "        matched_centers_green.append(centers_green)\n",
    "        matched_dist.append(distances_matched)\n",
    "        matched_centers_FQ.append(FQ_centers_matched)\n",
    "        good_pos.append(pos)\n",
    "        log_file.write('Matched clusters after transform update: ' + str(len(seq_matched))+'\\n')\n",
    "        log_file.write('Out of ' + str(len(smFRET_centers)) + ' smFRET peaks and ' + str(len(FQ_centers)) + ' clusters'+'\\n')\n",
    "        log_file.write('Percentage of matched smFRET peaks: ' + str(int(100*len(seq_matched)/len(smFRET_centers)))+'\\n')\n",
    "        log_file.write('Percentage of matched clusters: ' + str(int(100*len(seq_matched)/len(FQ_centers)))+'\\n')\n",
    "        print('Matched clusters after transform update: ',len(seq_matched))\n",
    "        print('Out of ',len(smFRET_centers), ' smFRET peaks and ', len(FQ_centers), ' clusters')\n",
    "        print('Percentage of matched smFRET peaks: ',int(100*len(seq_matched)/len(smFRET_centers)))\n",
    "        print('Percentage of matched clusters: ',int(100*len(seq_matched)/len(FQ_centers)))\n",
    "        # Saving transformed bead and molecule images for QC\n",
    "        img_beads_tfd = Image.fromarray(transform.warp(img_beads_F, tr_inv, output_shape = [y_border, x_border]))\n",
    "        img_beads_tfd.save(os.path.join(pos_direct, pos + \"_beads_transformed.tif\"))\n",
    "        img_smFRET_tfd = Image.fromarray(transform.warp(combined, tr_inv, output_shape = [y_border, x_border]))\n",
    "        img_smFRET_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_transformed.tif\"))\n",
    "        centers_red_tfd = tr(centers_red)\n",
    "        img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_matched_transformed.tif\"))\n",
    "\n",
    "        centers_red_tfd = tr(smFRET_centers)\n",
    "        img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_all_transformed.tif\"))\n",
    "\n",
    "        img_centers_red_tfd = generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_matched.tif\"))\n",
    "\n",
    "        img_centers_red_tfd = generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_all.tif\"))\n",
    "        \n",
    "#         Saving a composite image for quick QC\n",
    "        fig, ax = plt.subplots()\n",
    "        QC_composite_array = np.zeros([y_border,x_border,3], dtype=np.uint8)\n",
    "        red_channel = np.asarray(generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(red_channel[75:125,:], (0.5, 99.5))        \n",
    "        red_channel = exposure.rescale_intensity(red_channel, in_range=tuple(percentiles))\n",
    "        red_channel = img_as_ubyte(red_channel)\n",
    "\n",
    "        green_channel = np.asarray(generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(green_channel, (0.5, 99.5))\n",
    "        green_channel = exposure.rescale_intensity(green_channel, in_range=tuple(percentiles))\n",
    "        green_channel = img_as_ubyte(green_channel)\n",
    "\n",
    "        blue_channel = np.asarray(generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(blue_channel, (0.5, 99.5))\n",
    "        blue_channel = exposure.rescale_intensity(blue_channel, in_range=tuple(percentiles))\n",
    "        blue_channel = img_as_ubyte(blue_channel)\n",
    "\n",
    "        QC_composite_array[:,:,0] = red_channel\n",
    "        QC_composite_array[:,:,1] = green_channel\n",
    "        QC_composite_array[:,:,2] = blue_channel\n",
    "\n",
    "        QC_composite = Image.fromarray(QC_composite_array, mode=\"RGB\")\n",
    "        QC_composite.save(os.path.join(current_direct, 'QC_composites_raw' , pos + \"_QC.tif\"))\n",
    "\n",
    "        ax.imshow(QC_composite)\n",
    "        for blob in FQ_centers_matched:\n",
    "            c = plt.Circle(blob, 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig(os.path.join(current_direct, 'QC_composites' , pos + \"_QC.png\"))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "# Save good pos data to be able to extract traces later\n",
    "frame_rate = 5\n",
    "mdict1 = {\n",
    "    \"good_pos\": good_pos,\n",
    "    \"matched_sequences\": matched_sequences,\n",
    "    \"matched_centers_red\": matched_centers_red,\n",
    "    \"matched_centers_green\": matched_centers_green,\n",
    "    \"matched_distances\": matched_dist,\n",
    "    \"matched_FASTQ\": matched_centers_FQ,\n",
    "    \"FASTQ_shifts\": FQ_shifts\n",
    "}\n",
    "\n",
    "savemat(os.path.join(current_direct, \"good_pos.mat\"), mdict1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of matched FOVs: ',len(good_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# apriori_tr = transform.SimilarityTransform()\n",
    "# apriori_tr.params = np.array([[ 5.98278480e-01, -2.04811207e-03,  0],\n",
    "#  [ 2.04811207e-03,  5.98278480e-01,  0],\n",
    "#  [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "# # Centering the tranformation to the x_border and y_border\n",
    "# delta = 0.5*np.subtract([x_border,y_border],apriori_tr([512,256]))\n",
    "# dx, dy = delta[0]\n",
    "# apriori_tr.params[0,2] = dx\n",
    "# apriori_tr.params[1,2] = dy\n",
    "\n",
    "# # apriori_tr_inv = transform.SimilarityTransform()\n",
    "# # apriori_tr_inv.params = np.array([[ 1.67127284e+00,  5.72133913e-03,  0],\n",
    "# #  [-5.72133913e-03,  1.67127284e+00,  0],\n",
    "# #  [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "# # # Centering the tranformation to the x_border and y_border\n",
    "# # delta = 0.5*np.subtract([512,256],apriori_tr_inv([x_border,y_border]))\n",
    "# # dx, dy = delta[0]\n",
    "# # apriori_tr_inv.params[0,2] = dx\n",
    "# # apriori_tr_inv.params[1,2] = dy\n",
    "\n",
    "# #         fig, ax = plt.subplots()\n",
    "# #         ax.imshow(combined)\n",
    "# #         blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=1000) # Was 1000 for 19/07/2022\n",
    "# # #             Was 300 for 06/09/2022\n",
    "# #         CM = []\n",
    "# #         r = 3\n",
    "# #         [h,w] = red.shape\n",
    "# #         n_frames = img_smFRET.shape[0]\n",
    "# #         FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "        \n",
    "# #         for i, blob in enumerate(blobs_log):\n",
    "# #             x, y, d = blob\n",
    "# #             if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "# #                 temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "# #                 CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "# #                 c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "# #                 ax.add_patch(c)\n",
    "# #         ax.set_axis_off()\n",
    "# #         plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "# #         plt.show()\n",
    "# smFRET_centers_tr = apriori_tr(smFRET_centers)\n",
    "# smFRET_centers_tr_image_array = np.asarray(generate_img(smFRET_centers_tr[:,1],smFRET_centers_tr[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "# fastq_image_lib_array = np.asarray(generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1))\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(smFRET_centers_tr_image_array)\n",
    "# plt.show()\n",
    "# image_smFRET_tr = Image.fromarray(smFRET_centers_tr_image_array)\n",
    "# image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_tr.tif\"))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(fastq_image_lib_array)\n",
    "# plt.show()\n",
    "# image_smFRET_tr = Image.fromarray(fastq_image_lib_array)\n",
    "# image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_FQ_peaks.tif\"))\n",
    "\n",
    "# shift = phase_cross_correlation(fastq_image_lib_array,smFRET_centers_tr_image_array)\n",
    "# shift = shift[0]\n",
    "# print(shift)\n",
    "# # print(apriori_tr.params[0,2])\n",
    "# dx = apriori_tr.params[0,2] + shift[1] # Check sign!\n",
    "# dy = apriori_tr.params[1,2] + shift[0]\n",
    "# updated_tr = copy.deepcopy(apriori_tr)\n",
    "# updated_tr.params[0,2] = dx\n",
    "# updated_tr.params[1,2] = dy\n",
    "# # print(apriori_tr.params[0,2])\n",
    "# print(dx,dy)\n",
    "\n",
    "# smFRET_centers_tr = updated_tr(smFRET_centers)\n",
    "# smFRET_centers_tr_image_array = np.asarray(generate_img(smFRET_centers_tr[:,1],smFRET_centers_tr[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "# fastq_image_lib_array = np.asarray(generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1))\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(smFRET_centers_tr_image_array)\n",
    "# plt.show()\n",
    "# image_smFRET_tr = Image.fromarray(smFRET_centers_tr_image_array)\n",
    "# image_smFRET_tr.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_upd_tr.tif\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting traces with median background estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting traces, median BG version\n",
    "r = 3 # Half-width of the molecule aperture for trace extraction, i.e. for r = 3 it is -3:3\n",
    "rb = 5 # Half-width of the background aperture for trace extraction \n",
    "# (bacground is calculated as a median of intensities in a rectangular aperture between r and rb)\n",
    "# a = np.subtract(range(2*rb+1), rb)\n",
    "at = [[j,i] for i in range(2*rb+1) for j in range(rb-r)]\n",
    "bt = [[j,i] for i in range(2*rb+1) for j in range(r+rb+1,2*rb+1)]\n",
    "ct = [[j,i] for i in range(rb-r) for j in range(rb-r,r+rb+1)]\n",
    "dt = [[j,i] for i in range(r+rb+1,2*rb+1) for j in range(rb-r,r+rb+1)]\n",
    "idx_bg = np.subtract(np.concatenate([at,bt,ct,dt]), [rb,rb]) # Indexes that define the background aperture\n",
    "\n",
    "for i, pos in enumerate(good_pos):\n",
    "    # Reading the smFRET movie\n",
    "    if os.path.exists(os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')\n",
    "    elif os.path.exists(os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')\n",
    "    elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')\n",
    "    elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_Normal','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_Normal','img_000000000.tiff')\n",
    "    else:\n",
    "        continue\n",
    "    img_smFRET = io.imread(path_smFRET_file)\n",
    "    \n",
    "\n",
    "    seq_matched = matched_sequences[i]\n",
    "    dist_matched = matched_dist[i]\n",
    "    centers_red = matched_centers_red[i]\n",
    "    centers_green = matched_centers_green[i]\n",
    "    n_traces = len(centers_red)\n",
    "    [h,w] = [256,512]\n",
    "    n_frames = img_smFRET.shape[0]\n",
    "\n",
    "    weights_red = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    weights_green = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    traces_red =  np.zeros([n_traces,n_frames])\n",
    "    traces_green = np.zeros([n_traces,n_frames])\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Select matching peaks from peak_locations and their sequences\n",
    "\n",
    "\n",
    "    for j,coord in enumerate(centers_red):\n",
    "        x, y = coord\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_red[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "        x, y = centers_green[j]\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_green[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        if i%100 == 0: print(\"Working on frame \"+str(i))\n",
    "        red1 = img_smFRET[i,256:,:]\n",
    "        red1 = red1 - si.restoration.rolling_ball(red1, radius=rb_rad)\n",
    "        green1 = img_smFRET[i,:256,:]\n",
    "        green1 = green1 - si.restoration.rolling_ball(green1, radius=rb_rad)\n",
    "\n",
    "        for j,coord in enumerate(centers_red):\n",
    "            x, y = coord\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "#             red2 = red1[y0:y1,x0:x1]\n",
    "#             traces_red[j,i] = np.sum(np.multiply(weights_red[j],red2))\n",
    "\n",
    "            index = np.add(idx_bg,[int(x), int(y)])\n",
    "            # Temporary fix for molecules that are too close to the edge\n",
    "#             if (np.max(index[:,1])<256)&(np.min(index[:,1])>=0)&(np.max(index[:,0])<512)&(np.min(index[:,0])>=0):            \n",
    "            BG = np.median(red1[index[:,1], index[:,0]])\n",
    "            red2 = np.subtract(red1[y0:y1,x0:x1], BG)\n",
    "            traces_red[j,i] = np.sum(np.multiply(weights_red[j],red2))\n",
    "#             else:\n",
    "#                 traces_red[j,i] = -10000\n",
    "                \n",
    "            x, y = centers_green[j]\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "#             green2 = green1[y0:y1,x0:x1]\n",
    "#             traces_green[j,i] = np.sum(np.multiply(weights_green[j],green2))\n",
    "            index = np.add(idx_bg,[int(x), int(y)])\n",
    "#             if (np.max(index[:,1])<256)&(np.min(index[:,1])>=0)&(np.max(index[:,0])<512)&(np.min(index[:,0])>=0):            \n",
    "            BG = np.median(green1[index[:,1], index[:,0]])\n",
    "            green2 = np.subtract(green1[y0:y1,x0:x1], BG)\n",
    "            traces_green[j,i] = np.sum(np.multiply(weights_green[j],green2))\n",
    "#             else:\n",
    "#                 traces_green[j,i] = -10000\n",
    "            \n",
    "\n",
    "    centers_FQ = matched_centers_FQ[i]\n",
    "    # Save traces and sequences\n",
    "    frame_rate = 5\n",
    "    mdict = {\n",
    "        \"time\": np.divide(range(n_frames),frame_rate),\n",
    "        \"Cy3\": traces_green,\n",
    "        \"Cy5\": traces_red,\n",
    "        \"Seq\": seq_matched,\n",
    "        \"Dist\": dist_matched,\n",
    "        \"x\": centers_red[:,0],\n",
    "        \"y\": centers_red[:,1],\n",
    "        \"x_FQ\": centers_FQ[:,0],\n",
    "        \"y_FQ\": centers_FQ[:,1]\n",
    "    }\n",
    "\n",
    "    savemat(os.path.join(current_direct, pos + \"_traces.mat\"), mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centers_red\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual bead selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN CYCLE WITH MANUAL BEAD SELECTION\n",
    "good_pos = []\n",
    "matched_sequences = []\n",
    "matched_centers_red = []\n",
    "matched_centers_green = []\n",
    "matched_dist = []\n",
    "FQ_shifts = []\n",
    "FQ_shifts_pos = []\n",
    "matched_centers_FQ = []\n",
    "# processed_pos = []\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites'), exist_ok=True)\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites_raw'), exist_ok=True)\n",
    "r = 3 # Half-width of the molecule aperture for trace extraction, i.e. for r = 3 it is -3:3\n",
    "rb = 5 # Half-width of the background aperture for trace extraction \n",
    "for pos in labels_res :\n",
    "#     for current_dir,dirs, files in os.walk(beads_dir) :\n",
    "# #         for el in files:     \n",
    "#             if el.split('.')[-2] == pos:\n",
    "#     path1 = os.path.join(beads_dir,pos+'.tiff')\n",
    "    path1 = os.path.join(beads_dir,pos,'A_Red','img_000000000.tiff')\n",
    "    if os.path.exists(path1)&(not os.path.exists(os.path.join(current_direct, pos + \"_traces.mat\")))&(not pos in processed_pos):\n",
    "#         data['sequence'] = []\n",
    "        \n",
    "        processed_pos.append(pos)\n",
    "        pos_direct = os.path.join(current_direct, pos)\n",
    "        os.makedirs(pos_direct, exist_ok=True)\n",
    "        log_file = open(os.path.join(pos_direct, pos + \"_log.txt\"), 'w')\n",
    "        log_file.write('Working on: '+ pos+'\\n')\n",
    "        FRET_coord = []\n",
    "        seq_coord = []\n",
    "        point = []\n",
    "        counter = 0\n",
    "        rb_rad = 10\n",
    "        img_beads_F = io.imread(path1) #reading the stack of images\n",
    "        \n",
    "        if len(img_beads_F.shape) == 3:\n",
    "            if img_beads_F.shape[0] == 512: # sometimes slice number is the first dimension, sometimes the third\n",
    "                img_beads_F = np.mean(img_beads_F, axis = 2) #averaging by the stack\n",
    "            else:\n",
    "                img_beads_F = np.mean(img_beads_F, axis = 0) #averaging by the stack\n",
    "        \n",
    "        img_beads_F = img_beads_F.astype(\"ushort\") #turn from float format to ushort\n",
    "        img_beads_F = img_beads_F [256:512, 0:512]\n",
    "        img_beads_F = img_beads_F - rolling_ball(img_beads_F, radius=rb_rad)\n",
    "        image_array_F = transform.warp(img_beads_F, apriori_tr_inv, output_shape = [y_border, x_border])\n",
    "        image_array_F = img_as_ubyte(image_array_F)\n",
    "        #img = io.imread(current_dir + '/' + el) #initial reading of original averaging image\n",
    "        #img = cv2.imread(app.st)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img1)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(seq)\n",
    "\n",
    "        image_array_F = np.asarray(image_array_F) #array from FRET image\n",
    "#         plt.figure()\n",
    "#         plt.imshow(image_array_F)\n",
    "        \n",
    "        idx = [i for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 X_c = [posX_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 Y_c = [posY_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "        X_c = [posX_res[i] for i in idx]\n",
    "        Y_c = [posY_res[i] for i in idx]\n",
    "\n",
    "        X_c, Y_c = scaling_seq(X_c[0], Y_c[0])\n",
    "#         print (X_c, Y_c)\n",
    "        point.append(X_c)\n",
    "        point.append(Y_c)\n",
    "        point = np.array(point)\n",
    "        image_array_seq_t = image_array_seq[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_max_t = image_array_max[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_FQ_t = image_array_FQ[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+x_border) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+y_border)]\n",
    "        x_FQ = [x_coord[i] for i in idx]\n",
    "        y_FQ = [y_coord[i] for i in idx]\n",
    "        seq_t = [sequence[i] for i in idx]\n",
    "        if len(seq_t)<100:\n",
    "            log_file.write('Not enough (<100) clusters: '+ str(len(seq_t))+ '\\n')\n",
    "            continue\n",
    "\n",
    "        #print(image_array)\n",
    "\n",
    "        #reading by cv2 to make possible circles in color\n",
    "        #img_jpg = io.imread('C:/Users/panf/Documents/Muscle_intermediates/AVG_G10_1_1_MMStack_Pos0.ome.jpg')\n",
    "        #img_array = img_as_int(img)\n",
    "        # displaying the image\n",
    "        # setting mouse handler for the image\n",
    "        # and calling the click_event() function\n",
    "        image_seq = Image.fromarray(image_array_seq_t)\n",
    "        image_seq.save (pos_direct + '/'+ pos+'_seq.tif')\n",
    "\n",
    "        image_fastq = Image.fromarray(image_array_FQ_t)\n",
    "        image_fastq.save (pos_direct + '/'+ pos+'_fastq.tif')\n",
    "\n",
    "        v_min, v_max = np.percentile(image_array_seq_t, (0, 99.8))\n",
    "        if v_max == 0: v_max = np.max(image_array_seq_t)  \n",
    "\n",
    "        # Calculating the shift between the FASTQ and cluster images using cross-correlation\n",
    "        shift = phase_cross_correlation(image_array_max_t,image_array_FQ_t)\n",
    "        shift = shift[0]\n",
    "        print(shift)\n",
    "        # Translation of the FASTQ sequences in the FOV to match the cluster image\n",
    "        x_FQ = np.subtract(x_FQ,X_c-shift[1])\n",
    "        y_FQ = np.subtract(y_FQ,Y_c-shift[0])\n",
    "        FQ_shifts.append([X_c-shift[1], Y_c-shift[0]])\n",
    "        FQ_shifts_pos.append(pos)\n",
    "        \n",
    "        MAX_centers = blob_detection(\n",
    "            image_array_max_t,\n",
    "            min_sigma=1,\n",
    "            max_sigma=10,\n",
    "            threshold=0.0001\n",
    "        )\n",
    "        FQ_centers_all = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "        res, idx = count_nearest_pts(FQ_centers_all, MAX_centers, 2)\n",
    "        FQ_centers_all1 = FQ_centers_all[idx[np.where(res != inf)]]\n",
    "        MAX_centers1 = MAX_centers[np.where(res != inf)]\n",
    "#         print(FQ_centers_all1)\n",
    "#         print(MAX_centers1)\n",
    "\n",
    "        trFQtoMAX = transform.estimate_transform(\"similarity\", src=FQ_centers_all1, dst=MAX_centers1)\n",
    "\n",
    "        temp = trFQtoMAX(FQ_centers_all)\n",
    "        x_FQ = temp[:,0];\n",
    "        y_FQ = temp[:,1];\n",
    "\n",
    "        fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "        fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "        max_image = generate_img(MAX_centers[:,1],MAX_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        max_image.save(os.path.join(pos_direct,pos+'_MAX_seq_CoM.png'))\n",
    "        max_image = Image.fromarray(image_array_max_t)\n",
    "        max_image.save(os.path.join(pos_direct,pos+'_MAX_seq.png'))\n",
    "#         fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "#         fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(fastq_image1)\n",
    "        plt.show()\n",
    "\n",
    "        # Selecting the library sequences for further analysis\n",
    "        idx = library_index(library_seq, seq_t, 40)\n",
    "        x_FQ = [x_FQ[i] for i in idx]\n",
    "        y_FQ = [y_FQ[i] for i in idx]\n",
    "        seq_t = [seq_t[i] for i in idx]\n",
    "        \n",
    "\n",
    "        v_min, v_max = np.percentile(image_array_F, (0, 100))\n",
    "        if v_max == 0: v_max = np.max(image_array_F)\n",
    "        v_max = 0.1*v_max #adjust the percent (10% in this run) as necessary\n",
    "        better_contrast_image_array = exposure.rescale_intensity(image_array_F, in_range=(v_min, v_max))\n",
    "        better_contrast_img = Image.fromarray(better_contrast_image_array)\n",
    "        better_contrast_img.save(pos_direct + '/'+pos + '_contr.tif')\n",
    "        better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "        #reading by cv2 to make possible circles in color\n",
    "        v_min, v_max = np.percentile(image_array_seq_t, (0, 100))\n",
    "        if v_max == 0: v_max = np.max(image_array_seq_t)\n",
    "        v_max = 0.1*v_max\n",
    "        better_contrast_image_array_2 = exposure.rescale_intensity(image_array_seq_t, in_range=(v_min, v_max))\n",
    "        better_contrast_img_2 = Image.fromarray(better_contrast_image_array_2)\n",
    "        better_contrast_img_2.save(pos_direct + '/'+''+ pos+'_contr_MIN_seq_stack.tif')\n",
    "        better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif') \n",
    "        FRET_coord = []\n",
    "        seq_coord = []\n",
    "#         cv2.namedWindow(pos) \n",
    "#         cv2.namedWindow(pos+'_seq') \n",
    "        cv2.namedWindow(pos, cv2.WINDOW_NORMAL) \n",
    "        cv2.namedWindow(pos+'_seq',cv2.WINDOW_NORMAL) \n",
    "\n",
    "        cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "        cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "        cv2.resizeWindow(pos, 2*x_border,2*y_border)\n",
    "        cv2.resizeWindow(pos+'_seq', 2*x_border,2*y_border)\n",
    "        #cv2.setMouseCallback('image1',  click_event)\n",
    "        while(1):\n",
    "            cv2.imshow(pos,better_contrast_img)\n",
    "            cv2.imshow(pos+'_seq',better_contrast_img_2)\n",
    "            k = cv2.waitKey(1)&0xFF \n",
    "            #if cv2.waitKey(20) & 0xFF == 27: #press Esc to quit\n",
    "            if k == ord('q'): # Press 'q' to finish\n",
    "                if len(seq_coord) == len(FRET_coord):\n",
    "                    break\n",
    "                else:\n",
    "                    counter = 0\n",
    "                    cv2.destroyAllWindows()\n",
    "                    FRET_coord = []\n",
    "                    seq_coord = []\n",
    "                    cv2.namedWindow(pos, cv2.WINDOW_NORMAL) \n",
    "                    cv2.namedWindow(pos+'_seq',cv2.WINDOW_NORMAL) \n",
    "                    cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "                    cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "                    cv2.resizeWindow(pos, 2*x_border,2*y_border)\n",
    "                    cv2.resizeWindow(pos+'_seq', 2*x_border,2*y_border)\n",
    "                    better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif')\n",
    "                    better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "            elif k == ord('r'): # Press 'r' to restart\n",
    "                counter = 0\n",
    "                cv2.destroyAllWindows()\n",
    "                FRET_coord = []\n",
    "                seq_coord = []\n",
    "                cv2.namedWindow(pos, cv2.WINDOW_NORMAL) \n",
    "                cv2.namedWindow(pos+'_seq',cv2.WINDOW_NORMAL) \n",
    "                cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "                cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "                cv2.resizeWindow(pos, 2*x_border,2*y_border)\n",
    "                cv2.resizeWindow(pos+'_seq', 2*x_border,2*y_border)\n",
    "                better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif')\n",
    "                better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # If the user selected less than three beads we switch to the next FOV\n",
    "        if len(seq_coord) < 3:\n",
    "            log_file.write('Not enough (<3) manually selected beads\\n')\n",
    "            continue\n",
    "        \n",
    "        seq_coord = np.reshape(seq_coord,(int((counter+1)/2), 2))\n",
    "        FRET_coord = np.reshape(FRET_coord,(int((counter+1)/2), 2))\n",
    "        FRET_coord = apriori_tr_inv(FRET_coord)\n",
    "        result = np.concatenate ((FRET_coord, seq_coord), axis = 0)\n",
    "        np.save(pos_direct + '/' + pos+'_manual_coord', result)\n",
    "        \n",
    "        rough_tr1 = transform.estimate_transform(\"similarity\", src=FRET_coord, dst=seq_coord)\n",
    "        np.save(os.path.join(pos_direct, pos + \"_man_bead_tr\"), rough_tr1)\n",
    "        # Reading the smFRET movie\n",
    "#             path_smFRET_file = os.path.join(path_smFRET,pos+'.tiff')\n",
    "        \n",
    "        if os.path.exists(os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')\n",
    "        elif os.path.exists(os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')\n",
    "        elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')):\n",
    "            path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        img_smFRET = io.imread(path_smFRET_file)\n",
    "\n",
    "        # Averaging the first 10 frames to select peaks\n",
    "        if ALEX:\n",
    "            img_t = np.mean(img_smFRET[green_frames,::], axis = 0)\n",
    "        else:\n",
    "            img_t = np.mean(img_smFRET[0:10,::], axis = 0)\n",
    "        img_t = img_t.astype(\"ushort\")\n",
    "        rb_rad = 10\n",
    "\n",
    "        red = img_t[256:,:]\n",
    "        green = img_t[:256,:]\n",
    "        red = red - rolling_ball(red, radius=rb_rad)\n",
    "        green = green - rolling_ball(green, radius=rb_rad)\n",
    "        green = transform.warp(green,tr_R2G, preserve_range = True)\n",
    "        combined = red + green # Consider adding the red excitation channel, though there are some difficulties, e.g. beads and int scaling\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(combined)\n",
    "        blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=300) # Was 1000 for 19/07/2022\n",
    "#             Was 300 for 06/09/2022\n",
    "        CM = []\n",
    "        r = 3\n",
    "        [h,w] = red.shape\n",
    "        n_frames = img_smFRET.shape[0]\n",
    "\n",
    "        for i, blob in enumerate(blobs_log):\n",
    "            x, y, d = blob\n",
    "            if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "                temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "                CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "                c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "                ax.add_patch(c)\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        smFRET_centers = np.array(CM)\n",
    "        FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "        res, idx = count_nearest_pts(rough_tr1(smFRET_centers), FQ_centers, 2)\n",
    "        movie_centers1 = smFRET_centers[idx[np.where(res != inf)]]\n",
    "        seq_centers1 = FQ_centers[np.where(res != inf)]\n",
    "\n",
    "        if seq_centers1.shape[0]<4:\n",
    "            print('Not enough smFRET peaks (<4)')\n",
    "            log_file.write('Not enough smFRET peaks (<4)')\n",
    "            continue\n",
    "\n",
    "        tr = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "        tr_inv = transform.estimate_transform(\"similarity\", src=seq_centers1, dst=movie_centers1)\n",
    "        np.save(os.path.join(pos_direct, pos + \"_final_tr\"), tr)\n",
    "        np.save(os.path.join(pos_direct, pos + \"_final_tr_inv\"), tr_inv)\n",
    "        log_file.write('Matched clusters before transform update: ' + str(seq_centers1.shape[0])+'\\n')\n",
    "        print('Matched clusters before transform update: ',seq_centers1.shape[0])\n",
    "\n",
    "        res, idx = count_nearest_pts(tr(smFRET_centers), FQ_centers, 3) # Was 4 for 19/07/2022\n",
    "        centers_matched = smFRET_centers[idx[np.where(res != inf)]]\n",
    "        idx_t = np.where(res != inf)\n",
    "        seq_matched = [seq_t[i] for i in idx_t[0]]\n",
    "        FQ_centers_matched = FQ_centers[idx_t]\n",
    "        distances_matched = res[idx_t]\n",
    "\n",
    "\n",
    "        centers_red = centers_matched\n",
    "        centers_green = tr_R2G(centers_matched)\n",
    "        r = 3\n",
    "        # Weed out positions that are too close to the edge\n",
    "        idx_t = np.where((centers_red[:,0]>rb) & (centers_red[:,0]<(w-rb)) & (centers_red[:,1]>rb) & (centers_red[:,1]<(h-rb))  & \n",
    "                         (centers_green[:,0]>rb) & (centers_green[:,0]<(w-rb)) & (centers_green[:,1]>rb) & (centers_green[:,1]<(h-rb)))\n",
    "        centers_red = centers_red [idx_t]\n",
    "        centers_green = centers_green [idx_t]\n",
    "        seq_matched = [seq_matched[i] for i in idx_t[0]]\n",
    "        distances_matched = distances_matched[idx_t]\n",
    "\n",
    "        matched_sequences.append(seq_matched)\n",
    "        matched_centers_red.append(centers_red)\n",
    "        matched_centers_green.append(centers_green)\n",
    "        matched_dist.append(distances_matched)\n",
    "        matched_centers_FQ.append(FQ_centers_matched)\n",
    "        good_pos.append(pos)\n",
    "        log_file.write('Matched clusters after transform update: ' + str(len(seq_matched))+'\\n')\n",
    "        log_file.write('Out of ' + str(len(smFRET_centers)) + ' smFRET peaks and ' + str(len(FQ_centers)) + ' clusters'+'\\n')\n",
    "        log_file.write('Percentage of matched smFRET peaks: ' + str(int(100*len(seq_matched)/len(smFRET_centers)))+'\\n')\n",
    "        log_file.write('Percentage of matched clusters: ' + str(int(100*len(seq_matched)/len(FQ_centers)))+'\\n')\n",
    "        print('Matched clusters after transform update: ',len(seq_matched))\n",
    "        print('Out of ',len(smFRET_centers), ' smFRET peaks and ', len(FQ_centers), ' clusters')\n",
    "        print('Percentage of matched smFRET peaks: ',int(100*len(seq_matched)/len(smFRET_centers)))\n",
    "        print('Percentage of matched clusters: ',int(100*len(seq_matched)/len(FQ_centers)))\n",
    "        # Saving transformed bead and molecule images for QC\n",
    "        img_beads_tfd = Image.fromarray(transform.warp(img_beads_F, tr_inv, output_shape = [y_border, x_border]))\n",
    "        img_beads_tfd.save(os.path.join(pos_direct, pos + \"_beads_transformed.tif\"))\n",
    "        img_smFRET_tfd = Image.fromarray(transform.warp(combined, tr_inv, output_shape = [y_border, x_border]))\n",
    "        img_smFRET_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_transformed.tif\"))\n",
    "        centers_red_tfd = tr(centers_red)\n",
    "        img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_matched_transformed.tif\"))\n",
    "\n",
    "        centers_red_tfd = tr(smFRET_centers)\n",
    "        img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_all_transformed.tif\"))\n",
    "\n",
    "        img_centers_red_tfd = generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_matched.tif\"))\n",
    "\n",
    "        img_centers_red_tfd = generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_all.tif\"))\n",
    "        \n",
    "#         Saving a composite image for quick QC\n",
    "        fig, ax = plt.subplots()\n",
    "        QC_composite_array = np.zeros([y_border,x_border,3], dtype=np.uint8)\n",
    "        red_channel = np.asarray(generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(red_channel[75:125,:], (0.5, 99.5))        \n",
    "        red_channel = exposure.rescale_intensity(red_channel, in_range=tuple(percentiles))\n",
    "        red_channel = img_as_ubyte(red_channel)\n",
    "\n",
    "        green_channel = np.asarray(generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(green_channel, (0.5, 99.5))\n",
    "        green_channel = exposure.rescale_intensity(green_channel, in_range=tuple(percentiles))\n",
    "        green_channel = img_as_ubyte(green_channel)\n",
    "\n",
    "        blue_channel = np.asarray(generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "        percentiles = np.percentile(blue_channel, (0.5, 99.5))\n",
    "        blue_channel = exposure.rescale_intensity(blue_channel, in_range=tuple(percentiles))\n",
    "        blue_channel = img_as_ubyte(blue_channel)\n",
    "\n",
    "        QC_composite_array[:,:,0] = red_channel\n",
    "        QC_composite_array[:,:,1] = green_channel\n",
    "        QC_composite_array[:,:,2] = blue_channel\n",
    "\n",
    "        QC_composite = Image.fromarray(QC_composite_array, mode=\"RGB\")\n",
    "        QC_composite.save(os.path.join(current_direct, 'QC_composites_raw' , pos + \"_QC.tif\"))\n",
    "\n",
    "        ax.imshow(QC_composite)\n",
    "        for blob in FQ_centers_matched:\n",
    "            c = plt.Circle(blob, 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig(os.path.join(current_direct, 'QC_composites' , pos + \"_QC.png\"))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "# Save good pos data to be able to extract traces later\n",
    "frame_rate = 5\n",
    "mdict1 = {\n",
    "    \"good_pos\": good_pos,\n",
    "    \"matched_sequences\": matched_sequences,\n",
    "    \"matched_centers_red\": matched_centers_red,\n",
    "    \"matched_centers_green\": matched_centers_green,\n",
    "    \"matched_distances\": matched_dist,\n",
    "    \"FASTQ_x\": x_coord,\n",
    "    \"FASTQ_Y\": Y_coord,\n",
    "    \"FASTQ_shifts\": FQ_shifts\n",
    "}\n",
    "\n",
    "savemat(os.path.join(current_direct, \"good_pos_man.mat\"), mdict1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of matched FOVs: ',len(good_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting traces, median BG version\n",
    "r = 3 # Half-width of the molecule aperture for trace extraction, i.e. for r = 3 it is -3:3\n",
    "rb = 5 # Half-width of the background aperture for trace extraction \n",
    "# (bacground is calculated as a median of intensities in a rectangular aperture between r and rb)\n",
    "# a = np.subtract(range(2*rb+1), rb)\n",
    "at = [[j,i] for i in range(2*rb+1) for j in range(rb-r)]\n",
    "bt = [[j,i] for i in range(2*rb+1) for j in range(r+rb+1,2*rb+1)]\n",
    "ct = [[j,i] for i in range(rb-r) for j in range(rb-r,r+rb+1)]\n",
    "dt = [[j,i] for i in range(r+rb+1,2*rb+1) for j in range(rb-r,r+rb+1)]\n",
    "idx_bg = np.subtract(np.concatenate([at,bt,ct,dt]), [rb,rb]) # Indexes that define the background aperture\n",
    "\n",
    "for i, pos in enumerate(good_pos):\n",
    "    # Reading the smFRET movie\n",
    "#     img_smFRET = io.imread(os.path.join(path_smFRET,pos+'.tiff'))\n",
    "    if os.path.exists(os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')\n",
    "    elif os.path.exists(os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_hairpinGreen','img_000000000.tiff')\n",
    "    elif os.path.exists(os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')):\n",
    "        path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green_hairpin','img_000000000.tiff')\n",
    "    else:\n",
    "        continue\n",
    "    img_smFRET = io.imread(path_smFRET_file)\n",
    "    \n",
    "    seq_matched = matched_sequences[i]\n",
    "    dist_matched = matched_dist[i]\n",
    "    centers_red = matched_centers_red[i]\n",
    "    centers_green = matched_centers_green[i]\n",
    "    n_traces = len(centers_red)\n",
    "    [h,w] = [256,512]\n",
    "    n_frames = img_smFRET.shape[0]\n",
    "\n",
    "    weights_red = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    weights_green = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    traces_red =  np.zeros([n_traces,n_frames])\n",
    "    traces_green = np.zeros([n_traces,n_frames])\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Select matching peaks from peak_locations and their sequences\n",
    "\n",
    "\n",
    "    for j,coord in enumerate(centers_red):\n",
    "        x, y = coord\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_red[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "        x, y = centers_green[j]\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_green[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        if i%100 == 0: print(\"Working on frame \"+str(i))\n",
    "        red1 = img_smFRET[i,256:,:]\n",
    "        red1 = red1 - si.restoration.rolling_ball(red1, radius=rb_rad)\n",
    "        green1 = img_smFRET[i,:256,:]\n",
    "        green1 = green1 - si.restoration.rolling_ball(green1, radius=rb_rad)\n",
    "\n",
    "        for j,coord in enumerate(centers_red):\n",
    "            x, y = coord\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "#             red2 = red1[y0:y1,x0:x1]\n",
    "#             traces_red[j,i] = np.sum(np.multiply(weights_red[j],red2))\n",
    "\n",
    "            index = np.add(idx_bg,[int(x), int(y)])\n",
    "            # Temporary fix for molecules that are too close to the edge\n",
    "#             if (np.max(index[:,1])<256)&(np.min(index[:,1])>=0)&(np.max(index[:,0])<512)&(np.min(index[:,0])>=0):            \n",
    "            BG = np.median(red1[index[:,1], index[:,0]])\n",
    "            red2 = np.subtract(red1[y0:y1,x0:x1], BG)\n",
    "            traces_red[j,i] = np.sum(np.multiply(weights_red[j],red2))\n",
    "#             else:\n",
    "#                 traces_red[j,i] = -10000\n",
    "                \n",
    "            x, y = centers_green[j]\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "#             green2 = green1[y0:y1,x0:x1]\n",
    "#             traces_green[j,i] = np.sum(np.multiply(weights_green[j],green2))\n",
    "            index = np.add(idx_bg,[int(x), int(y)])\n",
    "#             if (np.max(index[:,1])<256)&(np.min(index[:,1])>=0)&(np.max(index[:,0])<512)&(np.min(index[:,0])>=0):            \n",
    "            BG = np.median(green1[index[:,1], index[:,0]])\n",
    "            green2 = np.subtract(green1[y0:y1,x0:x1], BG)\n",
    "            traces_green[j,i] = np.sum(np.multiply(weights_green[j],green2))\n",
    "#             else:\n",
    "#                 traces_green[j,i] = -10000\n",
    "            \n",
    "\n",
    "\n",
    "    centers_FQ = matched_centers_FQ[i]\n",
    "    # Save traces and sequences\n",
    "    frame_rate = 5\n",
    "    mdict = {\n",
    "        \"time\": np.divide(range(n_frames),frame_rate),\n",
    "        \"Cy3\": traces_green,\n",
    "        \"Cy5\": traces_red,\n",
    "        \"Seq\": seq_matched,\n",
    "        \"Dist\": dist_matched,\n",
    "        \"x\": centers_red[:,0],\n",
    "        \"y\": centers_red[:,1],\n",
    "        \"x_FQ\": centers_FQ[:,0],\n",
    "        \"y_FQ\": centers_FQ[:,1]\n",
    "    }\n",
    "\n",
    "    savemat(os.path.join(current_direct, pos + \"_traces.mat\"), mdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF THE MAIN CYCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(image_array_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_centers_red_tfd = generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "        \n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(img_centers_red_tfd)\n",
    "\n",
    "# for blob in FQ_centers_matched:\n",
    "#     c = plt.Circle(blob, 3, color=\"red\", linewidth=1, fill=False)\n",
    "#     ax.add_patch(c)\n",
    "# ax.set_axis_off()\n",
    "# # plt.savefig(os.path.join(current_direct, 'QC_composites' , pos + \"_QC.png\"))\n",
    "# plt.show()\n",
    "# # a[:,256:] = 50\n",
    "# # a[:,0:10] = 200\n",
    "# # print(a[1,1])\n",
    "# # a = exposure.rescale_intensity(a)\n",
    "# # a = img_as_ubyte(a)\n",
    "# # print(a[1,1])\n",
    "# # print(a[1,11])\n",
    "# # percentiles = np.percentile(a, (0.5, 99.5))\n",
    "# # a1 = exposure.rescale_intensity(a, in_range=tuple(percentiles))\n",
    "# # b = np.zeros((256,512,3), dtype=np.uint8)\n",
    "# # b[:,:,0] = a1\n",
    "# # b[:,:,1] = a1\n",
    "# # # print(a1[0,400])\n",
    "# # fig, ax = plt.subplots()\n",
    "# # # QC_composite = Image.fromarray(b)\n",
    "# # QC_composite = Image.fromarray(b, mode = 'RGB')\n",
    "# # ax.imshow(QC_composite)\n",
    "# # plt.show()\n",
    "# # # print(np.asarray(QC_composite))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(FQ_centers_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+x_border) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+y_border)]\n",
    "x_FQ = [x_coord[i] for i in idx]\n",
    "y_FQ = [y_coord[i] for i in idx]\n",
    "seq_t = [sequence[i] for i in idx]\n",
    "print(len(seq_t))\n",
    "\n",
    "\n",
    "# Selecting the library sequences for further analysis\n",
    "idx = library_index(library_seq, seq_t, 40)\n",
    "x_FQ = [x_FQ[i] for i in idx]\n",
    "y_FQ = [y_FQ[i] for i in idx]\n",
    "seq_t = [seq_t[i] for i in idx]\n",
    "print(len(seq_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uknmatchstars_coord\n",
    "     )\n",
    "print(refmatchstars_coord)\n",
    "print(apriori_tr_inv(uknmatchstars_coord))\n",
    "rough_tr1 = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "\n",
    "print(rough_tr1.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(combined)\n",
    "blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=1000) # Was 1000 for 19/07/2022\n",
    "#             Was 300 for 06/09/2022\n",
    "CM = []\n",
    "r = 3\n",
    "[h,w] = red.shape\n",
    "n_frames = img_smFRET.shape[0]\n",
    "\n",
    "for i, blob in enumerate(blobs_log):\n",
    "    x, y, d = blob\n",
    "    if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "        temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "        CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "        c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "        ax.add_patch(c)\n",
    "ax.set_axis_off()\n",
    "plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smFRET_centers = np.array(CM)\n",
    "FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "res, idx = count_nearest_pts(rough_tr1(smFRET_centers), FQ_centers, 8)\n",
    "movie_centers1 = smFRET_centers[idx[np.where(res != inf)]]\n",
    "seq_centers1 = FQ_centers[np.where(res != inf)]\n",
    "print(FQ_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN BY DEFAULT! Removing the last position.\n",
    "matched_sequences = matched_sequences[:-1]\n",
    "matched_centers_red = matched_centers_red[:-1]\n",
    "matched_centers_green = matched_centers_green[:-1]\n",
    "good_pos = good_pos[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rough_tf1(smFRET_centers)\n",
    "dst = FQ_centers\n",
    "tree = spatial.KDTree(src)\n",
    "print(len(src), len(dst))\n",
    "res, idx = tree.query(dst, k=1, distance_upper_bound=8)\n",
    "for i in range(0, len(idx)):\n",
    "#     i = 0\n",
    "    idx_t = np.argwhere(idx == idx[i])\n",
    "    # print(len(idx_t))\n",
    "    # print(idx)\n",
    "    if len(idx_t) > 1:\n",
    "        res_t = [res[j] for j in idx_t]\n",
    "        if res[i] > min(res_t): res[i] = inf\n",
    "\n",
    "idx_t1 = np.argwhere(res < inf)\n",
    "print(len(idx_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastq_image = generate_img(y_coord,x_coord, 0, 0, max_y, max_x, 1, True, 1)\n",
    "# image_array_FQ1 = np.asarray(fastq_image)\n",
    "# idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+330) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+170)]\n",
    "# x_FQ = [x_coord[i] for i in idx]\n",
    "# y_FQ = [y_coord[i] for i in idx]\n",
    "# x_FQ = np.subtract(x_FQ,X_c-shift[1])\n",
    "# y_FQ = np.subtract(y_FQ,Y_c-shift[0])\n",
    "# fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, 170, 330, 1, True, 1)\n",
    "# # image_array_FQ_t = image_array_FQ1[ Y_c:Y_c+170, X_c:X_c+330]\n",
    "# # fig, ax = plt.subplots()\n",
    "# # ax.imshow(image_array_FQ_t)\n",
    "# # plt.show()\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(fastq_image1)\n",
    "# plt.show()\n",
    "# print(X_c,Y_c, shift)\n",
    "# print(min(x_FQ),max(x_FQ), min(y_FQ), max(y_FQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(good_pos), len(matched_sequences), len(matched_centers_red), len(matched_centers_green))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting traces Standard version\n",
    "\n",
    "for i, pos in enumerate(good_pos):\n",
    "    # Reading the smFRET movie\n",
    "#     img_smFRET = io.imread(os.path.join(path_smFRET,pos+'.tiff'))\n",
    "    img_smFRET = io.imread(os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff'))\n",
    "    seq_matched = matched_sequences[i]\n",
    "    centers_red = matched_centers_red[i]\n",
    "    centers_green = matched_centers_green[i]\n",
    "    n_traces = len(centers_red)\n",
    "    [h,w] = [256,512]\n",
    "    n_frames = img_smFRET.shape[0]\n",
    "\n",
    "    weights_red = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    weights_green = np.zeros([n_traces,2*r+1,2*r+1])\n",
    "    traces_red =  np.zeros([n_traces,n_frames])\n",
    "    traces_green = np.zeros([n_traces,n_frames])\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Extracting the traces from matched smFRET peaks\n",
    "    # Select matching peaks from peak_locations and their sequences\n",
    "\n",
    "\n",
    "    for j,coord in enumerate(centers_red):\n",
    "        x, y = coord\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_red[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "        x, y = centers_green[j]\n",
    "        x0 = int(x-r)\n",
    "        x1 = int(x+r+1)\n",
    "        y0 = int(y-r)\n",
    "        y1 = int(y+r+1)\n",
    "        dx = x-x0\n",
    "        dy = y-y0\n",
    "\n",
    "        it = np.nditer(weights_green[j], flags=['multi_index'], op_flags=['readwrite'])\n",
    "        for w1 in it:\n",
    "            yt,xt = it.multi_index\n",
    "            w1[...] = 2*exp(-0.4*((xt-dx)**2+(yt-dy)**2))\n",
    "        it.close()\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        if i%100 == 0: print(\"Working on frame \"+str(i))\n",
    "        red1 = img_smFRET[i,256:,:]\n",
    "        red1 = red1 - si.restoration.rolling_ball(red1, radius=rb_rad)\n",
    "        green1 = img_smFRET[i,:256,:]\n",
    "        green1 = green1 - si.restoration.rolling_ball(green1, radius=rb_rad)\n",
    "\n",
    "        for j,coord in enumerate(centers_red):\n",
    "            x, y = coord\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "            red2 = red1[y0:y1,x0:x1]\n",
    "            traces_red[j,i] = np.sum(np.multiply(weights_red[j],red2))\n",
    "\n",
    "            x, y = centers_green[j]\n",
    "            x0 = int(x-r)\n",
    "            x1 = int(x+r+1)\n",
    "            y0 = int(y-r)\n",
    "            y1 = int(y+r+1)\n",
    "            dx = x-x0\n",
    "            dy = y-y0\n",
    "            green2 = green1[y0:y1,x0:x1]\n",
    "            traces_green[j,i] = np.sum(np.multiply(weights_green[j],green2))\n",
    "\n",
    "\n",
    "    # Save traces and sequences\n",
    "    frame_rate = 5\n",
    "    mdict = {\n",
    "        \"time\": np.divide(range(n_frames),frame_rate),\n",
    "        \"Cy3\": traces_green,\n",
    "        \"Cy5\": traces_red,\n",
    "        \"Seq\": seq_matched\n",
    "    }\n",
    "\n",
    "    savemat(os.path.join(current_direct, pos + \"_traces.mat\"), mdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main pipeline ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip by default! Figuring out the displacement for tiles.\n",
    "# file_path = fd.askopenfilename(title = \"Choose the position list\")\n",
    "\n",
    "# pos_file = open(file_path)\n",
    "# data = json.load(pos_file)\n",
    "# POS = data['POSITIONS']\n",
    "\n",
    "# labels = [P['LABEL'] for P in POS]\n",
    "# posX = [P['DEVICES'][0]['X'] for P in POS]\n",
    "# posY = [P['DEVICES'][0]['Y'] for P in POS]\n",
    "# # print(min(posX), max(posX), min(posY), max(posY))\n",
    "# upper_left_um_x = min(posX)\n",
    "# upper_left_um_y = max(posY)\n",
    "# file_path_coords = fd.askopenfilename(title = \"Choose the coordinate .npy file\", initialdir = os.path.dirname(file_path))\n",
    "# coords_t = np.load(file_path_coords)\n",
    "# n_t = int(len(coords_t)/2)\n",
    "# coords_t_seq = coords_t[:n_t,:]\n",
    "# coords_t_FRET = coords_t[n_t:,:]\n",
    "# [deltax, deltay] = np.mean(np.subtract(coords_t_seq,coords_t_FRET), axis = 0)\n",
    "# print(deltax,deltay)\n",
    "# print(upper_left_um_x, upper_left_um_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    root = tk.Tk()\n",
    "    root.attributes(\"-topmost\", True)\n",
    "    root.withdraw()\n",
    "    labels_res = []\n",
    "    posX_res = []\n",
    "    posY_res = []\n",
    "    file_path = fd.askopenfilename(title = \"Choose the position list\", initialdir = \"D:/Experiments/MUSCLE DONUTS/20220824_FC_Nano_Cas9_CCR5/parameter\")\n",
    "    pos_file = open(file_path)\n",
    "    data = json.load(pos_file)\n",
    "    POS = data['POSITIONS']\n",
    "\n",
    "    labels = [P['LABEL'] for P in POS]\n",
    "    posX = [P['DEVICES'][0]['X'] for P in POS]\n",
    "    posY = [P['DEVICES'][0]['Y'] for P in POS]\n",
    "    \n",
    "    for i,x in enumerate(labels):\n",
    "        x = int(2329 + (posX[i] - 28522.9)/0.34)\n",
    "        y = int(2042 - (posY[i] + 1313.3)/0.34)\n",
    "        if (x > 0 ) and (y > 0):\n",
    "            if (y+y_border<2866) and (x+x_border < 2944) :\n",
    "                labels_res.append (labels[i])\n",
    "                posX_res.append (posX[i])\n",
    "                posY_res.append( posY[i])\n",
    "    \n",
    "    \n",
    "    X_c = [posX[i] for i,x in enumerate(labels) if labels[i]=='Pos279']\n",
    "    Y_c = [posY[i] for i,x in enumerate(labels) if labels[i]=='Pos279']\n",
    "    #X_c, Y_c = scaling_seq(X_c[0], Y_c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dir = \"C:/Users/panf/Documents/Muscle_intermediates/test_folder_4/\"\n",
    "for pos in labels_res :\n",
    "    for current_dir,dirs, files in os.walk(app_dir) :\n",
    "        for el in files: \n",
    "            print(el.split('.')[-2])\n",
    "            print(pos)\n",
    "            if el.split('.')[-2] == pos:\n",
    "                img1 = io.imread(current_dir + '/' + el) #reading the stack of images\n",
    "                \n",
    "                img1 = img1.astype(\"ushort\") #turn from float format to ushort\n",
    "                img1 = img1 [256:512, 0:512]\n",
    "                plt.figure()\n",
    "                plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = [posX[i] for i,x in enumerate(labels) if labels[i]=='Pos148']\n",
    "Y_c = [posY[i] for i,x in enumerate(labels) if labels[i]=='Pos148']\n",
    "\n",
    "x_c, y_c = scaling_seq (X_c[0], Y_c[0])\n",
    "print (x_c, y_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "seq_coord = np.empty([0,2], dtype=int)\n",
    "fret_coord = np.empty([0,2], dtype=int)\n",
    "current_direct = \"D:/nanobio/uppsala/muscle/Muscle_Misha/beads/\"\n",
    "for current_dir,dirs, files in os.walk(current_direct) :\n",
    "        for el in files: \n",
    "            coord = np.load(current_dir + '/' + el) \n",
    "            length = len(coord)\n",
    "            fret_coord = np.concatenate ((fret_coord, coord[0:int(length/2)] ), axis = 0 )\n",
    "            seq_coord = np.concatenate ((seq_coord, coord[int(length/2):length] ), axis = 0 )\n",
    "\n",
    "seq_coord = seq_coord * 1.7\n",
    "#print(seq_coord)\n",
    "#print(fret_coord)\n",
    "distance1 = []\n",
    "length = len(seq_coord)\n",
    "print (length)\n",
    "res = np.concatenate ((seq_coord, fret_coord), axis = 1)\n",
    "for i in range(length):\n",
    "    \n",
    "    distance1.append(math.sqrt(math.pow((seq_coord[i][0] - fret_coord[i][0]),2) + math.pow((seq_coord[i][1] - fret_coord[i][1]),2)))\n",
    "    print(math.sqrt(math.pow((seq_coord[i][0] - fret_coord[i][0]),2) + math.pow((seq_coord[i][1] - fret_coord[i][1]),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ALTERNATIVE MAIN CYCLE to reanalyse the data with existing manual bead coordinates\n",
    "for pos in labels_res :\n",
    "#     for current_dir,dirs, files in os.walk(beads_dir) :\n",
    "# #         for el in files:     \n",
    "#             if el.split('.')[-2] == pos:\n",
    "    path1 = os.path.join(beads_dir,pos+'.tiff')\n",
    "    if os.path.exists(path1)&(not os.path.exists(os.path.join(path_smFRET, pos + \"_traces.mat\")))&(not pos in processed_pos):\n",
    "#         data['sequence'] = []\n",
    "        processed_pos.append(pos)\n",
    "        pos_direct = os.path.join(current_direct, pos)\n",
    "        os.makedirs(pos_direct, exist_ok=True)\n",
    "        log_file = open(os.path.join(pos_direct, pos + \"_log.txt\"), 'w')\n",
    "        log_file.write('Working on: '+ pos+'\\n')\n",
    "        FRET_coord = []\n",
    "        seq_coord = []\n",
    "        point = []\n",
    "        counter = 0\n",
    "        rb_rad = 10\n",
    "        img_beads_F = io.imread(path1) #reading the stack of images\n",
    "        if len(img_beads_F.shape) == 3:\n",
    "            img_beads_F = np.mean(img_beads_F, axis = 0) #averaging by the stack\n",
    "        img_beads_F = img_beads_F.astype(\"ushort\") #turn from float format to ushort\n",
    "        img_beads_F = img_beads_F [256:512, 0:512]\n",
    "        img_beads_F = img_beads_F - si.restoration.rolling_ball(img_beads_F, radius=rb_rad)\n",
    "        image_array_F = transform.warp(img_beads_F, apriori_tr_inv, output_shape = [y_border, x_border])\n",
    "        image_array_F = img_as_ubyte(image_array_F)\n",
    "        #img = io.imread(current_dir + '/' + el) #initial reading of original averaging image\n",
    "        #img = cv2.imread(app.st)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img1)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(seq)\n",
    "\n",
    "        image_array_F = np.asarray(image_array_F) #array from FRET image\n",
    "#         plt.figure()\n",
    "#         plt.imshow(image_array_F)\n",
    "        \n",
    "        idx = [i for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 X_c = [posX_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 Y_c = [posY_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "        X_c = [posX_res[i] for i in idx]\n",
    "        Y_c = [posY_res[i] for i in idx]\n",
    "\n",
    "        X_c, Y_c = scaling_seq(X_c[0], Y_c[0])\n",
    "#         print (X_c, Y_c)\n",
    "        point.append(X_c)\n",
    "        point.append(Y_c)\n",
    "        point = np.array(point)\n",
    "        image_array_seq_t = image_array_seq[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_max_t = image_array_max[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        image_array_FQ_t = image_array_FQ[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "        idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+x_border) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+y_border)]\n",
    "        x_FQ = [x_coord[i] for i in idx]\n",
    "        y_FQ = [y_coord[i] for i in idx]\n",
    "        seq_t = [sequence[i] for i in idx]\n",
    "        if len(seq_t)<100:\n",
    "            log_file.write('Not enough (<100) clusters: '+ str(len(seq_t))+ '\\n')\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "#                 for i in range (len(sequence)):\n",
    "#                     if (x_coord[i] >= X_c) and (x_coord[i] <= X_c+330): \n",
    "#                         if (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+170):\n",
    "#                                 data['sequence'].append({\n",
    "#                                                      'X': x_coord[i],\n",
    "#                                                      'Y': y_coord[i],\n",
    "#                                                      'sequence': sequence[i]\n",
    "#                                                         })\n",
    "\n",
    "        #print(image_array)\n",
    "        v_min, v_max = np.percentile(image_array_F, (0, 99.8))\n",
    "        if v_max == 0: v_max = np.max(image_array_F)\n",
    "        better_contrast_image_array = exposure.rescale_intensity(image_array_F, in_range=(v_min, v_max))\n",
    "        better_contrast_img = Image.fromarray(better_contrast_image_array)\n",
    "        better_contrast_img.save(pos_direct + '/'+pos + '_contr.tif')\n",
    "        better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "        #reading by cv2 to make possible circles in color\n",
    "        #img_jpg = io.imread('C:/Users/panf/Documents/Muscle_intermediates/AVG_G10_1_1_MMStack_Pos0.ome.jpg')\n",
    "        #img_array = img_as_int(img)\n",
    "        # displaying the image\n",
    "        # setting mouse handler for the image\n",
    "        # and calling the click_event() function\n",
    "        image_seq = Image.fromarray(image_array_seq_t)\n",
    "        image_seq.save (pos_direct + '/'+ pos+'_seq.tif')\n",
    "\n",
    "        image_fastq = Image.fromarray(image_array_FQ_t)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(image_fastq)\n",
    "        image_fastq.save (pos_direct + '/'+ pos+'_fastq.tif')\n",
    "\n",
    "        v_min, v_max = np.percentile(image_array_seq_t, (0, 99.8))\n",
    "        if v_max == 0: v_max = np.max(image_array_seq_t)\n",
    "        better_contrast_image_array_2 = exposure.rescale_intensity(image_array_seq_t, in_range=(v_min, v_max))\n",
    "        better_contrast_img_2 = Image.fromarray(better_contrast_image_array_2)\n",
    "        better_contrast_img_2.save(pos_direct + '/'+''+ pos+'_contr_MIN_seq_stack.tif')\n",
    "        better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif')     \n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow( Image.fromarray(image_array_seq_t))     \n",
    "        \n",
    "        # User clicks of beads with \"q\" for exit when done\n",
    "        FRET_coord = []\n",
    "        seq_coord = []\n",
    "#         cv2.namedWindow(pos) \n",
    "#         cv2.namedWindow(pos+'_seq') \n",
    "#         cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "#         cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "#         #cv2.setMouseCallback('image1',  click_event)\n",
    "#         while(1):\n",
    "#             cv2.imshow(pos,better_contrast_img)\n",
    "#             cv2.imshow(pos+'_seq',better_contrast_img_2)\n",
    "#             k = cv2.waitKey(1)&0xFF \n",
    "#             #if cv2.waitKey(20) & 0xFF == 27: #press Esc to quit\n",
    "#             if k == ord('q'): # Press 'q' to finish\n",
    "#                 if len(seq_coord) == len(FRET_coord):\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     counter = 0\n",
    "#                     cv2.destroyAllWindows()\n",
    "#                     FRET_coord = []\n",
    "#                     seq_coord = []\n",
    "#                     cv2.namedWindow(pos) \n",
    "#                     cv2.namedWindow(pos+'_seq') \n",
    "#                     cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "#                     cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "#                     better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif')\n",
    "#                     better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "#             elif k == ord('r'): # Press 'r' to restart\n",
    "#                 counter = 0\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 FRET_coord = []\n",
    "#                 seq_coord = []\n",
    "#                 cv2.namedWindow(pos) \n",
    "#                 cv2.namedWindow(pos+'_seq') \n",
    "#                 cv2.setMouseCallback(pos,  click_event_FRET)\n",
    "#                 cv2.setMouseCallback(pos+'_seq',  click_event_seq)\n",
    "#                 better_contrast_img_2 = cv2.imread(pos_direct + '/'+pos+ '_contr_MIN_seq_stack.tif')\n",
    "#                 better_contrast_img = cv2.imread(pos_direct + '/'+pos + '_contr.tif')\n",
    "        \n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "        # If the user selected at least three beads we proceed with analysis\n",
    "        if os.path.exists(pos_direct + '/' + pos+'_manual_coord.npy'): \n",
    "            result = np.load(pos_direct + '/' + pos+'_manual_coord.npy')\n",
    "#             seq_coord = np.reshape(seq_coord,(int((counter+1)/2), 2))\n",
    "            \n",
    "#             FRET_coord = np.reshape(FRET_coord,(int((counter+1)/2), 2))\n",
    "#             FRET_coord = apriori_tr_inv(FRET_coord)\n",
    "            split = int(len(result)/2)\n",
    "            FRET_coord = result[:split,:]\n",
    "            seq_coord = result[split:,:]\n",
    "#             np.save(pos_direct + '/' + pos+'_manual_coord', result)\n",
    "            \n",
    "            # Calculating the shift between the FASTQ and cluster images using cross-correlation\n",
    "            shift = phase_cross_correlation(image_array_max_t,image_array_FQ_t)\n",
    "            shift = shift[0]\n",
    "            # Translation of the FASTQ sequences in the FOV to match the cluster image\n",
    "            x_FQ = np.subtract(x_FQ,X_c-shift[1])\n",
    "            y_FQ = np.subtract(y_FQ,Y_c-shift[0])\n",
    "            max_image = Image.fromarray(image_array_max_t)\n",
    "            max_image.save(os.path.join(pos_direct,pos+'_MAX_seq.png'))\n",
    "            fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "            fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(fastq_image1)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # Selecting the library sequences for further analysis\n",
    "            idx = library_index(library_seq, seq_t, 40)\n",
    "            x_FQ = [x_FQ[i] for i in idx]\n",
    "            y_FQ = [y_FQ[i] for i in idx]\n",
    "            seq_t = [seq_t[i] for i in idx]\n",
    "\n",
    "            # Calculating the first rough transformation based on manually-selected beads\n",
    "            rough_tr = transform.estimate_transform(\"similarity\", src=FRET_coord, dst=seq_coord)\n",
    "            np.save(os.path.join(pos_direct, pos + \"_man_bead_tr\"), rough_tr)\n",
    "            # Refining the transformation based on automatically-selected beads\n",
    "            movie_centers = blob_detection(\n",
    "                np.asarray(img_beads_F),\n",
    "                min_sigma=1,\n",
    "                max_sigma=10,\n",
    "                threshold=0.01\n",
    "            )\n",
    "\n",
    "            seq_centers = blob_detection(\n",
    "                image_array_seq_t,\n",
    "                min_sigma=1,\n",
    "                max_sigma=10,\n",
    "                threshold=0.0001, # Was 0.00001 for 19/07/2022; 0.0001 for 06/09/2022\n",
    "             )\n",
    "            \n",
    "            res, idx = count_nearest_pts(rough_tr(movie_centers), seq_centers, 8)\n",
    "            movie_centers1 = movie_centers[idx[np.where(res != inf)]]\n",
    "            seq_centers1 = seq_centers[np.where(res != inf)]\n",
    "            print('Automatically matched beads: ',seq_centers1.shape[0])\n",
    "            if seq_centers1.shape[0] >2:\n",
    "                log_file.write(\"Detected \" + str(seq_centers1.shape[0]) + \" matched beads. Updating the manual transformation\\n\")                \n",
    "                rough_tr1 = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "            else:\n",
    "                log_file.write(\"\"\"Not enough (<3) automatically detected and matched beads to update the initial\n",
    "                               transformation estimate based on manually selected beads\\n\"\"\")\n",
    "                rough_tr1 = rough_tr\n",
    "\n",
    "            np.save(os.path.join(pos_direct, pos + \"_auto_bead_tr\"), rough_tr1)\n",
    "            # Reading the smFRET movie\n",
    "            img_smFRET = io.imread(os.path.join(path_smFRET,pos+'.tiff'))\n",
    "\n",
    "            # Averaging the first 10 frames to select peaks\n",
    "            img_t = np.mean(img_smFRET[0:10,::], axis = 0)\n",
    "            img_t = img_t.astype(\"ushort\")\n",
    "            rb_rad = 10\n",
    "            #print(img1[10:20,10:20])\n",
    "            #img = np.zeros([20,20])\n",
    "            #img[10,5] = 1000\n",
    "            red = img_t[256:,:]\n",
    "            green = img_t[:256,:]\n",
    "            red = red - si.restoration.rolling_ball(red, radius=rb_rad)\n",
    "            green = green - si.restoration.rolling_ball(green, radius=rb_rad)\n",
    "            green = transform.warp(green,tr_R2G, preserve_range = True)\n",
    "            combined = red + green # Consider adding the red excitation channel, though there are some difficulties, e.g. beads and int scaling\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(combined)\n",
    "            blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=300) # Was 1000 for 19/07/2022; 300 for 06/09/2022\n",
    "            CM = []\n",
    "            r = 3\n",
    "            [h,w] = red.shape\n",
    "            n_frames = img_smFRET.shape[0]\n",
    "\n",
    "            for i, blob in enumerate(blobs_log):\n",
    "                x, y, d = blob\n",
    "                if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "                    temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "                    CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "                    c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "                    ax.add_patch(c)\n",
    "            ax.set_axis_off()\n",
    "            plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            smFRET_centers = np.array(CM)\n",
    "            FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "            res, idx = count_nearest_pts(rough_tr1(smFRET_centers), FQ_centers, 8)\n",
    "            movie_centers1 = smFRET_centers[idx[np.where(res != inf)]]\n",
    "            seq_centers1 = FQ_centers[np.where(res != inf)]\n",
    "\n",
    "            # Calculating the polynomial tranformation between FRET peaks and clusters\n",
    "            \n",
    "#             if seq_centers1.shape[0]>=9:\n",
    "#                 order = 2\n",
    "#             if seq_centers1.shape[0]>=4:\n",
    "#                 order = 1\n",
    "#             else: continue\n",
    "            if seq_centers1.shape[0]<4: \n",
    "                log_file.write('Not enough smFRET peaks (<4)')\n",
    "                continue\n",
    "            \n",
    "            tr = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "            tr_inv = transform.estimate_transform(\"similarity\", src=seq_centers1, dst=movie_centers1)\n",
    "            np.save(os.path.join(pos_direct, pos + \"_final_tr\"), tr)\n",
    "            np.save(os.path.join(pos_direct, pos + \"_final_tr_inv\"), tr_inv)\n",
    "            log_file.write('Matched clusters before polywarp: ' + str(seq_centers1.shape[0])+'\\n')\n",
    "            print('Matched clusters before polywarp: ',seq_centers1.shape[0])\n",
    "            \n",
    "#             kx,ky = Polywarp.polywarp(seq_centers1[:,0],seq_centers1[:,1],movie_centers1[:,0],movie_centers1[:,1],degree=order)\n",
    "# #             print(kx)\n",
    "# #             print(ky)\n",
    "#             tr = transform.PolynomialTransform()\n",
    "#             #tr.estimate(src,dst,order = 2)\n",
    "\n",
    "#             order1 = 2*order\n",
    "#             pidx = 0\n",
    "#             par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "#             for j in range(order1 + 1):\n",
    "#                 for i in range(j + 1):\n",
    "#                     if (j-i)<=order and i<=order:\n",
    "#                         par[0, pidx] = kx[j - i,i]\n",
    "#                         par[1, pidx] = ky[j - i,i]\n",
    "#                     else:\n",
    "#                         par[0, pidx] = 0\n",
    "#                         par[1, pidx] = 0\n",
    "#                     pidx += 1\n",
    "#             tr.params = par        \n",
    "\n",
    "#             kx,ky = Polywarp.polywarp(movie_centers1[:,0],movie_centers1[:,1],seq_centers1[:,0],seq_centers1[:,1],degree=order)\n",
    "#             tr_inv = transform.PolynomialTransform()\n",
    "#             #tr.estimate(src,dst,order = 2)\n",
    "\n",
    "#             order1 = 2*order\n",
    "#             pidx = 0\n",
    "#             par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "#             for j in range(order1 + 1):\n",
    "#                 for i in range(j + 1):\n",
    "#                     if (j-i)<=order and i<=order:\n",
    "#                         par[0, pidx] = kx[j - i,i]\n",
    "#                         par[1, pidx] = ky[j - i,i]\n",
    "#                     else:\n",
    "#                         par[0, pidx] = 0\n",
    "#                         par[1, pidx] = 0\n",
    "#                     pidx += 1\n",
    "#             tr_inv.params = par\n",
    "\n",
    "            res, idx = count_nearest_pts(tr(smFRET_centers), FQ_centers, 8) # Was 4 for 19/07/2022\n",
    "            centers_matched = smFRET_centers[idx[np.where(res != inf)]]\n",
    "            idx_t = np.where(res != inf)\n",
    "            seq_matched = [seq_t[i] for i in idx_t[0]]\n",
    "            FQ_centers_matched = FQ_centers[idx_t]\n",
    "            \n",
    "            \n",
    "            centers_red = centers_matched\n",
    "            centers_green = tr_R2G(centers_matched)\n",
    "            r = 3\n",
    "            # Weed out positions that are too close to the edge\n",
    "            idx_t = np.where((centers_red[:,0]>r) & (centers_red[:,0]<(w-r)) & (centers_red[:,1]>r) & (centers_red[:,1]<(h-r))  & \n",
    "                             (centers_green[:,0]>r) & (centers_green[:,0]<(w-r)) & (centers_green[:,1]>r) & (centers_green[:,1]<(h-r)))\n",
    "            centers_red = centers_red [idx_t]\n",
    "            centers_green = centers_green [idx_t]\n",
    "            seq_matched = [seq_matched[i] for i in idx_t[0]]\n",
    "            \n",
    "            matched_sequences.append(seq_matched)\n",
    "            matched_centers_red.append(centers_red)\n",
    "            matched_centers_green.append(centers_green)\n",
    "            good_pos.append(pos)\n",
    "            log_file.write('Matched clusters after polywarp: ' + str(len(seq_matched))+'\\n')\n",
    "            log_file.write('Out of ' + str(len(smFRET_centers)) + ' smFRET peaks and ' + str(len(FQ_centers)) + ' clusters'+'\\n')\n",
    "            log_file.write('Percentage of matched smFRET peaks: ' + str(int(100*len(seq_matched)/len(smFRET_centers)))+'\\n')\n",
    "            log_file.write('Percentage of matched clusters: ' + str(int(100*len(seq_matched)/len(FQ_centers)))+'\\n')\n",
    "            print('Matched clusters after polywarp: ',len(seq_matched))\n",
    "            print('Out of ',len(smFRET_centers), ' smFRET peaks and ', len(FQ_centers), ' clusters')\n",
    "            print('Percentage of matched smFRET peaks: ',int(100*len(seq_matched)/len(smFRET_centers)))\n",
    "            print('Percentage of matched clusters: ',int(100*len(seq_matched)/len(FQ_centers)))\n",
    "            # Saving transformed bead and molecule images for QC\n",
    "            img_beads_tfd = Image.fromarray(transform.warp(img_beads_F, tr_inv, output_shape = [y_border, x_border]))\n",
    "            img_beads_tfd.save(os.path.join(pos_direct, pos + \"_beads_transformed.tif\"))\n",
    "            img_smFRET_tfd = Image.fromarray(transform.warp(combined, tr_inv, output_shape = [y_border, x_border]))\n",
    "            img_smFRET_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_transformed.tif\"))\n",
    "            centers_red_tfd = tr(centers_red)\n",
    "            img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "            img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_matched_transformed.tif\"))\n",
    "            \n",
    "            centers_red_tfd = tr(smFRET_centers)\n",
    "            img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "            img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_all_transformed.tif\"))\n",
    "            \n",
    "            img_centers_red_tfd = generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "            img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_matched.tif\"))\n",
    "                    \n",
    "            img_centers_red_tfd = generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "            img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_all.tif\"))\n",
    "        else:   log_file.write('Not enough manually matched beads\\n')\n",
    "\n",
    "# Save good pos data to be able to extract traces later\n",
    "frame_rate = 5\n",
    "mdict1 = {\n",
    "    \"good_pos\": good_pos,\n",
    "    \"matched_sequences\": matched_sequences,\n",
    "    \"matched_centers_red\": matched_centers_red,\n",
    "    \"matched_centers_green\": matched_centers_green\n",
    "}\n",
    "\n",
    "savemat(os.path.join(current_direct, \"good_pos.mat\"), mdict1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_c,X_c\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.measure import ransac\n",
    "# from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "# # print(movie_centers)\n",
    "# # print(seq_centers)\n",
    "\n",
    "# \"\"\" \n",
    "#     Wrapped polynomial transformation for Ransac using.\n",
    "# \"\"\"\n",
    "# class QuadPolyTrans(transform.PolynomialTransform):\n",
    "#     def estimate(*data):\n",
    "#         return transform.PolynomialTransform.estimate(*data, order=2)\n",
    "\n",
    "\n",
    "# class CubicPolyTrans(transform.PolynomialTransform):\n",
    "#     def estimate(*data):\n",
    "#         return transform.PolynomialTransform.estimate(*data, order=3)\n",
    "# model, inliers = ransac(\n",
    "#     (FQ_centers_all1, MAX_centers1),\n",
    "#     transform.SimilarityTransform,\n",
    "#     20,\n",
    "#     2,\n",
    "#     initial_inliers=np.ones(len(MAX_centers1), dtype=bool),\n",
    "#     stop_probability=0.999\n",
    "# )\n",
    "# print(model.params)\n",
    "# print(inliers)\n",
    "# FQ_centers_all2 = FQ_centers_all1[np.where(inliers == True)]\n",
    "# MAX_centers2 = MAX_centers1[np.where(inliers == True)]\n",
    "\n",
    "\n",
    "\n",
    "# print('Residuals after poly (order = '+str(order)+') transformation: ',mean_squared_error(model(FQ_centers_all1), MAX_centers1))\n",
    "# print('Residuals before transformation: ',mean_squared_error(FQ_centers_all1, MAX_centers1))\n",
    "\n",
    "\n",
    "# order = 3\n",
    "# kx,ky = Polywarp.polywarp(MAX_centers2[:,0],MAX_centers2[:,1],FQ_centers_all2[:,0],FQ_centers_all2[:,1],degree=order)\n",
    "# print(kx)\n",
    "# print(ky)\n",
    "# trFQtoMAX = transform.PolynomialTransform()\n",
    "# #tr.estimate(src,dst,order = 2)\n",
    "# order1 = 2*order\n",
    "# pidx = 0\n",
    "# par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "# for j in range(order1 + 1):\n",
    "#     for i in range(j + 1):\n",
    "#         if (j-i)<=order and i<=order:\n",
    "#             par[0, pidx] = kx[j - i,i]\n",
    "#             par[1, pidx] = ky[j - i,i]\n",
    "#         else:\n",
    "#             par[0, pidx] = 0\n",
    "#             par[1, pidx] = 0\n",
    "#         pidx += 1\n",
    "# trFQtoMAX.params = par  \n",
    "# print('Residuals after poly (order = '+str(order)+') transformation: ',mean_squared_error(trFQtoMAX(FQ_centers_all1), MAX_centers1))\n",
    "# print('Residuals before transformation: ',mean_squared_error(FQ_centers_all1, MAX_centers1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN CYCLE test\n",
    "processed_pos = []\n",
    "\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites'), exist_ok=True)\n",
    "os.makedirs(os.path.join(current_direct, 'QC_composites_raw'), exist_ok=True)\n",
    "# for pos in labels_res :\n",
    "#     for current_dir,dirs, files in os.walk(beads_dir) :\n",
    "# #         for el in files:     \n",
    "#             if el.split('.')[-2] == pos:\n",
    "#     path1 = os.path.join(beads_dir,pos+'.tiff')\n",
    "path1 = os.path.join(beads_dir,pos,'A_Red','img_000000000.tiff')\n",
    "if os.path.exists(path1)&(not os.path.exists(os.path.join(path_smFRET, pos + \"_traces.mat\")))&(not pos in processed_pos):\n",
    "#         data['sequence'] = []\n",
    "\n",
    "    processed_pos.append(pos)\n",
    "    pos_direct = os.path.join(current_direct, pos)\n",
    "    os.makedirs(pos_direct, exist_ok=True)\n",
    "    log_file = open(os.path.join(pos_direct, pos + \"_log.txt\"), 'w')\n",
    "    log_file.write('Working on: '+ pos+'\\n')\n",
    "    FRET_coord = []\n",
    "    seq_coord = []\n",
    "    point = []\n",
    "    counter = 0\n",
    "    rb_rad = 10\n",
    "    img_beads_F = io.imread(path1) #reading the stack of images\n",
    "    if len(img_beads_F.shape) == 3:\n",
    "        img_beads_F = np.mean(img_beads_F, axis = 0) #averaging by the stack\n",
    "    img_beads_F = img_beads_F.astype(\"ushort\") #turn from float format to ushort\n",
    "    img_beads_F = img_beads_F [256:512, 0:512]\n",
    "    img_beads_F = img_beads_F - rolling_ball(img_beads_F, radius=rb_rad)\n",
    "    image_array_F = transform.warp(img_beads_F, apriori_tr_inv, output_shape = [y_border, x_border])\n",
    "    image_array_F = img_as_ubyte(image_array_F)\n",
    "    #img = io.imread(current_dir + '/' + el) #initial reading of original averaging image\n",
    "    #img = cv2.imread(app.st)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img1)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(seq)\n",
    "\n",
    "    image_array_F = np.asarray(image_array_F) #array from FRET image\n",
    "#         plt.figure()\n",
    "#         plt.imshow(image_array_F)\n",
    "\n",
    "    idx = [i for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 X_c = [posX_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "#                 Y_c = [posY_res[i] for i,x in enumerate(labels_res) if labels_res[i]==pos]\n",
    "    X_c = [posX_res[i] for i in idx]\n",
    "    Y_c = [posY_res[i] for i in idx]\n",
    "\n",
    "    X_c, Y_c = scaling_seq(X_c[0], Y_c[0])\n",
    "#         print (X_c, Y_c)\n",
    "    point.append(X_c)\n",
    "    point.append(Y_c)\n",
    "    point = np.array(point)\n",
    "    image_array_seq_t = image_array_seq[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "    image_array_max_t = image_array_max[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "    image_array_FQ_t = image_array_FQ[ Y_c:Y_c+y_border, X_c:X_c+x_border]\n",
    "    idx = [i for i,x in enumerate(x_coord) if x_coord[i] >= X_c and (x_coord[i] <= X_c+x_border) and (y_coord[i] >= Y_c) and (y_coord[i] <= Y_c+y_border)]\n",
    "    x_FQ = [x_coord[i] for i in idx]\n",
    "    y_FQ = [y_coord[i] for i in idx]\n",
    "    seq_t = [sequence[i] for i in idx]\n",
    "    if len(seq_t)<100:\n",
    "        log_file.write('Not enough (<100) clusters: '+ str(len(seq_t))+ '\\n')\n",
    "#         continue\n",
    "\n",
    "    #print(image_array)\n",
    "\n",
    "    #reading by cv2 to make possible circles in color\n",
    "    #img_jpg = io.imread('C:/Users/panf/Documents/Muscle_intermediates/AVG_G10_1_1_MMStack_Pos0.ome.jpg')\n",
    "    #img_array = img_as_int(img)\n",
    "    # displaying the image\n",
    "    # setting mouse handler for the image\n",
    "    # and calling the click_event() function\n",
    "    image_seq = Image.fromarray(image_array_seq_t)\n",
    "    image_seq.save (pos_direct + '/'+ pos+'_seq.tif')\n",
    "\n",
    "    image_fastq = Image.fromarray(image_array_FQ_t)\n",
    "    image_fastq.save (pos_direct + '/'+ pos+'_fastq.tif')\n",
    "\n",
    "    v_min, v_max = np.percentile(image_array_seq_t, (0, 99.8))\n",
    "    if v_max == 0: v_max = np.max(image_array_seq_t)  \n",
    "\n",
    "    # Calculating the shift between the FASTQ and cluster images using cross-correlation\n",
    "    shift = phase_cross_correlation(image_array_max_t,image_array_FQ_t)\n",
    "    shift = shift[0]\n",
    "    # Translation of the FASTQ sequences in the FOV to match the cluster image\n",
    "    x_FQ = np.subtract(x_FQ,X_c-shift[1])\n",
    "    y_FQ = np.subtract(y_FQ,Y_c-shift[0])\n",
    "    max_image = Image.fromarray(image_array_max_t)\n",
    "    max_image.save(os.path.join(pos_direct,pos+'_MAX_seq.png'))\n",
    "\n",
    "#     fastq_image_ = generate_img(y_coord,x_coord, 0, 0, max_y, max_x, 1, True, 1)\n",
    "    MAX_centers = blob_detection(\n",
    "        image_array_max_t,\n",
    "        min_sigma=1,\n",
    "        max_sigma=10,\n",
    "        threshold=0.0001\n",
    "    )\n",
    "    FQ_centers_all = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "    res, idx = count_nearest_pts(FQ_centers_all, MAX_centers, 2)\n",
    "    FQ_centers_all1 = FQ_centers_all[idx[np.where(res != inf)]]\n",
    "    MAX_centers1 = MAX_centers[np.where(res != inf)]\n",
    "    print(FQ_centers_all1)\n",
    "    print(MAX_centers1)\n",
    "    \n",
    "    trFQtoMAX = transform.estimate_transform(\"similarity\", src=FQ_centers_all1, dst=MAX_centers1)\n",
    "#     order = 4\n",
    "#     kx,ky = Polywarp.polywarp(MAX_centers1[:,0],MAX_centers1[:,1],FQ_centers_all1[:,0],FQ_centers_all1[:,1],degree=order)\n",
    "#     print(kx)\n",
    "#     print(ky)\n",
    "#     trFQtoMAX = transform.PolynomialTransform()\n",
    "#     #tr.estimate(src,dst,order = 2)\n",
    "#     order1 = 2*order\n",
    "#     pidx = 0\n",
    "#     par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "#     for j in range(order1 + 1):\n",
    "#         for i in range(j + 1):\n",
    "#             if (j-i)<=order and i<=order:\n",
    "#                 par[0, pidx] = kx[j - i,i]\n",
    "#                 par[1, pidx] = ky[j - i,i]\n",
    "#             else:\n",
    "#                 par[0, pidx] = 0\n",
    "#                 par[1, pidx] = 0\n",
    "#             pidx += 1\n",
    "#     trFQtoMAX.params = par  \n",
    "    print('Residuals after poly (order = '+str(order)+') transformation: ',mean_squared_error(trFQtoMAX(FQ_centers_all1), MAX_centers1))\n",
    "    print('Residuals before transformation: ',mean_squared_error(FQ_centers_all1, MAX_centers1))\n",
    "    \n",
    "    \n",
    "    temp = trFQtoMAX(FQ_centers_all)\n",
    "    x_FQ = temp[:,0];\n",
    "    y_FQ = temp[:,1];\n",
    "    \n",
    "    \n",
    "    fastq_image1 = generate_img(y_FQ,x_FQ, 0, 0, y_border, x_border, 1, True, 1)\n",
    "    fastq_image1.save(os.path.join(pos_direct,pos+'_FQ_aligned.png'))\n",
    "    max_image = generate_img(MAX_centers[:,1],MAX_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "    max_image.save(os.path.join(pos_direct,pos+'_MAX_seq_CoM.png'))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(fastq_image1)\n",
    "    plt.show()\n",
    "\n",
    "    # Selecting the library sequences for further analysis\n",
    "    idx = [i for i,x in enumerate(seq_t) if library_seq in x]\n",
    "    x_FQ = [x_FQ[i] for i in idx]\n",
    "    y_FQ = [y_FQ[i] for i in idx]\n",
    "    seq_t = [seq_t[i] for i in idx]\n",
    "\n",
    "    # Calculating the transformation based on automatically-selected beads\n",
    "    movie_centers = blob_detection(\n",
    "        np.asarray(img_beads_F),\n",
    "        min_sigma=1,\n",
    "        max_sigma=10,\n",
    "        threshold=0.01\n",
    "    )\n",
    "\n",
    "    seq_centers = blob_detection(\n",
    "        image_array_seq_t,\n",
    "        min_sigma=1,\n",
    "        max_sigma=10,\n",
    "        threshold=0.001, # Was 0.00001 for 19/07/2022\n",
    "     )\n",
    "\n",
    "    a = run(seq_centers, apriori_tr(movie_centers))\n",
    "\n",
    "    uknmatchstars_coord = []\n",
    "    refmatchstars_coord = []\n",
    "    if len(a[0].refmatchstars) >= 3:\n",
    "        for i in range (len(a[0].refmatchstars)):\n",
    "            uknmatchstars_coord.append(a[0].uknmatchstars[i].x)\n",
    "            uknmatchstars_coord.append(a[0].uknmatchstars[i].y)\n",
    "            refmatchstars_coord.append(a[0].refmatchstars[i].x)\n",
    "            refmatchstars_coord.append(a[0].refmatchstars[i].y)\n",
    "\n",
    "        refmatchstars_coord = np.array(refmatchstars_coord)\n",
    "        uknmatchstars_coord = np.array(uknmatchstars_coord)\n",
    "\n",
    "        refmatchstars_coord = np.reshape ( refmatchstars_coord, ( int(len(a[0].refmatchstars)), 2 ) )\n",
    "        uknmatchstars_coord = np.reshape ( uknmatchstars_coord, ( int(len(a[0].uknmatchstars)), 2 ) )\n",
    "        result_coord = np.concatenate ((refmatchstars_coord,uknmatchstars_coord ), axis = 0)\n",
    "        print (pos+\"\\n\", result_coord )\n",
    "        np.save (os.path.join(pos_direct, pos + \"_matching_beads\"), result_coord)\n",
    "    else:\n",
    "        log_file.write(\"\"\"Not enough (<3) automatically detected and matched beads to update the initial\n",
    "                       transformation estimate based on manually selected beads\\n\"\"\")\n",
    "#         continue\n",
    "#         res, idx = count_nearest_pts(rough_tr(movie_centers), seq_centers, 8)\n",
    "#         movie_centers1 = movie_centers[idx[np.where(res != inf)]]\n",
    "#         seq_centers1 = seq_centers[np.where(res != inf)]\n",
    "    movie_centers1 = apriori_tr_inv(uknmatchstars_coord)\n",
    "    seq_centers1 = refmatchstars_coord\n",
    "    print('Automatically matched beads: ',seq_centers1.shape[0])\n",
    "    rough_tr1 = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "    np.save(os.path.join(pos_direct, pos + \"_auto_bead_tr\"), rough_tr1)\n",
    "    # Reading the smFRET movie\n",
    "#             path_smFRET_file = os.path.join(path_smFRET,pos+'.tiff')\n",
    "    path_smFRET_file = os.path.join(path_smFRET,pos,'B_Green','img_000000000.tiff')\n",
    "#     if not os.path.exists(path_smFRET_file):\n",
    "#         continue\n",
    "\n",
    "    img_smFRET = io.imread(path_smFRET_file)\n",
    "\n",
    "    # Averaging the first 10 frames to select peaks\n",
    "    img_t = np.mean(img_smFRET[0:10,::], axis = 0)\n",
    "    img_t = img_t.astype(\"ushort\")\n",
    "    rb_rad = 10\n",
    "\n",
    "    red = img_t[256:,:]\n",
    "    green = img_t[:256,:]\n",
    "    red = red - rolling_ball(red, radius=rb_rad)\n",
    "    green = green - rolling_ball(green, radius=rb_rad)\n",
    "    green = transform.warp(green,tr_R2G, preserve_range = True)\n",
    "    combined = red + green # Consider adding the red excitation channel, though there are some difficulties, e.g. beads and int scaling\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(combined)\n",
    "    blobs_log = blob_log(combined, max_sigma=10, num_sigma=10, threshold=1000) # Was 1000 for 19/07/2022\n",
    "#             Was 300 for 06/09/2022\n",
    "    CM = []\n",
    "    r = 3\n",
    "    [h,w] = red.shape\n",
    "    n_frames = img_smFRET.shape[0]\n",
    "\n",
    "    for i, blob in enumerate(blobs_log):\n",
    "        x, y, d = blob\n",
    "        if x>r and x<(h-r) and y>r and y<(w-r):\n",
    "            temp = ndimage.measurements.center_of_mass(combined[int(x-r):int(x+r+1),int(y-r):int(y+r+1)])\n",
    "            CM.append(np.flip(np.add(temp, [x-r,y-r])))\n",
    "\n",
    "            c = plt.Circle(CM[-1], 3, color=\"red\", linewidth=1, fill=False)\n",
    "            ax.add_patch(c)\n",
    "    ax.set_axis_off()\n",
    "    plt.savefig(os.path.join(pos_direct, pos + \"_smFRET_peaks.tif\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    smFRET_centers = np.array(CM)\n",
    "    FQ_centers = np.concatenate((x_FQ, y_FQ)).reshape((-1, 2), order='F')\n",
    "    res, idx = count_nearest_pts(rough_tr1(smFRET_centers), FQ_centers, 2)\n",
    "    movie_centers1 = smFRET_centers[idx[np.where(res != inf)]]\n",
    "    seq_centers1 = FQ_centers[np.where(res != inf)]\n",
    "\n",
    "    if seq_centers1.shape[0]<4:\n",
    "        print('Not enough smFRET peaks (<4)')\n",
    "        log_file.write('Not enough smFRET peaks (<4)')\n",
    "#         continue\n",
    "    \n",
    "    order = 2\n",
    "    kx,ky = Polywarp.polywarp(seq_centers1[:,0],seq_centers1[:,1],movie_centers1[:,0],movie_centers1[:,1],degree=order)\n",
    "    print(kx)\n",
    "    print(ky)\n",
    "    tr = transform.PolynomialTransform()\n",
    "    #tr.estimate(src,dst,order = 2)\n",
    "\n",
    "    order1 = 2*order\n",
    "    pidx = 0\n",
    "    par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "    for j in range(order1 + 1):\n",
    "        for i in range(j + 1):\n",
    "            if (j-i)<=order and i<=order:\n",
    "                par[0, pidx] = kx[j - i,i]\n",
    "                par[1, pidx] = ky[j - i,i]\n",
    "            else:\n",
    "                par[0, pidx] = 0\n",
    "                par[1, pidx] = 0\n",
    "            pidx += 1\n",
    "    tr.params = par        \n",
    "\n",
    "    kx,ky = Polywarp.polywarp(movie_centers1[:,0],movie_centers1[:,1],seq_centers1[:,0],seq_centers1[:,1],degree=order)\n",
    "    tr_inv = transform.PolynomialTransform()\n",
    "    #tr.estimate(src,dst,order = 2)\n",
    "\n",
    "    order1 = 2*order\n",
    "    pidx = 0\n",
    "    par = np.zeros([2,int((order1+1)*(order1+2)/2)])\n",
    "    for j in range(order1 + 1):\n",
    "        for i in range(j + 1):\n",
    "            if (j-i)<=order and i<=order:\n",
    "                par[0, pidx] = kx[j - i,i]\n",
    "                par[1, pidx] = ky[j - i,i]\n",
    "            else:\n",
    "                par[0, pidx] = 0\n",
    "                par[1, pidx] = 0\n",
    "            pidx += 1\n",
    "    tr_inv.params = par    \n",
    "#     tr = transform.estimate_transform(\"similarity\", src=movie_centers1, dst=seq_centers1)\n",
    "#     tr_inv = transform.estimate_transform(\"similarity\", src=seq_centers1, dst=movie_centers1)\n",
    "    np.save(os.path.join(pos_direct, pos + \"_final_tr\"), tr)\n",
    "    np.save(os.path.join(pos_direct, pos + \"_final_tr_inv\"), tr_inv)\n",
    "    log_file.write('Matched clusters before transform update: ' + str(seq_centers1.shape[0])+'\\n')\n",
    "    print('Matched clusters before transform update: ',seq_centers1.shape[0])\n",
    "\n",
    "    res, idx = count_nearest_pts(tr(smFRET_centers), FQ_centers, 1) # Was 4 for 19/07/2022\n",
    "    centers_matched = smFRET_centers[idx[np.where(res != inf)]]\n",
    "    idx_t = np.where(res != inf)\n",
    "    seq_matched = [seq_t[i] for i in idx_t[0]]\n",
    "    FQ_centers_matched = FQ_centers[idx_t]\n",
    "\n",
    "\n",
    "    centers_red = centers_matched\n",
    "    centers_green = tr_R2G(centers_matched)\n",
    "    r = 3\n",
    "    # Weed out positions that are too close to the edge\n",
    "    idx_t = np.where((centers_red[:,0]>r) & (centers_red[:,0]<(w-r)) & (centers_red[:,1]>r) & (centers_red[:,1]<(h-r))  & \n",
    "                     (centers_green[:,0]>r) & (centers_green[:,0]<(w-r)) & (centers_green[:,1]>r) & (centers_green[:,1]<(h-r)))\n",
    "    centers_red = centers_red [idx_t]\n",
    "    centers_green = centers_green [idx_t]\n",
    "    seq_matched = [seq_matched[i] for i in idx_t[0]]\n",
    "\n",
    "    matched_sequences.append(seq_matched)\n",
    "    matched_centers_red.append(centers_red)\n",
    "    matched_centers_green.append(centers_green)\n",
    "    good_pos.append(pos)\n",
    "    log_file.write('Matched clusters after transform update: ' + str(len(seq_matched))+'\\n')\n",
    "    log_file.write('Out of ' + str(len(smFRET_centers)) + ' smFRET peaks and ' + str(len(FQ_centers)) + ' clusters'+'\\n')\n",
    "    log_file.write('Percentage of matched smFRET peaks: ' + str(int(100*len(seq_matched)/len(smFRET_centers)))+'\\n')\n",
    "    log_file.write('Percentage of matched clusters: ' + str(int(100*len(seq_matched)/len(FQ_centers)))+'\\n')\n",
    "    print('Matched clusters after transform update: ',len(seq_matched))\n",
    "    print('Out of ',len(smFRET_centers), ' smFRET peaks and ', len(FQ_centers), ' clusters')\n",
    "    print('Percentage of matched smFRET peaks: ',int(100*len(seq_matched)/len(smFRET_centers)))\n",
    "    print('Percentage of matched clusters: ',int(100*len(seq_matched)/len(FQ_centers)))\n",
    "    # Saving transformed bead and molecule images for QC\n",
    "    img_beads_tfd = Image.fromarray(transform.warp(img_beads_F, tr_inv, output_shape = [y_border, x_border]))\n",
    "    img_beads_tfd.save(os.path.join(pos_direct, pos + \"_beads_transformed.tif\"))\n",
    "    img_smFRET_tfd = Image.fromarray(transform.warp(combined, tr_inv, output_shape = [y_border, x_border]))\n",
    "    img_smFRET_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_transformed.tif\"))\n",
    "    centers_red_tfd = tr(centers_red)\n",
    "    img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "    img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_matched_transformed.tif\"))\n",
    "\n",
    "    centers_red_tfd = tr(smFRET_centers)\n",
    "    img_centers_red_tfd = generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "    img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_smFRET_peaks_all_transformed.tif\"))\n",
    "\n",
    "    img_centers_red_tfd = generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "    img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_matched.tif\"))\n",
    "\n",
    "    img_centers_red_tfd = generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1)\n",
    "    img_centers_red_tfd.save(os.path.join(pos_direct, pos + \"_FQ_lib_all.tif\"))\n",
    "\n",
    "#         Saving a composite image for quick QC\n",
    "    fig, ax = plt.subplots()\n",
    "    QC_composite_array = np.zeros([y_border,x_border,3], dtype=np.uint8)\n",
    "    red_channel = np.asarray(generate_img(centers_red_tfd[:,1],centers_red_tfd[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "    percentiles = np.percentile(red_channel[75:125,:], (0.5, 99.5))        \n",
    "    red_channel = exposure.rescale_intensity(red_channel, in_range=tuple(percentiles))\n",
    "    red_channel = img_as_ubyte(red_channel)\n",
    "\n",
    "    green_channel = np.asarray(generate_img(FQ_centers[:,1],FQ_centers[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "    percentiles = np.percentile(green_channel, (0.5, 99.5))\n",
    "    green_channel = exposure.rescale_intensity(green_channel, in_range=tuple(percentiles))\n",
    "    green_channel = img_as_ubyte(green_channel)\n",
    "\n",
    "    blue_channel = np.asarray(generate_img(FQ_centers_matched[:,1],FQ_centers_matched[:,0], 0, 0, y_border, x_border, 1, True, 1))\n",
    "    percentiles = np.percentile(blue_channel, (0.5, 99.5))\n",
    "    blue_channel = exposure.rescale_intensity(blue_channel, in_range=tuple(percentiles))\n",
    "    blue_channel = img_as_ubyte(blue_channel)\n",
    "\n",
    "    QC_composite_array[:,:,0] = red_channel\n",
    "    QC_composite_array[:,:,1] = green_channel\n",
    "    QC_composite_array[:,:,2] = blue_channel\n",
    "\n",
    "    QC_composite = Image.fromarray(QC_composite_array, mode=\"RGB\")\n",
    "    QC_composite.save(os.path.join(current_direct, 'QC_composites_raw' , pos + \"_QC.tif\"))\n",
    "\n",
    "    ax.imshow(QC_composite)\n",
    "    for blob in FQ_centers_matched:\n",
    "        c = plt.Circle(blob, 3, color=\"red\", linewidth=1, fill=False)\n",
    "        ax.add_patch(c)\n",
    "    ax.set_axis_off()\n",
    "    plt.savefig(os.path.join(current_direct, 'QC_composites' , pos + \"_QC.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Save good pos data to be able to extract traces later\n",
    "frame_rate = 5\n",
    "mdict1 = {\n",
    "    \"good_pos\": good_pos,\n",
    "    \"matched_sequences\": matched_sequences,\n",
    "    \"matched_centers_red\": matched_centers_red,\n",
    "    \"matched_centers_green\": matched_centers_green\n",
    "}\n",
    "\n",
    "savemat(os.path.join(current_direct, \"good_pos.mat\"), mdict1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
