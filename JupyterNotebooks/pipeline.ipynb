{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import PolynomialTransform as Poly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from numpy.testing import assert_almost_equal\n",
    "from random import random, uniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import dist\n",
    "from skimage.filters import gaussian\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_cal(src, dst):\n",
    "    mse = mean_squared_error(src, dst) / len(src)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def save_np_img(npimg, path):\n",
    "    img = Image.fromarray(npimg)\n",
    "    img = img.convert(\"L\")\n",
    "    img.save(path, dpi=(300.0, 300.0))\n",
    "\n",
    "\n",
    "def ploting_res(canvas_size, res, pts_radius, save_path):\n",
    "    x_range, y_range = canvas_size\n",
    "    pk_img = np.zeros(canvas_size)\n",
    "    for ele in res:\n",
    "        y = int(ele[1])\n",
    "        x = int(ele[0])\n",
    "        for j in range(0, pts_radius):\n",
    "            for k in range(0, pts_radius):\n",
    "                pk_img[min(max(0, x - j), x_range - 1),\n",
    "                    min(max(0, y - k), y_range - 1)] = 1024 * 2\n",
    "                pk_img[min(x_range - 1, x + j),\n",
    "                    min(max(0, y - k), y_range - 1)] = 1024 * 2\n",
    "                pk_img[min(x_range - 1, x + j),\n",
    "                    min(y_range - 1, y + k)] = 1024 * 2\n",
    "                pk_img[min(max(0, x - j), x_range - 1),\n",
    "                    min(y_range - 1, y + k)] = 1024 * 2\n",
    "    blurred_img = gaussian(pk_img, sigma=3, multichannel=False)\n",
    "    save_np_img(blurred_img, save_path)\n",
    "\n",
    "\n",
    "def fake_data_test(marker_num, pts_num, noise_rate, displacement=False):\n",
    "    def poly_3_trans(pts, x_params, y_parms, displacement=False):\n",
    "            x, y = pts\n",
    "            poly_terms = np.array([1, x, y, x * x, x * y, y * y, x * x * x, x * x * y, x * y * y, y * y * y])\n",
    "            # print(poly_terms)\n",
    "            return np.array((np.dot(poly_terms, x_params.reshape(10, 1)) + int(displacement) * np.random.normal(loc=3, scale=3, size=1)[0], \n",
    "                             np.dot(poly_terms, y_parms.reshape(10, 1) + int(displacement) * np.random.normal(loc=3, scale=3, size=1)[0]))).reshape(1, 2)[0]\n",
    "\n",
    "    def generate_data(marker_num, pts_num, noise_rate):\n",
    "        rng = np.random.default_rng(seed=428)\n",
    "        beads_movie = rng.random((marker_num, 2))\n",
    "        beads_movie[:, 0] = beads_movie[:, 0] * 256\n",
    "        beads_movie[:, 1] = beads_movie[:, 1] * 512\n",
    "\n",
    "        pts_movie = rng.random((pts_num, 2))\n",
    "        pts_movie[:, 0] = pts_movie[:, 0] * 256\n",
    "        pts_movie[:, 1] = pts_movie[:, 1] * 512\n",
    "\n",
    "        # poly_trans_x_params = np.random.normal(loc=2, scale=1, size=10)\n",
    "        # poly_trans_y_params = np.random.normal(loc=2, scale=1, size=10)\n",
    "        # poly_trans_x_params = np.ones((10, 1))\n",
    "        poly_trans_x_params = np.array([-181.42149878341644, 7.512515275589122, 6.5142480464264265, 0.0057307135507819644, -0.050887234358891614, -0.012077111940913236, -2.7315150951088216e-05, 9.199782464861516e-05, 6.125989003219573e-05, 7.666340508330289e-07])\n",
    "        poly_trans_y_params = np.array([-698.9907615136117, 6.186382401506084, 22.584236882212387, -0.0011193284807307165, -0.14345083473014503, -0.021153463917421282, -3.564021898664521e-05, 0.0002703737578728173, 0.000156067089278071, -1.9121326943110133e-05])\n",
    "\n",
    "        beads_fastq = np.zeros((marker_num, 2))\n",
    "        for i in range(0, len(beads_movie)):\n",
    "            beads_fastq[i] = poly_3_trans(beads_movie[i], poly_trans_x_params, poly_trans_y_params, displacement)\n",
    "        pts_fastq = np.zeros((pts_num, 2))\n",
    "        for i in range(0, pts_num):\n",
    "            pts_fastq[i] = poly_3_trans(pts_movie[i], poly_trans_x_params, poly_trans_y_params, displacement)\n",
    "        if noise_rate > 0:\n",
    "            noise_fastq = rng.random((int(pts_num * noise_rate), 2))\n",
    "            noise_fastq[:, 0] = noise_fastq[:, 0] * 256\n",
    "            noise_fastq[:, 1] = noise_fastq[:, 1] * 512\n",
    "            for i in range(0, (int(pts_num * noise_rate))):\n",
    "                noise_fastq[i] = poly_3_trans(noise_fastq[i], poly_trans_x_params, poly_trans_y_params, displacement)\n",
    "            pts_fastq = np.concatenate((pts_fastq, noise_fastq))\n",
    "        return beads_movie, beads_fastq, pts_movie, pts_fastq\n",
    "        \n",
    "    beads_movie, beads_fastq, pts_movie, pts_fastq = generate_data(marker_num, pts_num, noise_rate)\n",
    "    # ploting_res((256, 512), beads_movie, 1, '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/PolyTest/beads_movie.png')\n",
    "    # ploting_res((256, 512), pts_movie, 1, '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/PolyTest/pts_movie.png')\n",
    "    # ploting_res((int(2.5e3), int(5e3)), beads_fastq, 3, '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/PolyTest/beads_fastq.png')\n",
    "    # ploting_res((int(2.5e3), int(5e3)), pts_fastq, 3, '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/PolyTest/pts_fastq.png')\n",
    "    # print(beads_movie)\n",
    "    # print(beads_fastq)\n",
    "    tform = transform.estimate_transform('polynomial', src=beads_movie, dst=beads_fastq, order=3)\n",
    "    res = tform(np.array(pts_movie))\n",
    "    print(residual_cal(pts_fastq, res))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.201997424272543e-10\n"
     ]
    }
   ],
   "source": [
    "fake_data_test(10, 40, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "tensor([[ 294.9398,  529.3074],\n",
      "        [ 955.2356,  598.4745],\n",
      "        [1489.4929,  369.5218],\n",
      "        [1420.0492, 1127.7278],\n",
      "        [ 740.4353, 2201.2944],\n",
      "        [1412.2332,  464.5072],\n",
      "        [1280.4548,  436.5154],\n",
      "        [1210.0364,  738.2871],\n",
      "        [1530.9141, 2267.9114],\n",
      "        [1125.6588, 1777.7992]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 294.0000,  530.0000],\n",
      "        [ 955.5000,  601.5000],\n",
      "        [1489.5000,  371.5000],\n",
      "        [1421.5000, 1133.5000],\n",
      "        [ 739.5000, 2201.5000],\n",
      "        [1407.5000,  459.5000],\n",
      "        [1281.5000,  431.5000],\n",
      "        [1213.5000,  741.5000],\n",
      "        [1529.5000, 2269.5000],\n",
      "        [1127.5000, 1771.5000]])\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Y\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tkinter import Y\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_feature, n_output):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, 8)\n",
    "        # self.hidden2 = torch.nn.Linear(8, 8)\n",
    "        self.predict = torch.nn.Linear(8, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        # x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(n_feature=2, n_output=2).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "res_tb = pd.read_csv('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0808/Results.csv')\n",
    "sample_num = int(len(res_tb) / 2)\n",
    "# print(np.array(res_tb['Y'][0:sample_num]))\n",
    "# print(np.column_stack((np.array(res_tb['Y'][0:sample_num]), np.array(res_tb['X'][0:sample_num]))))\n",
    "src = np.column_stack((np.array(res_tb['Y'][0:sample_num]), np.array(res_tb['X'][0:sample_num])))\n",
    "src_v = torch.from_numpy(src.astype(np.float32))\n",
    "dst = np.column_stack((np.array(res_tb['Y'][sample_num:]), np.array(res_tb['X'][sample_num:])))\n",
    "dst_v = torch.from_numpy(dst.astype(np.float32))\n",
    "\n",
    "\n",
    "for t in range(10000):\n",
    "    prediction = model(src_v)\n",
    "    loss = loss_fn(prediction, dst_v)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model(src_v))\n",
    "print(dst_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_tb = pd.read_csv('/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0808/res_maximum.csv')\n",
    "sample_num_peaks = int(len(peaks_tb))\n",
    "# print(np.array(res_tb['Y'][0:sample_num]))\n",
    "# print(np.column_stack((np.array(res_tb['Y'][0:sample_num]), np.array(res_tb['X'][0:sample_num]))))\n",
    "peak_locations = np.column_stack((np.array(peaks_tb['Y'][0:sample_num_peaks]), np.array(peaks_tb['X'][0:sample_num_peaks])))\n",
    "\n",
    "# peak_location_v = torch.from_numpy(np.array(peak_locations).astype(np.float32))\n",
    "# model.eval()\n",
    "# res = model(peak_location_v).cpu().detach().numpy()\n",
    "\n",
    "tform_1 = transform.estimate_transform('polynomial', src=src, dst=dst, order=1)\n",
    "poly_res_1 = tform_1(np.array(peak_locations))\n",
    "\n",
    "tform_2 = transform.estimate_transform('polynomial', src=src, dst=dst, order=2)\n",
    "poly_res_2 = tform_2(np.array(peak_locations))\n",
    "\n",
    "\n",
    "tform_3 = transform.estimate_transform('polynomial', src=src, dst=dst, order=3)\n",
    "poly_res_3 = tform_3(np.array(peak_locations))\n",
    "\n",
    "save_path = '/Users/qinhanhou/Desktop/DeindlLab/0729Poly/0810/'\n",
    "canvas_size = (1566, 3240)\n",
    "# ploting_res(canvas_size, res, 3, save_path + 'transformed_res_NN_test.png')\n",
    "ploting_res(canvas_size, poly_res_3, 3, save_path + 'transformed_res_poly3.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('donuts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09a6daa413063a39d67ff2395b4b7988be6704d7b326a0f0df1f4a2f602d4384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
